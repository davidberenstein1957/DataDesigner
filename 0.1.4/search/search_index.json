{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udfa8 NeMo Data Designer Library","text":"<p>\ud83d\udc4b Welcome to the Data Designer community! We're excited to have you here.</p> <p>Data Designer is a general framework for generating high-quality synthetic data from scratch or using your own seed data as a starting point for domain-grounded data generation.</p>"},{"location":"#why-data-designer","title":"Why Data Designer?","text":"<p>Generating high-quality synthetic data requires much more than iteratively calling an LLM.</p> <p>Data Designer is purpose-built to support large-scale, high-quality data generation, including</p> <ul> <li>Diversity \u2013 statistical distributions and variety that reflect real-world data patterns, not repetitive LLM outputs\u00a0</li> <li>Correlations \u2013 meaningful relationships between fields that LLMs cannot maintain across independent calls</li> <li>Steerability \u2013 flexible control over data characteristics throughout the generation process</li> <li>Validation \u2013 automated quality checks and verification that data meets specifications</li> <li>Reproducibility \u2013 shareable and reproducible generation workflows</li> </ul>"},{"location":"#how-does-it-work","title":"How does it work?","text":"<p>Data Designer helps you create datasets through an intuitive, iterative process:</p> <ol> <li>\u2699\ufe0f Configure your model settings<ul> <li>Bring your own OpenAI-compatible model providers and models</li> <li>Or use the default model providers and models to get started quickly</li> <li>Learn more by reading the model docs</li> </ul> </li> <li> <p>\ud83c\udfd7\ufe0f Design your dataset</p> <ul> <li>Iteratively design your dataset, column by column</li> <li>Leverage tools like statistical samplers and LLMs to generate a variety of data types</li> <li>Learn more by reading the column docs</li> </ul> </li> <li> <p>\ud83d\udd01 Preview your results and iterate</p> <ul> <li>Generate a preview dataset stored in memory for fast iteration</li> <li>Inspect sample records and analysis results to refine your configuration</li> <li>Try for yourself by running the tutorial notebooks</li> </ul> </li> <li>\ud83d\uddbc\ufe0f Create your dataset<ul> <li>Generate your full dataset and save results to disk</li> <li>Access the generated dataset and associated artifacts for downstream use</li> <li>Give it a try by running the tutorial notebooks</li> </ul> </li> </ol>"},{"location":"#library-and-microservice","title":"Library and Microservice","text":"<p>Data Designer is available as both an open-source library and a NeMo microservice.</p> <ul> <li>Open-source Library: Purpose-built for flexibility and customization, prioritizing UX excellence, modularity, and extensibility.</li> <li>NeMo Microservice: An enterprise-grade solution that offers a seamless transition from the library, allowing you to leverage other NeMo microservices and generate datasets at scale. See the microservice docs for more details.</li> </ul>"},{"location":"CONTRIBUTING/","title":"\ud83c\udfa8\u2728 Contributing to NeMo Data Designer \ud83c\udfa8\u2728","text":"<p>Thank you for your interest in contributing to Data Designer!</p> <p>We welcome contributions from the community and sincerely appreciate your efforts to improve the project. Whether you're fixing a typo, reporting a bug, proposing a new feature, or implementing a major enhancement, your work helps make Data Designer better for everyone \ud83c\udf89.</p> <p>This guide will help you get started with the contribution process.</p>"},{"location":"CONTRIBUTING/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Getting Started</li> <li>Ways to Contribute</li> <li>Feature Requests</li> <li>Development Guide</li> <li>Submitting Changes</li> <li>Code of Conduct</li> <li>Signing off on your work</li> </ul>"},{"location":"CONTRIBUTING/#getting-started","title":"Getting Started","text":"<p>\ud83d\udc4b Welcome to the Data Designer community! We're excited to have you here.</p> <p>Whether you're new to the project or ready to dive in, the resources below will help you get oriented and productive quickly:</p> <ol> <li> <p>README.md \u2013\u00a0best place to start to learn the basics of the project</p> </li> <li> <p>AGENTS.md\u00a0\u2013 context and instructions to help AI coding agents work on Data Designer (it's also useful for human developers!)</p> </li> <li> <p>Documentation \u2013\u00a0detailed documentation on Data Designer's capabilities and usage</p> </li> </ol>"},{"location":"CONTRIBUTING/#ways-to-contribute","title":"Ways to Contribute","text":"<p>There are many ways to contribute to Data Designer:</p>"},{"location":"CONTRIBUTING/#bug-fixes","title":"\ud83d\udc1b Bug Fixes","text":"<p>Found a bug? Before reporting, please 1. Verify you're using the latest version: <code>uv pip install --upgrade data-designer</code> 2. Search for duplicates in the issue tracker</p> <p>When creating a bug report, please include: - Data Designer version - Python version and operating system - Minimal reproducible example - Expected vs. actual behavior - Full error messages and stack traces</p> <p>If you are interested in fixing the bug yourself, that's AWESOME! Please follow the development guide to get started.</p>"},{"location":"CONTRIBUTING/#feature-implementation","title":"\u2728 Feature Implementation","text":"<p>Want to add new functionality? Great! Please review our development approach and open a feature request to discuss the idea and get feedback before investing significant time on the implementation.</p>"},{"location":"CONTRIBUTING/#documentation-improvements","title":"\ud83d\udcd6 Documentation Improvements","text":"<p>Documentation is crucial for user adoption. Contributions that clarify usage, add examples, or fix typos are highly valued.</p>"},{"location":"CONTRIBUTING/#examples-and-tutorials","title":"\ud83d\udca1 Examples and Tutorials","text":"<p>Share your use cases! Example notebooks and tutorials help others understand how to leverage Data Designer effectively.</p>"},{"location":"CONTRIBUTING/#test-coverage","title":"\ud83e\uddea Test Coverage","text":"<p>Help us improve test coverage by adding tests for untested code paths or edge cases.</p>"},{"location":"CONTRIBUTING/#feature-requests","title":"Feature Requests","text":"<p>Data Designer is designed to be as flexible and extensible as possible, and we welcome your ideas for pushing its capabilities even further! To keep the core library maintainable, while also supporting innovation, we take an incremental approach when adding new features \u2013 we explore what's already possible, extend through plugins when needed, and integrate the most broadly useful features into the core library:</p>"},{"location":"CONTRIBUTING/#how-we-grow-data-designer","title":"How We Grow Data Designer","text":"<ol> <li> <p>\ud83e\uddd7 Explore what's possible: Can your use case be achieved with current features? We've designed Data Designer to be composable \u2013 sometimes creative combinations of existing tools can accomplish what you need. Check out our examples or open an issue if you'd like help exploring this!</p> </li> <li> <p>\ud83d\udd0c Extend through plugins: If existing features aren't quite enough, consider implementing your idea as a plugin that extends the core library. Plugins let you experiment and share functionality while keeping the core library focused.</p> </li> <li> <p>\u2699\ufe0f Integrate into the core library: If your feature or plugin proves broadly useful and aligns with Data Designer's goals, we'd love to integrate it into the core library! We're happy to discuss whether it's a good fit and how to move forward together.</p> </li> </ol> <p>This approach helps us grow thoughtfully while keeping Data Designer focused and maintainable.</p>"},{"location":"CONTRIBUTING/#submitting-a-feature-request","title":"Submitting a Feature Request","text":"<p>Open a new issue with:</p> <ul> <li>Clear title: Concise description of the feature</li> <li>Use case: Explain what problem this solves and why it's important</li> <li>Proposed solution: Describe how you envision the feature working</li> <li>Alternatives considered: Other approaches you've thought about</li> <li>Examples: Code examples or mockups of how users would interact with the feature</li> <li>Willingness to implement: Are you interested in implementing this yourself?</li> </ul>"},{"location":"CONTRIBUTING/#development-guide","title":"Development Guide","text":"<p>Data Designer uses <code>uv</code> for dependency management. If you don't have uv installed, follow their installation instructions.</p>"},{"location":"CONTRIBUTING/#initial-setup","title":"Initial Setup","text":"<ol> <li> <p>Create or find an issue</p> <p>Before starting work, ensure there's an issue tracking your contribution:</p> <ul> <li>For bug fixes: Search existing issues or create a new one</li> <li>For new features: Open a feature request to discuss the approach first</li> <li>Comment on the issue to let maintainers know you're working on it</li> </ul> </li> <li> <p>Fork and clone the repository</p> <p>Start by forking the Data Designer repository, then clone your fork and add the upstream remote:</p> <pre><code>git clone https://github.com/YOUR_GITHUB_USERNAME/DataDesigner.git\n\ncd DataDesigner\n\ngit remote add upstream https://github.com/NVIDIA-NeMo/DataDesigner.git\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code># Install project with dev dependencies\nmake install-dev\n\n# Or, if you use Jupyter / IPython for development\nmake install-dev-notebooks\n</code></pre> </li> <li> <p>Verify your setup</p> <pre><code>make test &amp;&amp; make check-all\n</code></pre> <p>If no errors are reported, you're ready to develop \ud83d\ude80</p> </li> </ol>"},{"location":"CONTRIBUTING/#making-changes","title":"Making Changes","text":"<ol> <li> <p>Create a feature branch</p> <pre><code>git checkout main\ngit pull upstream main\ngit checkout -b &lt;username&gt;/&lt;type-of-change&gt;/&lt;issue-number&gt;-&lt;short-description&gt;\n</code></pre> <p>Example types of change:</p> <ul> <li><code>feat</code> for new features</li> <li><code>fix</code> for bug fixes</li> <li><code>docs</code> for documentation updates</li> <li><code>test</code> for testing changes</li> <li><code>refactor</code> for code refactoring</li> <li><code>chore</code> for chore tasks</li> <li><code>style</code> for style changes</li> <li><code>perf</code> for performance improvements</li> </ul> <p>Example branch name:</p> <ul> <li><code>johnnygreco/feat/123-add-xyz-generator</code> for a new feature by @johnnygreco, addressing issue #123</li> </ul> </li> <li> <p>Develop your changes</p> <p>Please follow the patterns and conventions used throughout the codebase, as well as those outlined in AGENTS.md.</p> </li> <li> <p>Test and validate</p> <pre><code>make check-all-fix  # Format code and fix linting issues\nmake test           # Run all tests\nmake coverage       # Check test coverage (must be &gt;90%)\n</code></pre> <p>Writing tests: Place tests in tests/ mirroring the source structure. Use fixtures from tests/conftest.py, mock external services with <code>unittest.mock</code> or <code>pytest-httpx</code>, and test both success and failure cases. See AGENTS.md for patterns and examples.</p> </li> <li> <p>Commit your work</p> <p>Write clear, descriptive commit messages, optionally including a brief summary (50 characters or less) and reference issue numbers when applicable (e.g., \"Fixes #123\").</p> <pre><code>git commit -m \"Add XYZ generator for synthetic data\" -m \"Fixes #123\"\n</code></pre> </li> <li> <p>Stay up to date</p> <p>Regularly sync your branch with upstream changes:</p> <pre><code>git fetch upstream\ngit merge upstream/main\n</code></pre> </li> </ol>"},{"location":"CONTRIBUTING/#submitting-changes","title":"Submitting Changes","text":""},{"location":"CONTRIBUTING/#before-submitting","title":"Before Submitting","text":"<p>Ensure your changes meet the following criteria:</p> <ul> <li>All tests pass (<code>make test</code>)</li> <li>Code is formatted and linted (<code>make check-all-fix</code>)</li> <li>New functionality includes tests</li> <li>Documentation is updated (README, docstrings, examples)</li> <li>License headers are present on all new files</li> <li>Commit messages are clear and descriptive</li> </ul>"},{"location":"CONTRIBUTING/#creating-a-pull-request","title":"Creating a Pull Request","text":"<ol> <li> <p>Push your changes to your fork:</p> <pre><code>git push origin &lt;username&gt;/&lt;type-of-change&gt;/&lt;issue-number&gt;-&lt;short-description&gt;\n</code></pre> </li> <li> <p>Open a pull request on GitHub from your fork to the main repository</p> </li> <li> <p>Respond to review feedback update your PR as needed</p> </li> </ol>"},{"location":"CONTRIBUTING/#pull-request-review-process","title":"Pull Request Review Process","text":"<ul> <li>Maintainers will review your PR and may request changes</li> <li>Address feedback by pushing additional commits to your branch</li> <li>Reply to the feedback comment with a link to the commit that addresses it.</li> <li>Once approved, a maintainer will merge your PR</li> <li>Your contribution will be included in the next release!</li> </ul>"},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>Data Designer follows the Contributor Covenant Code of Conduct. We are committed to providing a welcoming and inclusive environment for all contributors.</p> <p>Please read our complete Code of Conduct for full details on our standards and expectations.</p>"},{"location":"CONTRIBUTING/#license-file-headers","title":"License File Headers","text":"<p>All code files that are added to this repository must include the appropriate NVIDIA copyright header:</p> <pre><code># SPDX-FileCopyrightText: Copyright (c) {YEAR} NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n</code></pre> <p>Use <code>make update-license-headers</code> to add headers automatically.</p>"},{"location":"CONTRIBUTING/#signing-off-on-your-work","title":"Signing off on your work","text":"<p>When contributing to this project, you must agree that you have authored 100% of the content, that you have the necessary rights to the content and that the content you contribute may be provided under the project license. All contributors are asked to sign the Data Designer Developer Certificate of Origin (DCO) when submitting their first pull request. The process is automated by a bot that will comment on the pull request. Our DCO is the same as the Linux Foundation requires its contributors to sign.</p> <p>Thank you for contributing to NeMo Data Designer! Your efforts help make synthetic data generation more accessible and powerful for everyone. \ud83c\udfa8\u2728</p>"},{"location":"installation/","title":"Installation","text":"<p>Installing Data Designer is as simple as:</p> pipuv <pre><code>pip install data-designer\n</code></pre> <pre><code>uv add data-designer\n</code></pre>"},{"location":"installation/#development-installation","title":"Development Installation","text":"<p>To install the latest development version from the GitHub repository:</p> pipuv <pre><code>pip install 'git+https://github.com/NVIDIA-NeMo/DataDesigner@main'\n</code></pre> <pre><code>uv add 'git+https://github.com/NVIDIA-NeMo/DataDesigner@main'\n</code></pre>"},{"location":"quick-start/","title":"Quick Start","text":"<p>Get started with Data Designer using the default model providers and configurations. Data Designer ships with built-in model providers and configurations that make it easy to start generating synthetic data immediately.</p>"},{"location":"quick-start/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, you'll need an API key from one of the default providers:</p> <ul> <li>NVIDIA API Key: Get yours from build.nvidia.com</li> <li>OpenAI API Key (optional): Get yours from platform.openai.com</li> </ul> <p>Set your API key as an environment variable:</p> <pre><code>export NVIDIA_API_KEY=\"your-api-key-here\"\n# Or for OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key-here\"\n</code></pre>"},{"location":"quick-start/#example","title":"Example","text":"<p>Below we'll construct a simple Data Designer workflow that generates multilingual greetings.</p> <pre><code>import os\n\nfrom data_designer.essentials import (\n    CategorySamplerParams,\n    DataDesigner,\n    DataDesignerConfigBuilder,\n    InfoType,\n    LLMTextColumnConfig,\n    SamplerColumnConfig,\n    SamplerType,\n)\n\n# Set your API key from build.nvidia.com\n# Skip this step if you've already exported your key to the environemnt variable\nos.environ[\"NVIDIA_API_KEY\"] = \"your-api-key-here\"\n\n# Create a DataDesigner instance\n# This automatically configures the default model providers\ndata_designer = DataDesigner()\n\n# Print out all the model providers available\ndata_designer.info.display(InfoType.MODEL_PROVIDERS)\n\n# Create a config builder\n# This automatically loads the default model configurations\nconfig_builder = DataDesignerConfigBuilder()\n\n# Print out all the model configurations available\nconfig_builder.info.display(InfoType.MODEL_CONFIGS)\n\n# Add a sampler column to randomly select a language\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"language\",\n        sampler_type=SamplerType.CATEGORY,\n        params=CategorySamplerParams(\n            values=[\"English\", \"Spanish\", \"French\", \"German\", \"Italian\"],\n        ),\n    )\n)\n\n# Add an LLM text generation column\n# We'll use the built-in 'nvidia-text' model alias\nconfig_builder.add_column(\n    LLMTextColumnConfig(\n        name=\"greetings\",\n        model_alias=\"nvidia-text\",\n        prompt=\"\"\"Write a casual and formal greeting in '{{language}}' language.\"\"\",\n    )\n)\n\n# Run a preview to generate sample records\npreview_results = data_designer.preview(config_builder=config_builder)\n\n# Display a sample record\npreview_results.display_sample_record()\n</code></pre> <p>\ud83c\udf89 Congratulations, you successfully ran one iteration designing your synthetic data. Follow along to learn more.</p> <p>To learn more about the default providers and model configurations available, see the Default Model Settings guide.</p>"},{"location":"code_reference/column_configs/","title":"Column Configurations","text":"<p>The <code>column_configs</code> module defines configuration objects for all Data Designer column types. Each configuration inherits from SingleColumnConfig, which provides shared arguments like the column <code>name</code>, whether to <code>drop</code> the column after generation, and the <code>column_type</code>.</p> <p><code>column_type</code> is a discriminator field</p> <p>The <code>column_type</code> argument is used to identify column types when deserializing the Data Designer Config from JSON/YAML. It acts as the discriminator in a discriminated union, allowing Pydantic to automatically determine which column configuration class to instantiate.</p> <p>Classes:</p> Name Description <code>ExpressionColumnConfig</code> <p>Configuration for derived columns using Jinja2 expressions.</p> <code>LLMCodeColumnConfig</code> <p>Configuration for code generation columns using Large Language Models.</p> <code>LLMJudgeColumnConfig</code> <p>Configuration for LLM-as-a-judge quality assessment and scoring columns.</p> <code>LLMStructuredColumnConfig</code> <p>Configuration for structured JSON generation columns using Large Language Models.</p> <code>LLMTextColumnConfig</code> <p>Configuration for text generation columns using Large Language Models.</p> <code>SamplerColumnConfig</code> <p>Configuration for columns generated using numerical samplers.</p> <code>Score</code> <p>Configuration for a \"score\" in an LLM judge evaluation.</p> <code>SeedDatasetColumnConfig</code> <p>Configuration for columns sourced from seed datasets.</p> <code>SingleColumnConfig</code> <p>Abstract base class for all single-column configuration types.</p> <code>ValidationColumnConfig</code> <p>Configuration for validation columns that validate existing columns.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.ExpressionColumnConfig","title":"<code>ExpressionColumnConfig</code>","text":"<p>               Bases: <code>SingleColumnConfig</code></p> <p>Configuration for derived columns using Jinja2 expressions.</p> <p>Expression columns compute values by evaluating Jinja2 templates that reference other columns. Useful for transformations, concatenations, conditional logic, and derived features without requiring LLM generation. The expression is evaluated row-by-row.</p> <p>Attributes:</p> Name Type Description <code>expr</code> <code>str</code> <p>Jinja2 expression to evaluate. Can reference other column values using {{ column_name }} syntax. Supports filters, conditionals, and arithmetic. Must be a valid, non-empty Jinja2 template.</p> <code>dtype</code> <code>Literal['int', 'float', 'str', 'bool']</code> <p>Data type to cast the result to. Must be one of \"int\", \"float\", \"str\", or \"bool\". Defaults to \"str\". Type conversion is applied after expression evaluation.</p> <code>column_type</code> <code>Literal['expression']</code> <p>Discriminator field, always \"expression\" for this configuration type.</p> <p>Methods:</p> Name Description <code>assert_expression_valid_jinja</code> <p>Validate that the expression is a valid, non-empty Jinja2 template.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.ExpressionColumnConfig.required_columns","title":"<code>required_columns</code>  <code>property</code>","text":"<p>Returns the columns referenced in the expression template.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.ExpressionColumnConfig.assert_expression_valid_jinja","title":"<code>assert_expression_valid_jinja()</code>","text":"<p>Validate that the expression is a valid, non-empty Jinja2 template.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The validated instance.</p> <p>Raises:</p> Type Description <code>InvalidConfigError</code> <p>If expression is empty or contains invalid Jinja2 syntax.</p> Source code in <code>src/data_designer/config/column_configs.py</code> <pre><code>@model_validator(mode=\"after\")\ndef assert_expression_valid_jinja(self) -&gt; Self:\n    \"\"\"Validate that the expression is a valid, non-empty Jinja2 template.\n\n    Returns:\n        The validated instance.\n\n    Raises:\n        InvalidConfigError: If expression is empty or contains invalid Jinja2 syntax.\n    \"\"\"\n    if not self.expr.strip():\n        raise InvalidConfigError(\n            f\"\ud83d\uded1 Expression column '{self.name}' has an empty or whitespace-only expression. \"\n            f\"Please provide a valid Jinja2 expression (e.g., '{{ column_name }}' or '{{ col1 }} + {{ col2 }}') \"\n            \"or remove this column if not needed.\"\n        )\n    assert_valid_jinja2_template(self.expr)\n    return self\n</code></pre>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.LLMCodeColumnConfig","title":"<code>LLMCodeColumnConfig</code>","text":"<p>               Bases: <code>LLMTextColumnConfig</code></p> <p>Configuration for code generation columns using Large Language Models.</p> <p>Extends LLMTextColumnConfig to generate code snippets in specific programming languages or SQL dialects. The generated code is automatically extracted from markdown code blocks for the specified language. Inherits all prompt templating capabilities.</p> <p>Attributes:</p> Name Type Description <code>code_lang</code> <code>CodeLang</code> <p>Programming language or SQL dialect for code generation. Supported values include: \"python\", \"javascript\", \"typescript\", \"java\", \"kotlin\", \"go\", \"rust\", \"ruby\", \"scala\", \"swift\", \"sql:sqlite\", \"sql:postgres\", \"sql:mysql\", \"sql:tsql\", \"sql:bigquery\", \"sql:ansi\". See CodeLang enum for complete list.</p> <code>column_type</code> <code>Literal['llm-code']</code> <p>Discriminator field, always \"llm-code\" for this configuration type.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.LLMJudgeColumnConfig","title":"<code>LLMJudgeColumnConfig</code>","text":"<p>               Bases: <code>LLMTextColumnConfig</code></p> <p>Configuration for LLM-as-a-judge quality assessment and scoring columns.</p> <p>Extends LLMTextColumnConfig to create judge columns that evaluate and score other generated content based on the defined criteria. Useful for quality assessment, preference ranking, and multi-dimensional evaluation of generated data.</p> <p>Attributes:</p> Name Type Description <code>scores</code> <code>list[Score]</code> <p>List of Score objects defining the evaluation dimensions. Each score represents a different aspect to evaluate (e.g., accuracy, relevance, fluency). Must contain at least one score.</p> <code>column_type</code> <code>Literal['llm-judge']</code> <p>Discriminator field, always \"llm-judge\" for this configuration type.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.LLMStructuredColumnConfig","title":"<code>LLMStructuredColumnConfig</code>","text":"<p>               Bases: <code>LLMTextColumnConfig</code></p> <p>Configuration for structured JSON generation columns using Large Language Models.</p> <p>Extends LLMTextColumnConfig to generate structured data conforming to a specified schema. Uses JSON schema or Pydantic models to define the expected output structure, enabling type-safe and validated structured output generation. Inherits prompt templating capabilities.</p> <p>Attributes:</p> Name Type Description <code>output_format</code> <code>Union[dict, Type[BaseModel]]</code> <p>The schema defining the expected output structure. Can be either: - A Pydantic BaseModel class (recommended) - A JSON schema dictionary</p> <code>column_type</code> <code>Literal['llm-structured']</code> <p>Discriminator field, always \"llm-structured\" for this configuration type.</p> <p>Methods:</p> Name Description <code>validate_output_format</code> <p>Convert Pydantic model to JSON schema if needed.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.LLMStructuredColumnConfig.validate_output_format","title":"<code>validate_output_format()</code>","text":"<p>Convert Pydantic model to JSON schema if needed.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The validated instance with output_format as a JSON schema dict.</p> Source code in <code>src/data_designer/config/column_configs.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_output_format(self) -&gt; Self:\n    \"\"\"Convert Pydantic model to JSON schema if needed.\n\n    Returns:\n        The validated instance with output_format as a JSON schema dict.\n    \"\"\"\n    if not isinstance(self.output_format, dict) and issubclass(self.output_format, BaseModel):\n        self.output_format = self.output_format.model_json_schema()\n    return self\n</code></pre>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.LLMTextColumnConfig","title":"<code>LLMTextColumnConfig</code>","text":"<p>               Bases: <code>SingleColumnConfig</code></p> <p>Configuration for text generation columns using Large Language Models.</p> <p>LLM text columns generate free-form text content using language models via LiteLLM. Prompts support Jinja2 templating to reference values from other columns, enabling context-aware generation. The generated text can optionally include reasoning traces when models support extended thinking.</p> <p>Attributes:</p> Name Type Description <code>prompt</code> <code>str</code> <p>Prompt template for text generation. Supports Jinja2 syntax to reference other columns (e.g., \"Write a story about {{ character_name }}\"). Must be a valid Jinja2 template.</p> <code>model_alias</code> <code>str</code> <p>Alias of the model configuration to use for generation. Must match a model alias defined when initializing the DataDesignerConfigBuilder.</p> <code>system_prompt</code> <code>Optional[str]</code> <p>Optional system prompt to set model behavior and constraints. Also supports Jinja2 templating. If provided, must be a valid Jinja2 template. Do not put any output parsing instructions in the system prompt. Instead, use the appropriate column type for the output you want to generate - e.g., <code>LLMStructuredColumnConfig</code> for structured output, <code>LLMCodeColumnConfig</code> for code.</p> <code>multi_modal_context</code> <code>Optional[list[ImageContext]]</code> <p>Optional list of image contexts for multi-modal generation. Enables vision-capable models to generate text based on image inputs.</p> <code>column_type</code> <code>Literal['llm-text']</code> <p>Discriminator field, always \"llm-text\" for this configuration type.</p> <p>Methods:</p> Name Description <code>assert_prompt_valid_jinja</code> <p>Validate that prompt and system_prompt are valid Jinja2 templates.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.LLMTextColumnConfig.required_columns","title":"<code>required_columns</code>  <code>property</code>","text":"<p>Get columns referenced in the prompt and system_prompt templates.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of unique column names referenced in Jinja2 templates.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.LLMTextColumnConfig.side_effect_columns","title":"<code>side_effect_columns</code>  <code>property</code>","text":"<p>Returns the reasoning trace column, which may be generated alongside the main column.</p> <p>Reasoning traces are only returned if the served model parses and returns reasoning content.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List containing the reasoning trace column name.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.LLMTextColumnConfig.assert_prompt_valid_jinja","title":"<code>assert_prompt_valid_jinja()</code>","text":"<p>Validate that prompt and system_prompt are valid Jinja2 templates.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The validated instance.</p> <p>Raises:</p> Type Description <code>InvalidConfigError</code> <p>If prompt or system_prompt contains invalid Jinja2 syntax.</p> Source code in <code>src/data_designer/config/column_configs.py</code> <pre><code>@model_validator(mode=\"after\")\ndef assert_prompt_valid_jinja(self) -&gt; Self:\n    \"\"\"Validate that prompt and system_prompt are valid Jinja2 templates.\n\n    Returns:\n        The validated instance.\n\n    Raises:\n        InvalidConfigError: If prompt or system_prompt contains invalid Jinja2 syntax.\n    \"\"\"\n    assert_valid_jinja2_template(self.prompt)\n    if self.system_prompt:\n        assert_valid_jinja2_template(self.system_prompt)\n    return self\n</code></pre>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.SamplerColumnConfig","title":"<code>SamplerColumnConfig</code>","text":"<p>               Bases: <code>SingleColumnConfig</code></p> <p>Configuration for columns generated using numerical samplers.</p> <p>Sampler columns provide efficient data generation using numerical samplers for common data types and distributions. Supported samplers include UUID generation, datetime/timedelta sampling, person generation, category / subcategory sampling, and various statistical distributions (uniform, gaussian, binomial, poisson, scipy).</p> <p>Attributes:</p> Name Type Description <code>sampler_type</code> <code>SamplerType</code> <p>Type of sampler to use. Available types include: \"uuid\", \"category\", \"subcategory\", \"uniform\", \"gaussian\", \"bernoulli\", \"bernoulli_mixture\", \"binomial\", \"poisson\", \"scipy\", \"person\", \"datetime\", \"timedelta\".</p> <code>params</code> <code>Annotated[SamplerParamsT, Discriminator(sampler_type)]</code> <p>Parameters specific to the chosen sampler type. Type varies based on the <code>sampler_type</code> (e.g., <code>CategorySamplerParams</code>, <code>UniformSamplerParams</code>, <code>PersonSamplerParams</code>).</p> <code>conditional_params</code> <code>dict[str, Annotated[SamplerParamsT, Discriminator(sampler_type)]]</code> <p>Optional dictionary for conditional parameters. The dict keys are the conditions that must be met (e.g., \"age &gt; 21\") for the conditional parameters to be used. The values of dict are the parameters to use when the condition is met.</p> <code>convert_to</code> <code>Optional[str]</code> <p>Optional type conversion to apply after sampling. Must be one of \"float\", \"int\", or \"str\". Useful for converting numerical samples to strings or other types.</p> <code>column_type</code> <code>Literal['sampler']</code> <p>Discriminator field, always \"sampler\" for this configuration type.</p> <p>Displaying available samplers and their parameters</p> <p>The config builder has an <code>info</code> attribute that can be used to display the available samplers and their parameters: <pre><code>config_builder.info.display(\"samplers\")\n</code></pre></p> <p>Methods:</p> Name Description <code>inject_sampler_type_into_params</code> <p>Inject sampler_type into params dict to enable discriminated union resolution.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.SamplerColumnConfig.inject_sampler_type_into_params","title":"<code>inject_sampler_type_into_params(data)</code>  <code>classmethod</code>","text":"<p>Inject sampler_type into params dict to enable discriminated union resolution.</p> <p>This allows users to pass params as a simple dict without the sampler_type field, which will be automatically added based on the outer sampler_type field.</p> Source code in <code>src/data_designer/config/column_configs.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef inject_sampler_type_into_params(cls, data: dict) -&gt; dict:\n    \"\"\"Inject sampler_type into params dict to enable discriminated union resolution.\n\n    This allows users to pass params as a simple dict without the sampler_type field,\n    which will be automatically added based on the outer sampler_type field.\n    \"\"\"\n    if isinstance(data, dict):\n        sampler_type = data.get(\"sampler_type\")\n        params = data.get(\"params\")\n\n        # If params is a dict and doesn't have sampler_type, inject it\n        if sampler_type and isinstance(params, dict) and \"sampler_type\" not in params:\n            data[\"params\"] = {\"sampler_type\": sampler_type, **params}\n\n        # Handle conditional_params similarly\n        conditional_params = data.get(\"conditional_params\")\n        if conditional_params and isinstance(conditional_params, dict):\n            for condition, cond_params in conditional_params.items():\n                if isinstance(cond_params, dict) and \"sampler_type\" not in cond_params:\n                    data[\"conditional_params\"][condition] = {\"sampler_type\": sampler_type, **cond_params}\n\n    return data\n</code></pre>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.Score","title":"<code>Score</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Configuration for a \"score\" in an LLM judge evaluation.</p> <p>Defines a single scoring criterion with its possible values and descriptions. Multiple Score objects can be combined in an LLMJudgeColumnConfig to create multi-dimensional quality assessments.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>A clear, concise name for this scoring dimension (e.g., \"Relevance\", \"Fluency\").</p> <code>description</code> <code>str</code> <p>An informative and detailed assessment guide explaining how to evaluate this dimension. Should provide clear criteria for scoring.</p> <code>options</code> <code>dict[Union[int, str], str]</code> <p>Dictionary mapping score values to their descriptions. Keys can be integers (e.g., 1-5 scale) or strings (e.g., \"Poor\", \"Good\", \"Excellent\"). Values are descriptions explaining what each score level means.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.SeedDatasetColumnConfig","title":"<code>SeedDatasetColumnConfig</code>","text":"<p>               Bases: <code>SingleColumnConfig</code></p> <p>Configuration for columns sourced from seed datasets.</p> <p>This config marks columns that come from seed data. It is typically created automatically when calling <code>with_seed_dataset()</code> on the builder, rather than being instantiated directly by users.</p> <p>Attributes:</p> Name Type Description <code>column_type</code> <code>Literal['seed-dataset']</code> <p>Discriminator field, always \"seed-dataset\" for this configuration type.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.SingleColumnConfig","title":"<code>SingleColumnConfig</code>","text":"<p>               Bases: <code>ConfigBase</code>, <code>ABC</code></p> <p>Abstract base class for all single-column configuration types.</p> <p>This class serves as the foundation for all column configurations in DataDesigner, defining shared fields and properties across all column types.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Unique name of the column to be generated.</p> <code>drop</code> <code>bool</code> <p>If True, the column will be generated but removed from the final dataset. Useful for intermediate columns that are dependencies for other columns.</p> <code>column_type</code> <code>str</code> <p>Discriminator field that identifies the specific column type. Subclasses must override this field to specify the column type with a <code>Literal</code> value.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.SingleColumnConfig.required_columns","title":"<code>required_columns</code>  <code>property</code>","text":"<p>Returns a list of column names that must exist before this column can be generated.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names that this column depends on. Empty list indicates</p> <code>list[str]</code> <p>no dependencies. Override in subclasses to specify dependencies.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.SingleColumnConfig.side_effect_columns","title":"<code>side_effect_columns</code>  <code>property</code>","text":"<p>Returns a list of additional columns that this column will create as a side effect.</p> <p>Some column types generate additional metadata or auxiliary columns alongside the primary column (e.g., reasoning traces for LLM columns).</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names that this column will create as a side effect. Empty list</p> <code>list[str]</code> <p>indicates no side effect columns. Override in subclasses to specify side effects.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.ValidationColumnConfig","title":"<code>ValidationColumnConfig</code>","text":"<p>               Bases: <code>SingleColumnConfig</code></p> <p>Configuration for validation columns that validate existing columns.</p> <p>Validation columns execute validation logic against specified target columns and return structured results indicating pass/fail status with validation details. Supports multiple validation strategies: code execution (Python/SQL), local callable functions (library only), and remote HTTP endpoints.</p> <p>Attributes:</p> Name Type Description <code>target_columns</code> <code>list[str]</code> <p>List of column names to validate. These columns are passed to the validator for validation. All target columns must exist in the dataset before validation runs.</p> <code>validator_type</code> <code>ValidatorType</code> <p>The type of validator to use. Options: - \"code\": Execute code (Python or SQL) for validation. The code receives a   DataFrame with target columns and must return a DataFrame with validation results. - \"local_callable\": Call a local Python function with the data. Only supported   when running DataDesigner locally. - \"remote\": Send data to a remote HTTP endpoint for validation. Useful for</p> <code>validator_params</code> <code>ValidatorParamsT</code> <p>Parameters specific to the validator type. Type varies by validator: - CodeValidatorParams: Specifies code language (python or SQL dialect like   \"sql:postgres\", \"sql:mysql\"). - LocalCallableValidatorParams: Provides validation function (Callable[[pd.DataFrame],   pd.DataFrame]) and optional output schema for validation results. - RemoteValidatorParams: Configures endpoint URL, HTTP timeout, retry behavior   (max_retries, retry_backoff), and parallel request limits (max_parallel_requests).</p> <code>batch_size</code> <code>int</code> <p>Number of records to process in each validation batch. Defaults to 10. Larger batches are more efficient but use more memory. Adjust based on validator complexity and available resources.</p> <code>column_type</code> <code>Literal['validation']</code> <p>Discriminator field, always \"validation\" for this configuration type.</p>"},{"location":"code_reference/column_configs/#data_designer.config.column_configs.ValidationColumnConfig.required_columns","title":"<code>required_columns</code>  <code>property</code>","text":"<p>Returns the columns that need to be validated.</p>"},{"location":"code_reference/config_builder/","title":"Data Designer's Config Builder","text":"<p>The <code>config_builder</code> module provides a high-level interface for constructing Data Designer configurations through the DataDesignerConfigBuilder class, enabling programmatic creation of DataDesignerConfig objects by incrementally adding column configurations, constraints, processors, and profilers.</p> <p>You can use the builder to create Data Designer configurations from scratch or from existing configurations stored in YAML/JSON files via <code>from_config()</code>. The builder includes validation capabilities to catch configuration errors early and can work with seed datasets from local sources or external datastores. Once configured, use <code>build()</code> to generate the final configuration object or <code>write_config()</code> to serialize it to disk.</p> <p>Model configs are required</p> <p>DataDesignerConfigBuilder requires a list of model configurations at initialization. This tells the builder which model aliases can be referenced by LLM-generated columns (such as <code>LLMTextColumnConfig</code>, <code>LLMCodeColumnConfig</code>, <code>LLMStructuredColumnConfig</code>, and <code>LLMJudgeColumnConfig</code>). Each model configuration specifies the model alias, model provider, model ID, and inference parameters that will be used during data generation.</p> <p>Classes:</p> Name Description <code>BuilderConfig</code> <p>Configuration container for Data Designer builder.</p> <code>DataDesignerConfigBuilder</code> <p>Config builder for Data Designer configurations.</p>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.BuilderConfig","title":"<code>BuilderConfig</code>","text":"<p>               Bases: <code>ExportableConfigBase</code></p> <p>Configuration container for Data Designer builder.</p> <p>This class holds the main Data Designer configuration along with optional datastore settings needed for seed dataset operations.</p> <p>Attributes:</p> Name Type Description <code>data_designer</code> <code>DataDesignerConfig</code> <p>The main Data Designer configuration containing columns, constraints, profilers, and other settings.</p> <code>datastore_settings</code> <code>Optional[DatastoreSettings]</code> <p>Optional datastore settings for accessing external datasets.</p>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder","title":"<code>DataDesignerConfigBuilder(model_configs=None)</code>","text":"<p>Config builder for Data Designer configurations.</p> <p>This class provides a high-level interface for building Data Designer configurations.</p> <p>Initialize a new DataDesignerConfigBuilder instance.</p> <p>Parameters:</p> Name Type Description Default <code>model_configs</code> <code>Optional[Union[list[ModelConfig], str, Path]]</code> <p>Model configurations. Can be: - None to use default model configurations in local mode - A list of ModelConfig objects - A string or Path to a model configuration file</p> <code>None</code> <p>Methods:</p> Name Description <code>add_column</code> <p>Add a Data Designer column configuration to the current Data Designer configuration.</p> <code>add_constraint</code> <p>Add a constraint to the current Data Designer configuration.</p> <code>add_model_config</code> <p>Add a model configuration to the current Data Designer configuration.</p> <code>add_processor</code> <p>Add a processor to the current Data Designer configuration.</p> <code>add_profiler</code> <p>Add a profiler to the current Data Designer configuration.</p> <code>build</code> <p>Build a DataDesignerConfig instance based on the current builder configuration.</p> <code>delete_column</code> <p>Delete the column with the given name.</p> <code>delete_constraints</code> <p>Delete all constraints for the given target column.</p> <code>delete_model_config</code> <p>Delete a model configuration from the current Data Designer configuration by alias.</p> <code>from_config</code> <p>Create a DataDesignerConfigBuilder from an existing configuration.</p> <code>get_builder_config</code> <p>Get the builder config for the current Data Designer configuration.</p> <code>get_column_config</code> <p>Get a column configuration by name.</p> <code>get_column_configs</code> <p>Get all column configurations.</p> <code>get_columns_excluding_type</code> <p>Get all column configurations excluding the specified type.</p> <code>get_columns_of_type</code> <p>Get all column configurations of the specified type.</p> <code>get_constraints</code> <p>Get all constraints for the given target column.</p> <code>get_llm_gen_columns</code> <p>Get all LLM-generated column configurations.</p> <code>get_processor_configs</code> <p>Get processor configuration objects.</p> <code>get_profilers</code> <p>Get all profilers.</p> <code>get_seed_config</code> <p>Get the seed config for the current Data Designer configuration.</p> <code>get_seed_datastore_settings</code> <p>Get most recent datastore settings for the current Data Designer configuration.</p> <code>num_columns_of_type</code> <p>Get the count of columns of the specified type.</p> <code>set_seed_datastore_settings</code> <p>Set the datastore settings for the seed dataset.</p> <code>validate</code> <p>Validate the current Data Designer configuration.</p> <code>with_seed_dataset</code> <p>Add a seed dataset to the current Data Designer configuration.</p> <code>write_config</code> <p>Write the current configuration to a file.</p> <p>Attributes:</p> Name Type Description <code>allowed_references</code> <code>list[str]</code> <p>Get all referenceable variables allowed in prompt templates and expressions.</p> <code>info</code> <code>ConfigBuilderInfo</code> <p>Get the ConfigBuilderInfo object for this builder.</p> <code>model_configs</code> <code>list[ModelConfig]</code> <p>Get the model configurations for this builder.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def __init__(self, model_configs: Optional[Union[list[ModelConfig], str, Path]] = None):\n    \"\"\"Initialize a new DataDesignerConfigBuilder instance.\n\n    Args:\n        model_configs: Model configurations. Can be:\n            - None to use default model configurations in local mode\n            - A list of ModelConfig objects\n            - A string or Path to a model configuration file\n    \"\"\"\n    self._column_configs = {}\n    self._model_configs = _load_model_configs(model_configs)\n    self._processor_configs: list[ProcessorConfig] = []\n    self._seed_config: Optional[SeedConfig] = None\n    self._constraints: list[ColumnConstraintT] = []\n    self._profilers: list[ColumnProfilerConfigT] = []\n    self._datastore_settings: Optional[DatastoreSettings] = None\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.allowed_references","title":"<code>allowed_references</code>  <code>property</code>","text":"<p>Get all referenceable variables allowed in prompt templates and expressions.</p> <p>This includes all column names and their side effect columns that can be referenced in prompt templates and expressions within the configuration.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of variable names that can be referenced in templates and expressions.</p>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.info","title":"<code>info</code>  <code>property</code>","text":"<p>Get the ConfigBuilderInfo object for this builder.</p> <p>Returns:</p> Type Description <code>ConfigBuilderInfo</code> <p>An object containing information about the configuration.</p>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.model_configs","title":"<code>model_configs</code>  <code>property</code>","text":"<p>Get the model configurations for this builder.</p> <p>Returns:</p> Type Description <code>list[ModelConfig]</code> <p>A list of ModelConfig objects used for data generation.</p>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.add_column","title":"<code>add_column(column_config=None, *, name=None, column_type=None, **kwargs)</code>","text":"<p>Add a Data Designer column configuration to the current Data Designer configuration.</p> <p>If no column config object is provided, you must provide the <code>name</code>, <code>column_type</code>, and any additional keyword arguments that are required by the column config constructor.</p> <p>Parameters:</p> Name Type Description Default <code>column_config</code> <code>Optional[ColumnConfigT]</code> <p>Data Designer column config object to add.</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>Name of the column to add. This is only used if <code>column_config</code> is not provided.</p> <code>None</code> <code>column_type</code> <code>Optional[DataDesignerColumnType]</code> <p>Column type to add. This is only used if <code>column_config</code> is not provided.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the column constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Self</code> <p>The current Data Designer config builder instance.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def add_column(\n    self,\n    column_config: Optional[ColumnConfigT] = None,\n    *,\n    name: Optional[str] = None,\n    column_type: Optional[DataDesignerColumnType] = None,\n    **kwargs,\n) -&gt; Self:\n    \"\"\"Add a Data Designer column configuration to the current Data Designer configuration.\n\n    If no column config object is provided, you must provide the `name`, `column_type`, and any\n    additional keyword arguments that are required by the column config constructor.\n\n    Args:\n        column_config: Data Designer column config object to add.\n        name: Name of the column to add. This is only used if `column_config` is not provided.\n        column_type: Column type to add. This is only used if `column_config` is not provided.\n        **kwargs: Additional keyword arguments to pass to the column constructor.\n\n    Returns:\n        The current Data Designer config builder instance.\n    \"\"\"\n    if column_config is None:\n        if name is None or column_type is None:\n            raise BuilderConfigurationError(\n                \"\ud83d\uded1 You must provide either a 'column_config' object or 'name' *and* 'column_type' \"\n                f\"with additional keyword arguments. You provided {column_config=}, {name=}, and {column_type=}.\"\n            )\n        column_config = get_column_config_from_kwargs(name=name, column_type=column_type, **kwargs)\n\n    allowed_column_configs = ColumnConfigT.__args__\n    if not any(isinstance(column_config, t) for t in allowed_column_configs):\n        raise InvalidColumnTypeError(\n            f\"\ud83d\uded1 Invalid column config object: '{column_config}'. Valid column config options are: \"\n            f\"{', '.join([t.__name__ for t in allowed_column_configs])}\"\n        )\n\n    self._column_configs[column_config.name] = column_config\n    return self\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.add_constraint","title":"<code>add_constraint(constraint=None, *, constraint_type=None, **kwargs)</code>","text":"<p>Add a constraint to the current Data Designer configuration.</p> <p>Currently, constraints are only supported for numerical samplers.</p> <p>You can either provide a constraint object directly, or provide a constraint type and additional keyword arguments to construct the constraint object. Valid constraint types are:     - \"scalar_inequality\": Constraint between a column and a scalar value.     - \"column_inequality\": Constraint between two columns.</p> <p>Parameters:</p> Name Type Description Default <code>constraint</code> <code>Optional[ColumnConstraintT]</code> <p>Constraint object to add.</p> <code>None</code> <code>constraint_type</code> <code>Optional[ConstraintType]</code> <p>Constraint type to add. Ignored when <code>constraint</code> is provided.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the constraint constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Self</code> <p>The current Data Designer config builder instance.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def add_constraint(\n    self,\n    constraint: Optional[ColumnConstraintT] = None,\n    *,\n    constraint_type: Optional[ConstraintType] = None,\n    **kwargs,\n) -&gt; Self:\n    \"\"\"Add a constraint to the current Data Designer configuration.\n\n    Currently, constraints are only supported for numerical samplers.\n\n    You can either provide a constraint object directly, or provide a constraint type and\n    additional keyword arguments to construct the constraint object. Valid constraint types are:\n        - \"scalar_inequality\": Constraint between a column and a scalar value.\n        - \"column_inequality\": Constraint between two columns.\n\n    Args:\n        constraint: Constraint object to add.\n        constraint_type: Constraint type to add. Ignored when `constraint` is provided.\n        **kwargs: Additional keyword arguments to pass to the constraint constructor.\n\n    Returns:\n        The current Data Designer config builder instance.\n    \"\"\"\n    if constraint is None:\n        if constraint_type is None:\n            raise BuilderConfigurationError(\n                \"\ud83d\uded1 You must provide either a 'constraint' object or 'constraint_type' \"\n                \"with additional keyword arguments.\"\n            )\n        try:\n            constraint_type = ConstraintType(constraint_type)\n        except Exception:\n            raise BuilderConfigurationError(\n                f\"\ud83d\uded1 Invalid constraint type: {constraint_type}. Valid options are: \"\n                f\"{', '.join([t.value for t in ConstraintType])}\"\n            )\n        if constraint_type == ConstraintType.SCALAR_INEQUALITY:\n            constraint = ScalarInequalityConstraint(**kwargs)\n        elif constraint_type == ConstraintType.COLUMN_INEQUALITY:\n            constraint = ColumnInequalityConstraint(**kwargs)\n\n    allowed_constraint_types = ColumnConstraintT.__args__\n    if not any(isinstance(constraint, t) for t in allowed_constraint_types):\n        raise BuilderConfigurationError(\n            \"\ud83d\uded1 Invalid constraint object. Valid constraint options are: \"\n            f\"{', '.join([t.__name__ for t in allowed_constraint_types])}\"\n        )\n\n    self._constraints.append(constraint)\n    return self\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.add_model_config","title":"<code>add_model_config(model_config)</code>","text":"<p>Add a model configuration to the current Data Designer configuration.</p> <p>Parameters:</p> Name Type Description Default <code>model_config</code> <code>ModelConfig</code> <p>The model configuration to add.</p> required Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def add_model_config(self, model_config: ModelConfig) -&gt; Self:\n    \"\"\"Add a model configuration to the current Data Designer configuration.\n\n    Args:\n        model_config: The model configuration to add.\n    \"\"\"\n    if model_config.alias in [mc.alias for mc in self._model_configs]:\n        raise BuilderConfigurationError(\n            f\"\ud83d\uded1 Model configuration with alias {model_config.alias} already exists. Please delete the existing model configuration or choose a different alias.\"\n        )\n    self._model_configs.append(model_config)\n    return self\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.add_processor","title":"<code>add_processor(processor_config=None, *, processor_type=None, **kwargs)</code>","text":"<p>Add a processor to the current Data Designer configuration.</p> <p>You can either provide a processor config object directly, or provide a processor type and additional keyword arguments to construct the processor config object.</p> <p>Parameters:</p> Name Type Description Default <code>processor_config</code> <code>Optional[ProcessorConfig]</code> <p>The processor configuration object to add.</p> <code>None</code> <code>processor_type</code> <code>Optional[ProcessorType]</code> <p>The type of processor to add.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the processor constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Self</code> <p>The current Data Designer config builder instance.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def add_processor(\n    self,\n    processor_config: Optional[ProcessorConfig] = None,\n    *,\n    processor_type: Optional[ProcessorType] = None,\n    **kwargs,\n) -&gt; Self:\n    \"\"\"Add a processor to the current Data Designer configuration.\n\n    You can either provide a processor config object directly, or provide a processor type and\n    additional keyword arguments to construct the processor config object.\n\n    Args:\n        processor_config: The processor configuration object to add.\n        processor_type: The type of processor to add.\n        **kwargs: Additional keyword arguments to pass to the processor constructor.\n\n    Returns:\n        The current Data Designer config builder instance.\n    \"\"\"\n    if processor_config is None:\n        if processor_type is None:\n            raise BuilderConfigurationError(\n                \"\ud83d\uded1 You must provide either a 'processor_config' object or 'processor_type' \"\n                \"with additional keyword arguments.\"\n            )\n        processor_config = get_processor_config_from_kwargs(processor_type=processor_type, **kwargs)\n\n    # Checks elsewhere fail if DropColumnsProcessor drops a column but it is not marked for drop\n    if processor_config.processor_type == ProcessorType.DROP_COLUMNS:\n        for column in processor_config.column_names:\n            if column in self._column_configs:\n                self._column_configs[column].drop = True\n\n    self._processor_configs.append(processor_config)\n    return self\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.add_profiler","title":"<code>add_profiler(profiler_config)</code>","text":"<p>Add a profiler to the current Data Designer configuration.</p> <p>Parameters:</p> Name Type Description Default <code>profiler_config</code> <code>ColumnProfilerConfigT</code> <p>The profiler configuration object to add.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The current Data Designer config builder instance.</p> <p>Raises:</p> Type Description <code>BuilderConfigurationError</code> <p>If the profiler configuration is of an invalid type.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def add_profiler(self, profiler_config: ColumnProfilerConfigT) -&gt; Self:\n    \"\"\"Add a profiler to the current Data Designer configuration.\n\n    Args:\n        profiler_config: The profiler configuration object to add.\n\n    Returns:\n        The current Data Designer config builder instance.\n\n    Raises:\n        BuilderConfigurationError: If the profiler configuration is of an invalid type.\n    \"\"\"\n    if not isinstance(profiler_config, ColumnProfilerConfigT):\n        if hasattr(ColumnProfilerConfigT, \"__args__\"):\n            valid_options = \", \".join([t.__name__ for t in ColumnProfilerConfigT.__args__])\n        else:\n            valid_options = ColumnProfilerConfigT.__name__\n        raise BuilderConfigurationError(f\"\ud83d\uded1 Invalid profiler object. Valid profiler options are: {valid_options}\")\n    self._profilers.append(profiler_config)\n    return self\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.build","title":"<code>build(*, skip_validation=False, raise_exceptions=False)</code>","text":"<p>Build a DataDesignerConfig instance based on the current builder configuration.</p> <p>Parameters:</p> Name Type Description Default <code>skip_validation</code> <code>bool</code> <p>Whether to skip validation of the configuration.</p> <code>False</code> <code>raise_exceptions</code> <code>bool</code> <p>Whether to raise an exception if the configuration is invalid.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataDesignerConfig</code> <p>The current Data Designer config object.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def build(self, *, skip_validation: bool = False, raise_exceptions: bool = False) -&gt; DataDesignerConfig:\n    \"\"\"Build a DataDesignerConfig instance based on the current builder configuration.\n\n    Args:\n        skip_validation: Whether to skip validation of the configuration.\n        raise_exceptions: Whether to raise an exception if the configuration is invalid.\n\n    Returns:\n        The current Data Designer config object.\n    \"\"\"\n    if not skip_validation:\n        self.validate(raise_exceptions=raise_exceptions)\n\n    return DataDesignerConfig(\n        model_configs=self._model_configs,\n        seed_config=self._seed_config,\n        columns=list(self._column_configs.values()),\n        constraints=self._constraints or None,\n        profilers=self._profilers or None,\n        processors=self._processor_configs or None,\n    )\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.delete_column","title":"<code>delete_column(column_name)</code>","text":"<p>Delete the column with the given name.</p> <p>Parameters:</p> Name Type Description Default <code>column_name</code> <code>str</code> <p>Name of the column to delete.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The current Data Designer config builder instance.</p> <p>Raises:</p> Type Description <code>BuilderConfigurationError</code> <p>If trying to delete a seed dataset column.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def delete_column(self, column_name: str) -&gt; Self:\n    \"\"\"Delete the column with the given name.\n\n    Args:\n        column_name: Name of the column to delete.\n\n    Returns:\n        The current Data Designer config builder instance.\n\n    Raises:\n        BuilderConfigurationError: If trying to delete a seed dataset column.\n    \"\"\"\n    if isinstance(self._column_configs.get(column_name), SeedDatasetColumnConfig):\n        raise BuilderConfigurationError(\"Seed columns cannot be deleted. Please update the seed dataset instead.\")\n    self._column_configs.pop(column_name, None)\n    return self\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.delete_constraints","title":"<code>delete_constraints(target_column)</code>","text":"<p>Delete all constraints for the given target column.</p> <p>Parameters:</p> Name Type Description Default <code>target_column</code> <code>str</code> <p>Name of the column to remove constraints for.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The current Data Designer config builder instance.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def delete_constraints(self, target_column: str) -&gt; Self:\n    \"\"\"Delete all constraints for the given target column.\n\n    Args:\n        target_column: Name of the column to remove constraints for.\n\n    Returns:\n        The current Data Designer config builder instance.\n    \"\"\"\n    self._constraints = [c for c in self._constraints if c.target_column != target_column]\n    return self\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.delete_model_config","title":"<code>delete_model_config(alias)</code>","text":"<p>Delete a model configuration from the current Data Designer configuration by alias.</p> <p>Parameters:</p> Name Type Description Default <code>alias</code> <code>str</code> <p>The alias of the model configuration to delete.</p> required Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def delete_model_config(self, alias: str) -&gt; Self:\n    \"\"\"Delete a model configuration from the current Data Designer configuration by alias.\n\n    Args:\n        alias: The alias of the model configuration to delete.\n    \"\"\"\n    self._model_configs = [mc for mc in self._model_configs if mc.alias != alias]\n    if len(self._model_configs) == 0:\n        logger.warning(\n            f\"\u26a0\ufe0f No model configurations found after deleting model configuration with alias {alias}. Please add a model configuration before building the configuration.\"\n        )\n    return self\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.from_config","title":"<code>from_config(config)</code>  <code>classmethod</code>","text":"<p>Create a DataDesignerConfigBuilder from an existing configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Union[dict, str, Path, BuilderConfig]</code> <p>Configuration source. Can be: - A dictionary containing the configuration - A string or Path to a YAML/JSON configuration file - A BuilderConfig object</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new instance populated with the configuration from the provided source.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the config format is invalid.</p> <code>ValidationError</code> <p>If the builder config loaded from the config is invalid.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>@classmethod\ndef from_config(cls, config: Union[dict, str, Path, BuilderConfig]) -&gt; Self:\n    \"\"\"Create a DataDesignerConfigBuilder from an existing configuration.\n\n    Args:\n        config: Configuration source. Can be:\n            - A dictionary containing the configuration\n            - A string or Path to a YAML/JSON configuration file\n            - A BuilderConfig object\n\n    Returns:\n        A new instance populated with the configuration from the provided source.\n\n    Raises:\n        ValueError: If the config format is invalid.\n        ValidationError: If the builder config loaded from the config is invalid.\n    \"\"\"\n    if isinstance(config, BuilderConfig):\n        builder_config = config\n    else:\n        json_config = json.loads(serialize_data(smart_load_yaml(config)))\n        builder_config = BuilderConfig.model_validate(json_config)\n\n    builder = cls(model_configs=builder_config.data_designer.model_configs)\n    config = builder_config.data_designer\n\n    for col in config.columns:\n        builder.add_column(col)\n\n    for constraint in config.constraints or []:\n        builder.add_constraint(constraint=constraint)\n\n    if config.seed_config:\n        if builder_config.datastore_settings is None:\n            if can_run_data_designer_locally():\n                seed_dataset_reference = LocalSeedDatasetReference(dataset=config.seed_config.dataset)\n            else:\n                raise BuilderConfigurationError(\"\ud83d\uded1 Datastore settings are required.\")\n        else:\n            seed_dataset_reference = DatastoreSeedDatasetReference(\n                dataset=config.seed_config.dataset,\n                datastore_settings=builder_config.datastore_settings,\n            )\n            builder.set_seed_datastore_settings(builder_config.datastore_settings)\n        builder.with_seed_dataset(\n            seed_dataset_reference,\n            sampling_strategy=config.seed_config.sampling_strategy,\n            selection_strategy=config.seed_config.selection_strategy,\n        )\n\n    return builder\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.get_builder_config","title":"<code>get_builder_config()</code>","text":"<p>Get the builder config for the current Data Designer configuration.</p> <p>Returns:</p> Type Description <code>BuilderConfig</code> <p>The builder config.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def get_builder_config(self) -&gt; BuilderConfig:\n    \"\"\"Get the builder config for the current Data Designer configuration.\n\n    Returns:\n        The builder config.\n    \"\"\"\n    return BuilderConfig(data_designer=self.build(), datastore_settings=self._datastore_settings)\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.get_column_config","title":"<code>get_column_config(name)</code>","text":"<p>Get a column configuration by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the column to retrieve the config for.</p> required <p>Returns:</p> Type Description <code>ColumnConfigT</code> <p>The column configuration object.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If no column with the given name exists.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def get_column_config(self, name: str) -&gt; ColumnConfigT:\n    \"\"\"Get a column configuration by name.\n\n    Args:\n        name: Name of the column to retrieve the config for.\n\n    Returns:\n        The column configuration object.\n\n    Raises:\n        KeyError: If no column with the given name exists.\n    \"\"\"\n    return self._column_configs[name]\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.get_column_configs","title":"<code>get_column_configs()</code>","text":"<p>Get all column configurations.</p> <p>Returns:</p> Type Description <code>list[ColumnConfigT]</code> <p>A list of all column configuration objects.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def get_column_configs(self) -&gt; list[ColumnConfigT]:\n    \"\"\"Get all column configurations.\n\n    Returns:\n        A list of all column configuration objects.\n    \"\"\"\n    return list(self._column_configs.values())\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.get_columns_excluding_type","title":"<code>get_columns_excluding_type(column_type)</code>","text":"<p>Get all column configurations excluding the specified type.</p> <p>Parameters:</p> Name Type Description Default <code>column_type</code> <code>DataDesignerColumnType</code> <p>The type of columns to exclude.</p> required <p>Returns:</p> Type Description <code>list[ColumnConfigT]</code> <p>A list of column configurations that do not match the specified type.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def get_columns_excluding_type(self, column_type: DataDesignerColumnType) -&gt; list[ColumnConfigT]:\n    \"\"\"Get all column configurations excluding the specified type.\n\n    Args:\n        column_type: The type of columns to exclude.\n\n    Returns:\n        A list of column configurations that do not match the specified type.\n    \"\"\"\n    column_type = resolve_string_enum(column_type, DataDesignerColumnType)\n    return [c for c in self._column_configs.values() if c.column_type != column_type]\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.get_columns_of_type","title":"<code>get_columns_of_type(column_type)</code>","text":"<p>Get all column configurations of the specified type.</p> <p>Parameters:</p> Name Type Description Default <code>column_type</code> <code>DataDesignerColumnType</code> <p>The type of columns to filter by.</p> required <p>Returns:</p> Type Description <code>list[ColumnConfigT]</code> <p>A list of column configurations matching the specified type.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def get_columns_of_type(self, column_type: DataDesignerColumnType) -&gt; list[ColumnConfigT]:\n    \"\"\"Get all column configurations of the specified type.\n\n    Args:\n        column_type: The type of columns to filter by.\n\n    Returns:\n        A list of column configurations matching the specified type.\n    \"\"\"\n    column_type = resolve_string_enum(column_type, DataDesignerColumnType)\n    return [c for c in self._column_configs.values() if c.column_type == column_type]\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.get_constraints","title":"<code>get_constraints(target_column)</code>","text":"<p>Get all constraints for the given target column.</p> <p>Parameters:</p> Name Type Description Default <code>target_column</code> <code>str</code> <p>Name of the column to get constraints for.</p> required <p>Returns:</p> Type Description <code>list[ColumnConstraintT]</code> <p>A list of constraint objects targeting the specified column.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def get_constraints(self, target_column: str) -&gt; list[ColumnConstraintT]:\n    \"\"\"Get all constraints for the given target column.\n\n    Args:\n        target_column: Name of the column to get constraints for.\n\n    Returns:\n        A list of constraint objects targeting the specified column.\n    \"\"\"\n    return [c for c in self._constraints if c.target_column == target_column]\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.get_llm_gen_columns","title":"<code>get_llm_gen_columns()</code>","text":"<p>Get all LLM-generated column configurations.</p> <p>Returns:</p> Type Description <code>list[ColumnConfigT]</code> <p>A list of column configurations that use LLM generation.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def get_llm_gen_columns(self) -&gt; list[ColumnConfigT]:\n    \"\"\"Get all LLM-generated column configurations.\n\n    Returns:\n        A list of column configurations that use LLM generation.\n    \"\"\"\n    return [c for c in self._column_configs.values() if column_type_is_llm_generated(c.column_type)]\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.get_processor_configs","title":"<code>get_processor_configs()</code>","text":"<p>Get processor configuration objects.</p> <p>Returns:</p> Type Description <code>dict[BuildStage, list[ProcessorConfig]]</code> <p>A dictionary of processor configuration objects by dataset builder stage.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def get_processor_configs(self) -&gt; dict[BuildStage, list[ProcessorConfig]]:\n    \"\"\"Get processor configuration objects.\n\n    Returns:\n        A dictionary of processor configuration objects by dataset builder stage.\n    \"\"\"\n    return self._processor_configs\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.get_profilers","title":"<code>get_profilers()</code>","text":"<p>Get all profilers.</p> <p>Returns:</p> Type Description <code>list[ColumnProfilerConfigT]</code> <p>A list of profiler configuration objects.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def get_profilers(self) -&gt; list[ColumnProfilerConfigT]:\n    \"\"\"Get all profilers.\n\n    Returns:\n        A list of profiler configuration objects.\n    \"\"\"\n    return self._profilers\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.get_seed_config","title":"<code>get_seed_config()</code>","text":"<p>Get the seed config for the current Data Designer configuration.</p> <p>Returns:</p> Type Description <code>Optional[SeedConfig]</code> <p>The seed config if configured, None otherwise.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def get_seed_config(self) -&gt; Optional[SeedConfig]:\n    \"\"\"Get the seed config for the current Data Designer configuration.\n\n    Returns:\n        The seed config if configured, None otherwise.\n    \"\"\"\n    return self._seed_config\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.get_seed_datastore_settings","title":"<code>get_seed_datastore_settings()</code>","text":"<p>Get most recent datastore settings for the current Data Designer configuration.</p> <p>Returns:</p> Type Description <code>Optional[DatastoreSettings]</code> <p>The datastore settings if configured, None otherwise.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def get_seed_datastore_settings(self) -&gt; Optional[DatastoreSettings]:\n    \"\"\"Get most recent datastore settings for the current Data Designer configuration.\n\n    Returns:\n        The datastore settings if configured, None otherwise.\n    \"\"\"\n    return None if not self._datastore_settings else DatastoreSettings.model_validate(self._datastore_settings)\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.num_columns_of_type","title":"<code>num_columns_of_type(column_type)</code>","text":"<p>Get the count of columns of the specified type.</p> <p>Parameters:</p> Name Type Description Default <code>column_type</code> <code>DataDesignerColumnType</code> <p>The type of columns to count.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The number of columns matching the specified type.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def num_columns_of_type(self, column_type: DataDesignerColumnType) -&gt; int:\n    \"\"\"Get the count of columns of the specified type.\n\n    Args:\n        column_type: The type of columns to count.\n\n    Returns:\n        The number of columns matching the specified type.\n    \"\"\"\n    return len(self.get_columns_of_type(column_type))\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.set_seed_datastore_settings","title":"<code>set_seed_datastore_settings(datastore_settings)</code>","text":"<p>Set the datastore settings for the seed dataset.</p> <p>Parameters:</p> Name Type Description Default <code>datastore_settings</code> <code>Optional[DatastoreSettings]</code> <p>The datastore settings to use for the seed dataset.</p> required Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def set_seed_datastore_settings(self, datastore_settings: Optional[DatastoreSettings]) -&gt; Self:\n    \"\"\"Set the datastore settings for the seed dataset.\n\n    Args:\n        datastore_settings: The datastore settings to use for the seed dataset.\n    \"\"\"\n    self._datastore_settings = datastore_settings\n    return self\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.validate","title":"<code>validate(*, raise_exceptions=False)</code>","text":"<p>Validate the current Data Designer configuration.</p> <p>Parameters:</p> Name Type Description Default <code>raise_exceptions</code> <code>bool</code> <p>Whether to raise an exception if the configuration is invalid.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The current Data Designer config builder instance.</p> <p>Raises:</p> Type Description <code>InvalidConfigError</code> <p>If the configuration is invalid and raise_exceptions is True.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def validate(self, *, raise_exceptions: bool = False) -&gt; Self:\n    \"\"\"Validate the current Data Designer configuration.\n\n    Args:\n        raise_exceptions: Whether to raise an exception if the configuration is invalid.\n\n    Returns:\n        The current Data Designer config builder instance.\n\n    Raises:\n        InvalidConfigError: If the configuration is invalid and raise_exceptions is True.\n    \"\"\"\n\n    violations = validate_data_designer_config(\n        columns=list(self._column_configs.values()),\n        processor_configs=self._processor_configs,\n        allowed_references=self.allowed_references,\n    )\n    rich_print_violations(violations)\n    if raise_exceptions and len([v for v in violations if v.level == ViolationLevel.ERROR]) &gt; 0:\n        raise InvalidConfigError(\n            \"\ud83d\uded1 Your configuration contains validation errors. Please address the indicated issues and try again.\"\n        )\n    if len(violations) == 0:\n        logger.info(\"\u2705 Validation passed\")\n    return self\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.with_seed_dataset","title":"<code>with_seed_dataset(dataset_reference, *, sampling_strategy=SamplingStrategy.ORDERED, selection_strategy=None)</code>","text":"<p>Add a seed dataset to the current Data Designer configuration.</p> <p>This method sets the seed dataset for the configuration and automatically creates SeedDatasetColumnConfig objects for each column found in the dataset. The column names are fetched from the dataset source (Hugging Face Hub or NeMo Microservices Datastore).</p> <p>Parameters:</p> Name Type Description Default <code>dataset_reference</code> <code>SeedDatasetReference</code> <p>Seed dataset reference for fetching from the datastore.</p> required <code>sampling_strategy</code> <code>SamplingStrategy</code> <p>The sampling strategy to use when generating data from the seed dataset. Defaults to ORDERED sampling.</p> <code>ORDERED</code> <p>Returns:</p> Type Description <code>Self</code> <p>The current Data Designer config builder instance.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def with_seed_dataset(\n    self,\n    dataset_reference: SeedDatasetReference,\n    *,\n    sampling_strategy: SamplingStrategy = SamplingStrategy.ORDERED,\n    selection_strategy: Optional[Union[IndexRange, PartitionBlock]] = None,\n) -&gt; Self:\n    \"\"\"Add a seed dataset to the current Data Designer configuration.\n\n    This method sets the seed dataset for the configuration and automatically creates\n    SeedDatasetColumnConfig objects for each column found in the dataset. The column\n    names are fetched from the dataset source (Hugging Face Hub or NeMo Microservices Datastore).\n\n    Args:\n        dataset_reference: Seed dataset reference for fetching from the datastore.\n        sampling_strategy: The sampling strategy to use when generating data from the seed dataset.\n            Defaults to ORDERED sampling.\n\n    Returns:\n        The current Data Designer config builder instance.\n    \"\"\"\n    self._seed_config = SeedConfig(\n        dataset=dataset_reference.dataset,\n        sampling_strategy=sampling_strategy,\n        selection_strategy=selection_strategy,\n    )\n    self.set_seed_datastore_settings(\n        dataset_reference.datastore_settings if hasattr(dataset_reference, \"datastore_settings\") else None\n    )\n    for column_name in fetch_seed_dataset_column_names(dataset_reference):\n        self._column_configs[column_name] = SeedDatasetColumnConfig(name=column_name)\n    return self\n</code></pre>"},{"location":"code_reference/config_builder/#data_designer.config.config_builder.DataDesignerConfigBuilder.write_config","title":"<code>write_config(path, indent=2, **kwargs)</code>","text":"<p>Write the current configuration to a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the file to write the configuration to.</p> required <code>indent</code> <code>Optional[int]</code> <p>Indentation level for the output file (default: 2).</p> <code>2</code> <code>**kwargs</code> <p>Additional keyword arguments passed to the serialization methods used.</p> <code>{}</code> <p>Raises:</p> Type Description <code>BuilderConfigurationError</code> <p>If the file format is unsupported.</p> Source code in <code>src/data_designer/config/config_builder.py</code> <pre><code>def write_config(self, path: Union[str, Path], indent: Optional[int] = 2, **kwargs) -&gt; None:\n    \"\"\"Write the current configuration to a file.\n\n    Args:\n        path: Path to the file to write the configuration to.\n        indent: Indentation level for the output file (default: 2).\n        **kwargs: Additional keyword arguments passed to the serialization methods used.\n\n    Raises:\n        BuilderConfigurationError: If the file format is unsupported.\n    \"\"\"\n    cfg = self.get_builder_config()\n    suffix = Path(path).suffix\n    if suffix in {\".yaml\", \".yml\"}:\n        cfg.to_yaml(path, indent=indent, **kwargs)\n    elif suffix == \".json\":\n        cfg.to_json(path, indent=indent, **kwargs)\n    else:\n        raise BuilderConfigurationError(f\"\ud83d\uded1 Unsupported file type: {suffix}. Must be `.yaml`, `.yml` or `.json`.\")\n</code></pre>"},{"location":"code_reference/data_designer_config/","title":"Data Designer Configuration","text":"<p>DataDesignerConfig is the main configuration object for builder datasets with Data Designer. It is a declarative configuration for defining the dataset you want to generate column-by-column, including options for dataset post-processing, validation, and profiling.</p> <p>Generally, you should use the DataDesignerConfigBuilder to build your configuration, but you can also build it manually by instantiating the DataDesignerConfig class directly.</p> <p>Classes:</p> Name Description <code>DataDesignerConfig</code> <p>Configuration for NeMo Data Designer.</p>"},{"location":"code_reference/data_designer_config/#data_designer.config.data_designer_config.DataDesignerConfig","title":"<code>DataDesignerConfig</code>","text":"<p>               Bases: <code>ExportableConfigBase</code></p> <p>Configuration for NeMo Data Designer.</p> <p>This class defines the main configuration structure for NeMo Data Designer, which orchestrates the generation of synthetic data.</p> <p>Attributes:</p> Name Type Description <code>columns</code> <code>list[Annotated[ColumnConfigT, Field(discriminator='column_type')]]</code> <p>Required list of column configurations defining how each column should be generated. Must contain at least one column.</p> <code>model_configs</code> <code>Optional[list[ModelConfig]]</code> <p>Optional list of model configurations for LLM-based generation. Each model config defines the model, provider, and inference parameters.</p> <code>seed_config</code> <code>Optional[SeedConfig]</code> <p>Optional seed dataset settings to use for generation.</p> <code>constraints</code> <code>Optional[list[ColumnConstraintT]]</code> <p>Optional list of column constraints.</p> <code>profilers</code> <code>Optional[list[ColumnProfilerConfigT]]</code> <p>Optional list of column profilers for analyzing generated data characteristics.</p>"},{"location":"code_reference/models/","title":"Models","text":"<p>The <code>models</code> module defines configuration objects for model-based generation. ModelProvider, specifies connection and authentication details for custom providers. ModelConfig encapsulates model details including the model alias, identifier, and inference parameters. InferenceParameters controls model behavior through settings like <code>temperature</code>, <code>top_p</code>, and <code>max_tokens</code>, with support for both fixed values and distribution-based sampling. The module includes ImageContext for providing image inputs to multimodal models.</p> <p>For more information on how they are used, see below:</p> <ul> <li>Model Providers</li> <li>Model Configs</li> <li>Image Context</li> </ul> <p>Classes:</p> Name Description <code>DistributionType</code> <p>Types of distributions for sampling inference parameters.</p> <code>ImageContext</code> <p>Configuration for providing image context to multimodal models.</p> <code>ImageFormat</code> <p>Supported image formats for image modality.</p> <code>InferenceParameters</code> <p>Configuration for LLM inference parameters.</p> <code>ManualDistribution</code> <p>Manual (discrete) distribution for sampling inference parameters.</p> <code>ManualDistributionParams</code> <p>Parameters for manual distribution sampling.</p> <code>Modality</code> <p>Supported modality types for multimodal model data.</p> <code>ModalityDataType</code> <p>Data type formats for multimodal data.</p> <code>ModelConfig</code> <p>Configuration for a model used for generation.</p> <code>ModelProvider</code> <p>Configuration for a custom model provider.</p> <code>UniformDistribution</code> <p>Uniform distribution for sampling inference parameters.</p> <code>UniformDistributionParams</code> <p>Parameters for uniform distribution sampling.</p>"},{"location":"code_reference/models/#data_designer.config.models.DistributionType","title":"<code>DistributionType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Types of distributions for sampling inference parameters.</p>"},{"location":"code_reference/models/#data_designer.config.models.ImageContext","title":"<code>ImageContext</code>","text":"<p>               Bases: <code>ModalityContext</code></p> <p>Configuration for providing image context to multimodal models.</p> <p>Attributes:</p> Name Type Description <code>modality</code> <code>Modality</code> <p>The modality type (always \"image\").</p> <code>column_name</code> <code>str</code> <p>Name of the column containing image data.</p> <code>data_type</code> <code>ModalityDataType</code> <p>Format of the image data (\"url\" or \"base64\").</p> <code>image_format</code> <code>Optional[ImageFormat]</code> <p>Image format (required for base64 data).</p> <p>Methods:</p> Name Description <code>get_context</code> <p>Get the context for the image modality.</p>"},{"location":"code_reference/models/#data_designer.config.models.ImageContext.get_context","title":"<code>get_context(record)</code>","text":"<p>Get the context for the image modality.</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>dict</code> <p>The record containing the image data.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The context for the image modality.</p> Source code in <code>src/data_designer/config/models.py</code> <pre><code>def get_context(self, record: dict) -&gt; dict[str, Any]:\n    \"\"\"Get the context for the image modality.\n\n    Args:\n        record: The record containing the image data.\n\n    Returns:\n        The context for the image modality.\n    \"\"\"\n    context = dict(type=\"image_url\")\n    context_value = record[self.column_name]\n    if self.data_type == ModalityDataType.URL:\n        context[\"image_url\"] = context_value\n    else:\n        context[\"image_url\"] = {\n            \"url\": f\"data:image/{self.image_format.value};base64,{context_value}\",\n            \"format\": self.image_format.value,\n        }\n    return context\n</code></pre>"},{"location":"code_reference/models/#data_designer.config.models.ImageFormat","title":"<code>ImageFormat</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Supported image formats for image modality.</p>"},{"location":"code_reference/models/#data_designer.config.models.InferenceParameters","title":"<code>InferenceParameters</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Configuration for LLM inference parameters.</p> <p>Attributes:</p> Name Type Description <code>temperature</code> <code>Optional[Union[float, DistributionT]]</code> <p>Sampling temperature (0.0-2.0). Can be a fixed value or a distribution for dynamic sampling.</p> <code>top_p</code> <code>Optional[Union[float, DistributionT]]</code> <p>Nucleus sampling probability (0.0-1.0). Can be a fixed value or a distribution for dynamic sampling.</p> <code>max_tokens</code> <code>Optional[int]</code> <p>Maximum number of tokens (includes both input and output tokens).</p> <code>max_parallel_requests</code> <code>int</code> <p>Maximum number of parallel requests to the model API.</p> <code>timeout</code> <code>Optional[int]</code> <p>Timeout in seconds for each request.</p> <code>extra_body</code> <code>Optional[dict[str, Any]]</code> <p>Additional parameters to pass to the model API.</p>"},{"location":"code_reference/models/#data_designer.config.models.InferenceParameters.generate_kwargs","title":"<code>generate_kwargs</code>  <code>property</code>","text":"<p>Get the generate kwargs for the inference parameters.</p> <p>Returns:</p> Type Description <code>dict[str, Union[float, int]]</code> <p>A dictionary of the generate kwargs.</p>"},{"location":"code_reference/models/#data_designer.config.models.ManualDistribution","title":"<code>ManualDistribution</code>","text":"<p>               Bases: <code>Distribution[ManualDistributionParams]</code></p> <p>Manual (discrete) distribution for sampling inference parameters.</p> <p>Samples from a discrete set of values with optional weights. Useful for testing specific values or creating custom probability distributions for temperature or top_p.</p> <p>Attributes:</p> Name Type Description <code>distribution_type</code> <code>Optional[DistributionType]</code> <p>Type of distribution (\"manual\").</p> <code>params</code> <code>ManualDistributionParams</code> <p>Distribution parameters (values, weights).</p> <p>Methods:</p> Name Description <code>sample</code> <p>Sample a value from the manual distribution.</p>"},{"location":"code_reference/models/#data_designer.config.models.ManualDistribution.sample","title":"<code>sample()</code>","text":"<p>Sample a value from the manual distribution.</p> <p>Returns:</p> Type Description <code>float</code> <p>A float value sampled from the manual distribution.</p> Source code in <code>src/data_designer/config/models.py</code> <pre><code>def sample(self) -&gt; float:\n    \"\"\"Sample a value from the manual distribution.\n\n    Returns:\n        A float value sampled from the manual distribution.\n    \"\"\"\n    return float(np.random.choice(self.params.values, p=self.params.weights))\n</code></pre>"},{"location":"code_reference/models/#data_designer.config.models.ManualDistributionParams","title":"<code>ManualDistributionParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Parameters for manual distribution sampling.</p> <p>Attributes:</p> Name Type Description <code>values</code> <code>List[float]</code> <p>List of possible values to sample from.</p> <code>weights</code> <code>Optional[List[float]]</code> <p>Optional list of weights for each value. If not provided, all values have equal probability.</p>"},{"location":"code_reference/models/#data_designer.config.models.Modality","title":"<code>Modality</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Supported modality types for multimodal model data.</p>"},{"location":"code_reference/models/#data_designer.config.models.ModalityDataType","title":"<code>ModalityDataType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Data type formats for multimodal data.</p>"},{"location":"code_reference/models/#data_designer.config.models.ModelConfig","title":"<code>ModelConfig</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Configuration for a model used for generation.</p> <p>Attributes:</p> Name Type Description <code>alias</code> <code>str</code> <p>User-defined alias to reference in column configurations.</p> <code>model</code> <code>str</code> <p>Model identifier (e.g., from build.nvidia.com or other providers).</p> <code>inference_parameters</code> <code>InferenceParameters</code> <p>Inference parameters for the model (temperature, top_p, max_tokens, etc.).</p> <code>provider</code> <code>Optional[str]</code> <p>Optional model provider name if using custom providers.</p>"},{"location":"code_reference/models/#data_designer.config.models.ModelProvider","title":"<code>ModelProvider</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Configuration for a custom model provider.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the model provider.</p> <code>endpoint</code> <code>str</code> <p>API endpoint URL for the provider.</p> <code>provider_type</code> <code>str</code> <p>Provider type (default: \"openai\"). Determines the API format to use.</p> <code>api_key</code> <code>Optional[str]</code> <p>Optional API key for authentication.</p> <code>extra_body</code> <code>Optional[dict[str, Any]]</code> <p>Additional parameters to pass in API requests.</p>"},{"location":"code_reference/models/#data_designer.config.models.UniformDistribution","title":"<code>UniformDistribution</code>","text":"<p>               Bases: <code>Distribution[UniformDistributionParams]</code></p> <p>Uniform distribution for sampling inference parameters.</p> <p>Samples values uniformly between low and high bounds. Useful for exploring a continuous range of values for temperature or top_p.</p> <p>Attributes:</p> Name Type Description <code>distribution_type</code> <code>Optional[DistributionType]</code> <p>Type of distribution (\"uniform\").</p> <code>params</code> <code>UniformDistributionParams</code> <p>Distribution parameters (low, high).</p> <p>Methods:</p> Name Description <code>sample</code> <p>Sample a value from the uniform distribution.</p>"},{"location":"code_reference/models/#data_designer.config.models.UniformDistribution.sample","title":"<code>sample()</code>","text":"<p>Sample a value from the uniform distribution.</p> <p>Returns:</p> Type Description <code>float</code> <p>A float value sampled from the uniform distribution.</p> Source code in <code>src/data_designer/config/models.py</code> <pre><code>def sample(self) -&gt; float:\n    \"\"\"Sample a value from the uniform distribution.\n\n    Returns:\n        A float value sampled from the uniform distribution.\n    \"\"\"\n    return float(np.random.uniform(low=self.params.low, high=self.params.high, size=1)[0])\n</code></pre>"},{"location":"code_reference/models/#data_designer.config.models.UniformDistributionParams","title":"<code>UniformDistributionParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Parameters for uniform distribution sampling.</p> <p>Attributes:</p> Name Type Description <code>low</code> <code>float</code> <p>Lower bound (inclusive).</p> <code>high</code> <code>float</code> <p>Upper bound (exclusive).</p>"},{"location":"code_reference/sampler_params/","title":"Sampler Parameters","text":"<p>The <code>sampler_params</code> module defines parameter configuration objects for all Data Designer sampler types. Sampler parameters are used within the SamplerColumnConfig to specify how values should be generated for sampled columns.</p> <p>Displaying available samplers and their parameters</p> <p>The config builder has an <code>info</code> attribute that can be used to display the available sampler types and their parameters: <pre><code>config_builder.info.display(\"samplers\")\n</code></pre></p> <p>Classes:</p> Name Description <code>BernoulliMixtureSamplerParams</code> <p>Parameters for sampling from a Bernoulli mixture distribution.</p> <code>BernoulliSamplerParams</code> <p>Parameters for sampling from a Bernoulli distribution.</p> <code>BinomialSamplerParams</code> <p>Parameters for sampling from a Binomial distribution.</p> <code>CategorySamplerParams</code> <p>Parameters for categorical sampling with optional probability weighting.</p> <code>DatetimeSamplerParams</code> <p>Parameters for uniform datetime sampling within a specified range.</p> <code>GaussianSamplerParams</code> <p>Parameters for sampling from a Gaussian (Normal) distribution.</p> <code>PersonFromFakerSamplerParams</code> <code>PersonSamplerParams</code> <p>Parameters for sampling synthetic person data with demographic attributes.</p> <code>PoissonSamplerParams</code> <p>Parameters for sampling from a Poisson distribution.</p> <code>ScipySamplerParams</code> <p>Parameters for sampling from any scipy.stats continuous or discrete distribution.</p> <code>SubcategorySamplerParams</code> <p>Parameters for subcategory sampling conditioned on a parent category column.</p> <code>TimeDeltaSamplerParams</code> <p>Parameters for sampling time deltas relative to a reference datetime column.</p> <code>UUIDSamplerParams</code> <p>Parameters for generating UUID (Universally Unique Identifier) values.</p> <code>UniformSamplerParams</code> <p>Parameters for sampling from a continuous Uniform distribution.</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.BernoulliMixtureSamplerParams","title":"<code>BernoulliMixtureSamplerParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Parameters for sampling from a Bernoulli mixture distribution.</p> <p>Combines a Bernoulli distribution with another continuous distribution, creating a mixture where values are either 0 (with probability 1-p) or sampled from the specified distribution (with probability p). This is useful for modeling scenarios with many zero values mixed with a continuous distribution of non-zero values.</p> <p>Common use cases include modeling sparse events, zero-inflated data, or situations where an outcome either doesn't occur (0) or follows a specific distribution when it does occur.</p> <p>Attributes:</p> Name Type Description <code>p</code> <code>float</code> <p>Probability of sampling from the mixture distribution (non-zero outcome). Must be between 0.0 and 1.0 (inclusive). With probability 1-p, the sample is 0.</p> <code>dist_name</code> <code>str</code> <p>Name of the scipy.stats distribution to sample from when outcome is non-zero. Must be a valid scipy.stats distribution name (e.g., \"norm\", \"gamma\", \"expon\").</p> <code>dist_params</code> <code>dict</code> <p>Parameters for the specified scipy.stats distribution.</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.BernoulliSamplerParams","title":"<code>BernoulliSamplerParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Parameters for sampling from a Bernoulli distribution.</p> <p>Samples binary values (0 or 1) representing the outcome of a single trial with a fixed probability of success. This is the simplest discrete probability distribution, useful for modeling binary outcomes like success/failure, yes/no, or true/false.</p> <p>Attributes:</p> Name Type Description <code>p</code> <code>float</code> <p>Probability of success (sampling 1). Must be between 0.0 and 1.0 (inclusive). The probability of failure (sampling 0) is automatically 1 - p.</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.BinomialSamplerParams","title":"<code>BinomialSamplerParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Parameters for sampling from a Binomial distribution.</p> <p>Samples integer values representing the number of successes in a fixed number of independent Bernoulli trials, each with the same probability of success. Commonly used to model the number of successful outcomes in repeated experiments.</p> <p>Attributes:</p> Name Type Description <code>n</code> <code>int</code> <p>Number of independent trials. Must be a positive integer.</p> <code>p</code> <code>float</code> <p>Probability of success on each trial. Must be between 0.0 and 1.0 (inclusive).</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.CategorySamplerParams","title":"<code>CategorySamplerParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Parameters for categorical sampling with optional probability weighting.</p> <p>Samples values from a discrete set of categories. When weights are provided, values are sampled according to their assigned probabilities. Without weights, uniform sampling is used.</p> <p>Attributes:</p> Name Type Description <code>values</code> <code>list[Union[str, int, float]]</code> <p>List of possible categorical values to sample from. Can contain strings, integers, or floats. Must contain at least one value.</p> <code>weights</code> <code>Optional[list[float]]</code> <p>Optional unnormalized probability weights for each value. If provided, must be the same length as <code>values</code>. Weights are automatically normalized to sum to 1.0. Larger weights result in higher sampling probability for the corresponding value.</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.DatetimeSamplerParams","title":"<code>DatetimeSamplerParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Parameters for uniform datetime sampling within a specified range.</p> <p>Samples datetime values uniformly between a start and end date with a specified granularity. The sampling unit determines the smallest possible time interval between consecutive samples.</p> <p>Attributes:</p> Name Type Description <code>start</code> <code>str</code> <p>Earliest possible datetime for the sampling range (inclusive). Must be a valid datetime string parseable by pandas.to_datetime().</p> <code>end</code> <code>str</code> <p>Latest possible datetime for the sampling range (inclusive). Must be a valid datetime string parseable by pandas.to_datetime().</p> <code>unit</code> <code>Literal['Y', 'M', 'D', 'h', 'm', 's']</code> <p>Time unit for sampling granularity. Options: - \"Y\": Years - \"M\": Months - \"D\": Days (default) - \"h\": Hours - \"m\": Minutes - \"s\": Seconds</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.GaussianSamplerParams","title":"<code>GaussianSamplerParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Parameters for sampling from a Gaussian (Normal) distribution.</p> <p>Samples continuous values from a normal distribution characterized by its mean and standard deviation. The Gaussian distribution is one of the most commonly used probability distributions, appearing naturally in many real-world phenomena due to the Central Limit Theorem.</p> <p>Attributes:</p> Name Type Description <code>mean</code> <code>float</code> <p>Mean (center) of the Gaussian distribution. This is the expected value and the location of the distribution's peak.</p> <code>stddev</code> <code>float</code> <p>Standard deviation of the Gaussian distribution. Controls the spread or width of the distribution. Must be positive.</p> <code>decimal_places</code> <code>Optional[int]</code> <p>Optional number of decimal places to round sampled values to. If None, values are not rounded.</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.PersonFromFakerSamplerParams","title":"<code>PersonFromFakerSamplerParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Attributes:</p> Name Type Description <code>generator_kwargs</code> <code>list[str]</code> <p>Keyword arguments to pass to the person generator.</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.PersonFromFakerSamplerParams.generator_kwargs","title":"<code>generator_kwargs</code>  <code>property</code>","text":"<p>Keyword arguments to pass to the person generator.</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.PersonSamplerParams","title":"<code>PersonSamplerParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Parameters for sampling synthetic person data with demographic attributes.</p> <p>Generates realistic synthetic person data including names, addresses, phone numbers, and other demographic information. Data can be sampled from managed datasets (when available) or generated using Faker. The sampler supports filtering by locale, sex, age, geographic location, and can optionally include synthetic persona descriptions.</p> <p>Attributes:</p> Name Type Description <code>locale</code> <code>str</code> <p>Locale string determining the language and geographic region for synthetic people. Format: language_COUNTRY (e.g., \"en_US\", \"en_GB\", \"fr_FR\", \"de_DE\", \"es_ES\", \"ja_JP\"). Defaults to \"en_US\".</p> <code>sex</code> <code>Optional[SexT]</code> <p>If specified, filters to only sample people of the specified sex. Options: \"Male\" or \"Female\". If None, samples both sexes.</p> <code>city</code> <code>Optional[Union[str, list[str]]]</code> <p>If specified, filters to only sample people from the specified city or cities. Can be a single city name (string) or a list of city names.</p> <code>age_range</code> <code>list[int]</code> <p>Two-element list [min_age, max_age] specifying the age range to sample from (inclusive). Defaults to a standard age range. Both values must be between minimum and maximum allowed ages.</p> <code>with_synthetic_personas</code> <code>bool</code> <p>If True, appends additional synthetic persona columns including personality traits, interests, and background descriptions. Only supported for certain locales with managed datasets.</p> <code>sample_dataset_when_available</code> <code>bool</code> <p>If True, samples from curated managed datasets when available for the specified locale. If False or unavailable, falls back to Faker-generated data. Managed datasets typically provide more realistic and diverse synthetic people.</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.PersonSamplerParams.generator_kwargs","title":"<code>generator_kwargs</code>  <code>property</code>","text":"<p>Keyword arguments to pass to the person generator.</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.PoissonSamplerParams","title":"<code>PoissonSamplerParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Parameters for sampling from a Poisson distribution.</p> <p>Samples non-negative integer values representing the number of events occurring in a fixed interval of time or space. The Poisson distribution is commonly used to model count data like the number of arrivals, occurrences, or events per time period.</p> <p>The distribution is characterized by a single parameter (mean/rate), and both the mean and variance equal this parameter value.</p> <p>Attributes:</p> Name Type Description <code>mean</code> <code>float</code> <p>Mean number of events in the fixed interval (also called rate parameter \u03bb). Must be positive. This represents both the expected value and the variance of the distribution.</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.ScipySamplerParams","title":"<code>ScipySamplerParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Parameters for sampling from any scipy.stats continuous or discrete distribution.</p> <p>Provides a flexible interface to sample from the wide range of probability distributions available in scipy.stats. This enables advanced statistical sampling beyond the built-in distribution types (Gaussian, Uniform, etc.).</p> <p>See: scipy.stats documentation</p> <p>Attributes:</p> Name Type Description <code>dist_name</code> <code>str</code> <p>Name of the scipy.stats distribution to sample from (e.g., \"beta\", \"gamma\", \"lognorm\", \"expon\"). Must be a valid distribution name from scipy.stats.</p> <code>dist_params</code> <code>dict</code> <p>Dictionary of parameters for the specified distribution. Parameter names and values must match the scipy.stats distribution specification (e.g., {\"a\": 2, \"b\": 5} for beta distribution, {\"scale\": 1.5} for exponential).</p> <code>decimal_places</code> <code>Optional[int]</code> <p>Optional number of decimal places to round sampled values to. If None, values are not rounded.</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.SubcategorySamplerParams","title":"<code>SubcategorySamplerParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Parameters for subcategory sampling conditioned on a parent category column.</p> <p>Samples subcategory values based on the value of a parent category column. Each parent category value maps to its own list of possible subcategory values, enabling hierarchical or conditional sampling patterns.</p> <p>Attributes:</p> Name Type Description <code>category</code> <code>str</code> <p>Name of the parent category column that this subcategory depends on. The parent column must be generated before this subcategory column.</p> <code>values</code> <code>dict[str, list[Union[str, int, float]]]</code> <p>Mapping from each parent category value to a list of possible subcategory values. Each key must correspond to a value that appears in the parent category column.</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.TimeDeltaSamplerParams","title":"<code>TimeDeltaSamplerParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Parameters for sampling time deltas relative to a reference datetime column.</p> <p>Samples time offsets within a specified range and adds them to values from a reference datetime column. This is useful for generating related datetime columns like order dates and delivery dates, or event start times and end times.</p> Note <p>Years and months are not supported as timedelta units because they have variable lengths. See: pandas timedelta documentation</p> <p>Attributes:</p> Name Type Description <code>dt_min</code> <code>int</code> <p>Minimum time-delta value (inclusive). Must be non-negative and less than <code>dt_max</code>. Specified in units defined by the <code>unit</code> parameter.</p> <code>dt_max</code> <code>int</code> <p>Maximum time-delta value (exclusive). Must be positive and greater than <code>dt_min</code>. Specified in units defined by the <code>unit</code> parameter.</p> <code>reference_column_name</code> <code>str</code> <p>Name of an existing datetime column to add the time-delta to. This column must be generated before the timedelta column.</p> <code>unit</code> <code>Literal['D', 'h', 'm', 's']</code> <p>Time unit for the delta values. Options: - \"D\": Days (default) - \"h\": Hours - \"m\": Minutes - \"s\": Seconds</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.UUIDSamplerParams","title":"<code>UUIDSamplerParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Parameters for generating UUID (Universally Unique Identifier) values.</p> <p>Generates UUID4 (random) identifiers with optional formatting options. UUIDs are useful for creating unique identifiers for records, entities, or transactions.</p> <p>Attributes:</p> Name Type Description <code>prefix</code> <code>Optional[str]</code> <p>Optional string to prepend to each UUID. Useful for creating namespaced or typed identifiers (e.g., \"user-\", \"order-\", \"txn-\").</p> <code>short_form</code> <code>bool</code> <p>If True, truncates UUIDs to 8 characters (first segment only). Default is False for full 32-character UUIDs (excluding hyphens).</p> <code>uppercase</code> <code>bool</code> <p>If True, converts all hexadecimal letters to uppercase. Default is False for lowercase UUIDs.</p>"},{"location":"code_reference/sampler_params/#data_designer.config.sampler_params.UniformSamplerParams","title":"<code>UniformSamplerParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Parameters for sampling from a continuous Uniform distribution.</p> <p>Samples continuous values uniformly from a specified range, where every value in the range has equal probability of being sampled. This is useful when all values within a range are equally likely, such as random percentages, proportions, or unbiased measurements.</p> <p>Attributes:</p> Name Type Description <code>low</code> <code>float</code> <p>Lower bound of the uniform distribution (inclusive). Can be any real number.</p> <code>high</code> <code>float</code> <p>Upper bound of the uniform distribution (inclusive). Must be greater than <code>low</code>.</p> <code>decimal_places</code> <code>Optional[int]</code> <p>Optional number of decimal places to round sampled values to. If None, values are not rounded and may have many decimal places.</p>"},{"location":"code_reference/validator_params/","title":"Validator Parameters","text":"<p>When creating a <code>ValidationColumnConfig</code>, two parameters are used to define the validator: <code>validator_type</code> and <code>validator_config</code>. The <code>validator_type</code> parameter can be set to either <code>code</code>, <code>local_callable</code> or <code>remote</code>. The <code>validator_config</code> accompanying each of these is, respectively:</p> <p>Classes:</p> Name Description <code>CodeValidatorParams</code> <p>Configuration for code validation. Supports Python and SQL code validation.</p> <code>LocalCallableValidatorParams</code> <p>Configuration for local callable validation. Expects a function to be passed that validates the data.</p> <code>RemoteValidatorParams</code> <p>Configuration for remote validation. Sends data to a remote endpoint for validation.</p>"},{"location":"code_reference/validator_params/#data_designer.config.validator_params.CodeValidatorParams","title":"<code>CodeValidatorParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Configuration for code validation. Supports Python and SQL code validation.</p> <p>Attributes:</p> Name Type Description <code>code_lang</code> <code>CodeLang</code> <p>The language of the code to validate. Supported values include: <code>python</code>, <code>sql:sqlite</code>, <code>sql:postgres</code>, <code>sql:mysql</code>, <code>sql:tsql</code>, <code>sql:bigquery</code>, <code>sql:ansi</code>.</p>"},{"location":"code_reference/validator_params/#data_designer.config.validator_params.LocalCallableValidatorParams","title":"<code>LocalCallableValidatorParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Configuration for local callable validation. Expects a function to be passed that validates the data.</p> <p>Attributes:</p> Name Type Description <code>validation_function</code> <code>Any</code> <p>Function (<code>Callable[[pd.DataFrame], pd.DataFrame]</code>) to validate the data. Output must contain a column <code>is_valid</code> of type <code>bool</code>.</p> <code>output_schema</code> <code>Optional[dict[str, Any]]</code> <p>The JSON schema for the local callable validator's output. If not provided, the output will not be validated.</p>"},{"location":"code_reference/validator_params/#data_designer.config.validator_params.RemoteValidatorParams","title":"<code>RemoteValidatorParams</code>","text":"<p>               Bases: <code>ConfigBase</code></p> <p>Configuration for remote validation. Sends data to a remote endpoint for validation.</p> <p>Attributes:</p> Name Type Description <code>endpoint_url</code> <code>str</code> <p>The URL of the remote endpoint.</p> <code>output_schema</code> <code>Optional[dict[str, Any]]</code> <p>The JSON schema for the remote validator's output. If not provided, the output will not be validated.</p> <code>timeout</code> <code>float</code> <p>The timeout for the HTTP request in seconds. Defaults to 30.0.</p> <code>max_retries</code> <code>int</code> <p>The maximum number of retry attempts. Defaults to 3.</p> <code>retry_backoff</code> <code>float</code> <p>The backoff factor for the retry delay in seconds. Defaults to 2.0.</p> <code>max_parallel_requests</code> <code>int</code> <p>The maximum number of parallel requests to make. Defaults to 4.</p>"},{"location":"concepts/columns/","title":"Columns","text":"<p>Columns are the fundamental building blocks in Data Designer. Each column represents a field in your dataset and defines how to generate it\u2014whether that's sampling from a distribution, calling an LLM, or applying a transformation.</p> <p>The Declarative Approach</p> <p>Columns are declarative specifications. You describe what you want, and the framework handles how to generate it\u2014managing execution order, batching, parallelization, and resources automatically.</p>"},{"location":"concepts/columns/#column-types","title":"Column Types","text":"<p>Data Designer provides nine built-in column types, each optimized for different generation scenarios.</p>"},{"location":"concepts/columns/#sampler-columns","title":"\ud83c\udfb2 Sampler Columns","text":"<p>Sampler columns generate data using numerical sampling\u2014fast, deterministic, and ideal for numerical and categorical dataset fields. They're significantly faster than LLMs and can produce data following specific distributions (Poisson for event counts, Gaussian for measurements, etc.).</p> <p>Available sampler types:</p> <ul> <li>UUID: Unique identifiers</li> <li>Category: Categorical values with optional probability weights</li> <li>Subcategory: Hierarchical categorical data (states within countries, models within brands)</li> <li>Uniform: Evenly distributed numbers (integers or floats)</li> <li>Gaussian: Normally distributed values with configurable mean and standard deviation</li> <li>Bernoulli: Binary outcomes with specified success probability</li> <li>Bernoulli Mixture: Binary outcomes from multiple probability components</li> <li>Binomial: Count of successes in repeated trials</li> <li>Poisson: Count data and event frequencies</li> <li>Scipy: Access to the full scipy.stats distribution library</li> <li>Person: Realistic synthetic individuals with names, demographics, and attributes</li> <li>Datetime: Timestamps within specified ranges</li> <li>Timedelta: Time duration values</li> </ul> <p>Conditional Sampling</p> <p>Samplers support conditional parameters that change behavior based on other columns. Want age distributions that vary by country? Income ranges that depend on occupation? Just define conditions on existing column values.</p>"},{"location":"concepts/columns/#llm-text-columns","title":"\ud83d\udcdd LLM-Text Columns","text":"<p>LLM-Text columns generate natural language text: product descriptions, customer reviews, narrative summaries, email threads, or anything requiring semantic understanding and creativity.</p> <p>Use Jinja2 templating in prompts to reference other columns. Data Designer automatically manages dependencies and injects the referenced column values into the prompt.</p> <p>Reasoning Traces</p> <p>Models that support extended thinking (chain-of-thought reasoning) can capture their reasoning process in a separate <code>{column_name}__reasoning_trace</code> column\u2013useful for understanding why the model generated specific content. This column is automatically added to the dataset if the model and service provider parse and return reasoning content.</p>"},{"location":"concepts/columns/#llm-code-columns","title":"\ud83d\udcbb LLM-Code Columns","text":"<p>LLM-Code columns generate code in specific programming languages. They handle the prompting and parsing necessary to extract clean code from the LLM's response\u2014automatically detecting and extracting code from markdown blocks. You provide the prompt and choose the model; the column handles the extraction.</p> <p>Supported languages: Python, JavaScript, TypeScript, Java, Kotlin, Go, Rust, Ruby, Scala, Swift, plus SQL dialects (SQLite, PostgreSQL, MySQL, T-SQL, BigQuery, ANSI SQL).</p>"},{"location":"concepts/columns/#llm-structured-columns","title":"\ud83d\uddc2\ufe0f LLM-Structured Columns","text":"<p>LLM-Structured columns generate JSON with a guaranteed schema. Define your structure using a Pydantic model or JSON schema, and Data Designer ensures the LLM output conforms\u2014no parsing errors, no schema drift.</p> <p>Use for complex nested structures: API responses, configuration files, database records with multiple related fields, or any structured data where type safety matters. Schemas can be arbitrarily complex with nested objects, arrays, enums, and validation constraints, but success depends on the model's capabilities.</p> <p>Schema Complexity and Model Choice</p> <p>Flat schemas with simple fields are easier and more robustly produced across models. Deeply nested schemas with complex validation constraints are more sensitive to model choice\u2014stronger models handle complexity better. If you're experiencing schema conformance issues, try simplifying the schema or switching to a more capable model.</p>"},{"location":"concepts/columns/#llm-judge-columns","title":"\u2696\ufe0f LLM-Judge Columns","text":"<p>LLM-Judge columns score generated content across multiple quality dimensions using LLMs as evaluators.</p> <p>Define scoring rubrics (relevance, accuracy, fluency, helpfulness) and the judge model evaluates each record. Score rubrics specify criteria and scoring options (1-5 scales, categorical grades, etc.), producing quantified quality metrics for every data point.</p> <p>Use judge columns for data quality filtering (e.g., keep only 4+ rated responses), A/B testing generation strategies, and quality monitoring over time.</p>"},{"location":"concepts/columns/#expression-columns","title":"\ud83e\udde9 Expression Columns","text":"<p>Expression columns handle simple transformations using Jinja2 templates\u2014concatenate first and last names, calculate numerical totals, format date strings. No LLM overhead needed.</p> <p>Template capabilities:</p> <ul> <li>Variable substitution: Pull values from any existing column</li> <li>String filters: Uppercase, lowercase, strip whitespace, replace patterns</li> <li>Conditional logic: if/elif/else support</li> <li>Arithmetic: Add, subtract, multiply, divide</li> </ul>"},{"location":"concepts/columns/#validation-columns","title":"\ud83d\udd0d Validation Columns","text":"<p>Validation columns check generated content against rules and return structured pass/fail results.</p> <p>Built-in validation types:</p> <p>Code validation runs Python or SQL code through a linter to validate the code.</p> <p>Local callable validation accepts a Python function directly when using Data Designer as a library.</p> <p>Remote validation sends data to HTTP endpoints for validation-as-a-service. Useful for linters, security scanners, or proprietary systems.</p>"},{"location":"concepts/columns/#seed-dataset-columns","title":"\ud83c\udf31 Seed Dataset Columns","text":"<p>Seed dataset columns bootstrap generation from existing data. Provide a real dataset, and those columns become available as context for generating new synthetic data.</p> <p>Typical pattern: use seed data for one part of your schema (real product names and categories), then generate synthetic fields around it (customer reviews, purchase histories, ratings). The seed data provides realism and constraints; generated columns add volume and variation.</p>"},{"location":"concepts/columns/#shared-column-properties","title":"Shared Column Properties","text":"<p>Every column configuration inherits from <code>SingleColumnConfig</code> with these standard properties:</p>"},{"location":"concepts/columns/#name","title":"<code>name</code>","text":"<p>The column's identifier\u2014unique within your configuration, used in Jinja2 references, and becomes the column name in the output DataFrame. Choose descriptive names: <code>user_review</code> &gt; <code>col_17</code>.</p>"},{"location":"concepts/columns/#drop","title":"<code>drop</code>","text":"<p>Boolean flag (default: <code>False</code>) controlling whether the column appears in final output. Setting <code>drop=True</code> generates the column (available as a dependency) but excludes it from final output.</p> <p>When to drop columns:</p> <ul> <li>Intermediate calculations that feed expressions but aren't meaningful standalone</li> <li>Context columns used only for LLM prompt templates</li> <li>Validation results during development unwanted in production</li> </ul> <p>Dropped columns participate fully in generation and the dependency graph\u2014just filtered out at the end.</p>"},{"location":"concepts/columns/#column_type","title":"<code>column_type</code>","text":"<p>Literal string identifying the column type: <code>\"sampler\"</code>, <code>\"llm-text\"</code>, <code>\"expression\"</code>, etc. Set automatically by each configuration class and serves as Pydantic's discriminator for deserialization.</p> <p>You rarely set this manually\u2014instantiating <code>LLMTextColumnConfig</code> automatically sets <code>column_type=\"llm-text\"</code>. Serialization is reversible: save to YAML, load later, and Pydantic reconstructs the exact objects.</p>"},{"location":"concepts/columns/#required_columns","title":"<code>required_columns</code>","text":"<p>Computed property listing columns that must be generated before this one. The framework derives this automatically:</p> <ul> <li>For LLM/Expression columns: extracted from Jinja2 template <code>{{ variables }}</code></li> <li>For Validation columns: explicitly listed target columns</li> <li>For Sampler columns with conditional parameters: columns referenced in conditions</li> </ul> <p>You read this property for introspection but never set it\u2014always computed from configuration details.</p>"},{"location":"concepts/columns/#side_effect_columns","title":"<code>side_effect_columns</code>","text":"<p>Computed property listing columns created implicitly alongside the primary column. Currently, only LLM columns produce side effects (reasoning trace columns like <code>{name}__reasoning_trace</code> when models use extended thinking).</p> <p>For detailed information on each column type, refer to the column configuration code reference.</p>"},{"location":"concepts/person_sampling/","title":"Person Sampling in Data Designer","text":"<p>Person sampling in Data Designer allows you to generate synthetic person data for your datasets using the Faker library.</p>"},{"location":"concepts/person_sampling/#faker-based-sampling","title":"Faker-Based Sampling","text":""},{"location":"concepts/person_sampling/#what-it-does","title":"What It Does","text":"<p>Uses the Faker library to generate random personal information. The data is basic and not demographically accurate, but is useful for quick testing, prototyping, or when realistic demographic distributions are not relevant for your use case.</p>"},{"location":"concepts/person_sampling/#features","title":"Features","text":"<ul> <li>Gives you access to person attributes that Faker exposes</li> <li>Quick to set up with no additional downloads</li> <li>Generates random names, emails, addresses, phone numbers, etc.</li> <li>Supports all Faker-supported locales</li> <li>Not demographically grounded - data patterns don't reflect real-world demographics</li> </ul>"},{"location":"concepts/person_sampling/#usage-example","title":"Usage Example","text":"<pre><code>from data_designer.essentials import (\n    SamplerColumnConfig,\n    SamplerType,\n    PersonFromFakerSamplerParams,\n)\n\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"customer\",\n        sampler_type=SamplerType.PERSON_FROM_FAKER,\n        params=PersonFromFakerSamplerParams(\n            locale=\"en_US\",\n            age_range=[25, 65],\n            sex=\"Female\",\n        ),\n    )\n)\n</code></pre>"},{"location":"concepts/validators/","title":"Validators","text":"<p>Validators are quality assurance mechanisms in Data Designer that check generated content against rules and return structured pass/fail results. They enable automated verification of data for correctness, code quality, and adherence to specifications.</p> <p>Quality Gates for Generated Data</p> <p>Validators act as quality gates in your generation pipeline. Use them to filter invalid records, score code quality, verify format compliance, or integrate with external validation services.</p>"},{"location":"concepts/validators/#overview","title":"Overview","text":"<p>Validation columns execute validation logic against target columns and produce structured results indicating:</p> <ul> <li><code>is_valid</code>: Boolean pass/fail status</li> <li>Additional metadata: Error messages, scores, severity levels, and custom fields</li> </ul> <p>Validators currently support three execution strategies:</p> <ol> <li>Code validation: Lint and check Python or SQL code using industry-standard tools</li> <li>Local callable validation: Execute custom Python functions for flexible validation logic</li> <li>Remote validation: Send data to HTTP endpoints for external validation services</li> </ol>"},{"location":"concepts/validators/#validator-types","title":"Validator Types","text":""},{"location":"concepts/validators/#python-code-validator","title":"\ud83d\udc0d Python Code Validator","text":"<p>The Python code validator runs generated Python code through Ruff, a fast Python linter that checks for syntax errors, undefined variables, and code quality issues.</p> <p>Configuration:</p> <pre><code>from data_designer.essentials import CodeLang, CodeValidatorParams\n\nvalidator_params = CodeValidatorParams(code_lang=CodeLang.PYTHON)\n</code></pre> <p>Validation Output:</p> <p>Each validated record returns:</p> <ul> <li><code>is_valid</code>: <code>True</code> if no fatal or error-level issues found</li> <li><code>python_linter_score</code>: Quality score from 0-10 (based on pylint formula)</li> <li><code>python_linter_severity</code>: Highest severity level found (<code>\"none\"</code>, <code>\"convention\"</code>, <code>\"refactor\"</code>, <code>\"warning\"</code>, <code>\"error\"</code>, <code>\"fatal\"</code>)</li> <li><code>python_linter_messages</code>: List of linter messages with line numbers, columns, and descriptions</li> </ul> <p>Severity Levels:</p> <ul> <li>Fatal: Syntax errors preventing code execution</li> <li>Error: Undefined names, invalid syntax</li> <li>Warning: Code smells and potential issues</li> <li>Refactor: Simplification opportunities</li> <li>Convention: Style guide violations</li> </ul> <p>A record is marked valid if it has no messages or only messages at warning/convention/refactor levels.</p> <p>Example Validation Result:</p> <pre><code>{\n    \"is_valid\": False,\n    \"python_linter_score\": 0,\n    \"python_linter_severity\": \"error\",\n    \"python_linter_messages\": [\n        {\n            \"type\": \"error\",\n            \"symbol\": \"F821\",\n            \"line\": 1,\n            \"column\": 7,\n            \"message\": \"Undefined name `it`\"\n        }\n    ]\n}\n</code></pre>"},{"location":"concepts/validators/#sql-code-validator","title":"\ud83d\uddc4\ufe0f SQL Code Validator","text":"<p>The SQL code validator uses SQLFluff, a dialect-aware SQL linter that checks query syntax and structure.</p> <p>Configuration:</p> <pre><code>from data_designer.essentials import CodeLang, CodeValidatorParams\n\nvalidator_params = CodeValidatorParams(code_lang=CodeLang.SQL_POSTGRES)\n</code></pre> <p>Multiple Dialects</p> <p>The SQL code validator supports multiple dialects: <code>SQL_POSTGRES</code>, <code>SQL_ANSI</code>, <code>SQL_MYSQL</code>, <code>SQL_SQLITE</code>, <code>SQL_TSQL</code> and <code>SQL_BIGQUERY</code>.</p> <p>Validation Output:</p> <p>Each validated record returns:</p> <ul> <li><code>is_valid</code>: <code>True</code> if no parsing errors found</li> <li><code>error_messages</code>: Concatenated error descriptions (empty string if valid)</li> </ul> <p>The validator focuses on parsing errors (PRS codes) that indicate malformed SQL. It also checks for common pitfalls like <code>DECIMAL</code> definitions without scale parameters.</p> <p>Example Validation Result:</p> <pre><code># Valid SQL\n{\n    \"is_valid\": True,\n    \"error_messages\": \"\"\n}\n\n# Invalid SQL\n{\n    \"is_valid\": False,\n    \"error_messages\": \"PRS: Line 1, Position 1: Found unparsable section: 'NOT SQL'\"\n}\n</code></pre>"},{"location":"concepts/validators/#local-callable-validator","title":"\ud83d\udd27 Local Callable Validator","text":"<p>The local callable validator executes custom Python functions for flexible validation logic.</p> <p>Configuration:</p> <pre><code>import pandas as pd\n\nfrom data_designer.essentials import LocalCallableValidatorParams\n\ndef my_validation_function(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Validate that values are positive.\n\n    Args:\n        df: DataFrame with target columns\n\n    Returns:\n        DataFrame with is_valid column and optional metadata\n    \"\"\"\n    result = pd.DataFrame()\n    result[\"is_valid\"] = df[\"price\"] &gt; 0\n    result[\"error_message\"] = result[\"is_valid\"].apply(\n        lambda valid: \"\" if valid else \"Price must be positive\"\n    )\n    return result\n\nvalidator_params = LocalCallableValidatorParams(\n    validation_function=my_validation_function,\n    output_schema={  # Optional: enforce output schema\n        \"type\": \"object\",\n        \"properties\": {\n            \"data\": {\n                \"type\": \"array\",\n                \"items\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"is_valid\": {\"type\": [\"boolean\", \"null\"]},\n                        \"error_message\": {\"type\": \"string\"}\n                    },\n                    \"required\": [\"is_valid\"]\n                }\n            }\n        }\n    }\n)\n</code></pre> <p>Function Requirements:</p> <ul> <li>Input: DataFrame with target columns</li> <li>Output: DataFrame with <code>is_valid</code> column (boolean or null)</li> <li>Extra fields: Any additional columns become validation metadata</li> </ul> <p>The <code>output_schema</code> parameter is optional but recommended\u2014it validates the function's output against a JSON schema, catching unexpected return formats.</p>"},{"location":"concepts/validators/#remote-validator","title":"\ud83c\udf10 Remote Validator","text":"<p>The remote validator sends data to HTTP endpoints for validation-as-a-service. This is useful for when you have validation software that needs to run on external compute and you can expose it through a service. Some examples are:</p> <ul> <li>External linting services</li> <li>Security scanners</li> <li>Domain-specific validators</li> <li>Proprietary validation systems</li> </ul> <p>Authentication</p> <p>Currently, the remote validator is only able to perform unauthenticated API calls. When implementing your own service, you can rely on network isolation for security. If you need to reach a service that requires authentication, you should implement a local proxy.</p> <p>Configuration:</p> <pre><code>from data_designer.essentials import RemoteValidatorParams\n\nvalidator_params = RemoteValidatorParams(\n    endpoint_url=\"https://api.example.com/validate\",\n    timeout=30.0,  # Request timeout in seconds\n    max_retries=3,  # Retry attempts on failure\n    retry_backoff=2.0,  # Exponential backoff factor\n    max_parallel_requests=4,  # Concurrent request limit\n    output_schema={  # Optional: enforce response schema\n        \"type\": \"object\",\n        \"properties\": {\n            \"data\": {\n                \"type\": \"array\",\n                \"items\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"is_valid\": {\"type\": [\"boolean\", \"null\"]},\n                        \"confidence\": {\"type\": \"string\"}\n                    }\n                }\n            }\n        }\n    }\n)\n</code></pre> <p>Request Format:</p> <p>The validator sends POST requests with this structure:</p> <pre><code>{\n    \"data\": [\n        {\"column1\": \"value1\", \"column2\": \"value2\"},\n        {\"column1\": \"value3\", \"column2\": \"value4\"}\n    ]\n}\n</code></pre> <p>Expected Response Format:</p> <p>The endpoint must return:</p> <pre><code>{\n    \"data\": [\n        {\n            \"is_valid\": true,\n            \"custom_field\": \"any additional metadata\"\n        },\n        {\n            \"is_valid\": false,\n            \"custom_field\": \"more metadata\"\n        }\n    ]\n}\n</code></pre> <p>Retry Behavior:</p> <p>The validator automatically retries on:</p> <ul> <li>Network errors</li> <li>HTTP status codes: 429 (rate limit), 500, 502, 503, 504</li> </ul> <p>Failed requests use exponential backoff: <code>delay = retry_backoff^attempt</code>.</p> <p>Parallelization:</p> <p>Set <code>max_parallel_requests</code> to control concurrency. Higher values improve throughput but increase server load. The validator batches requests according to the <code>batch_size</code> parameter in the validation column configuration.</p>"},{"location":"concepts/validators/#using-validators-in-columns","title":"Using Validators in Columns","text":"<p>Add validation columns to your configuration using the builder's <code>add_column</code> method:</p> <pre><code>from data_designer.essentials import (\n    CodeValidatorParams,\n    CodeLang,\n    DataDesignerConfigBuilder,\n    LLMCodeColumnConfig,\n    ValidationColumnConfig,\n)\n\nbuilder = DataDesignerConfigBuilder()\n\n# Generate Python code\nbuilder.add_column(\n    LLMCodeColumnConfig(\n        name=\"sorting_algorithm\",\n        prompt=\"Write a Python function to sort a list using bubble sort.\",\n        code_lang=\"python\",\n        model_alias=\"my-model\"\n    )\n)\n\n# Validate the generated code\nbuilder.add_column(\n    ValidationColumnConfig(\n        name=\"code_validation\",\n        target_columns=[\"sorting_algorithm\"],\n        validator_type=\"code\",\n        validator_params=CodeValidatorParams(code_lang=CodeLang.PYTHON),\n        batch_size=10,\n        drop=False,\n    )\n)\n</code></pre> <p>The <code>target_columns</code> parameter specifies which columns to validate. All target columns are passed to the validator together (except for code validators, which process each column separately).</p>"},{"location":"concepts/validators/#configuration-parameters","title":"Configuration Parameters","text":"<p>See more about parameters used to instantiate <code>ValidationColumnConfig</code> in the code reference.</p>"},{"location":"concepts/validators/#batch-size-considerations","title":"Batch Size Considerations","text":"<p>Larger batch sizes improve efficiency but consume more memory:</p> <ul> <li>Code validators: 5-20 records (file I/O overhead)</li> <li>Local callable: 10-50 records (depends on function complexity)</li> <li>Remote validators: 1-10 records (network latency, server capacity)</li> </ul> <p>Adjust based on:</p> <ul> <li>Validator computational cost</li> <li>Available memory</li> <li>Network bandwidth (for remote validators)</li> <li>Server rate limits</li> </ul> <p>If the validation logic uses information from other samples, only samples in the batch will be considered.</p>"},{"location":"concepts/validators/#multiple-column-validation","title":"Multiple Column Validation","text":"<p>Validate multiple columns simultaneously:</p> <pre><code>from data_designer.essentials import RemoteValidatorParams, ValidationColumnConfig\n\nbuilder.add_column(\n    ValidationColumnConfig(\n        name=\"multi_column_validation\",\n        target_columns=[\"column_a\", \"column_b\", \"column_c\"],\n        validator_type=\"remote\",\n        validator_params=RemoteValidatorParams(\n            endpoint_url=\"https://api.example.com/validate\"\n        )\n    )\n)\n</code></pre> <p>Note: Code validators always process each target column separately, even when multiple columns are specified. Local callable and remote validators receive all target columns together.</p>"},{"location":"concepts/validators/#see-also","title":"See Also","text":"<ul> <li>Validator Parameters Reference: Configuration object schemas</li> </ul>"},{"location":"concepts/models/configure-model-settings-with-the-cli/","title":"Configuring Model Settings Using The CLI","text":"<p>The Data Designer CLI provides an interactive interface for creating and managing default model providers and model configurations stored in your Data Designer home directory (default: <code>~/.data-designer/</code>).</p>"},{"location":"concepts/models/configure-model-settings-with-the-cli/#configuration-files","title":"Configuration Files","text":"<p>The CLI manages two YAML configuration files:</p> <ul> <li><code>model_providers.yaml</code>: Model provider configurations</li> <li><code>model_configs.yaml</code>: Model configurations</li> </ul> <p>Automatic Configuration</p> <p>If these configuration files don't already exist, the Data Designer library automatically creates them with default settings at runtime when first initialized.</p> <p>Custom Directory</p> <p>You can customize the configuration directory location with the <code>DATA_DESIGNER_HOME</code> environment variable: <pre><code>export DATA_DESIGNER_HOME=\"/path/to/your/custom/directory\"\n</code></pre></p>"},{"location":"concepts/models/configure-model-settings-with-the-cli/#cli-commands","title":"CLI Commands","text":"<p>The Data Designer CLI provides four main configuration commands:</p> <pre><code># Configure model providers\ndata-designer config providers\n\n# Configure models\ndata-designer config models\n\n# List current configurations\ndata-designer config list\n\n# Reset all configurations\ndata-designer config reset\n</code></pre> <p>Getting help</p> <p>See available commands <pre><code>data-designer --help\n</code></pre></p> <p>See available sub-commands <pre><code>data-designer config --help\n</code></pre></p>"},{"location":"concepts/models/configure-model-settings-with-the-cli/#managing-model-providers","title":"Managing Model Providers","text":"<p>Run the interactive provider configuration command:</p> <pre><code>data-designer config providers\n</code></pre>"},{"location":"concepts/models/configure-model-settings-with-the-cli/#available-operations","title":"Available Operations","text":"<p>Add a new provider: Define a new provider by entering its name, endpoint URL, provider type, and optionally an API key (as plain text or as an environment variable name).</p> <p>Update an existing provider: Modify an existing provider's settings. All fields are pre-filled with current values.</p> <p>Delete a provider: Remove a provider and its associated models.</p> <p>Delete all providers: Remove all providers and their associated models.</p> <p>Change default provider: Set which provider is used by default. This option is only available when multiple providers are configured.</p>"},{"location":"concepts/models/configure-model-settings-with-the-cli/#managing-model-configurations","title":"Managing Model Configurations","text":"<p>Run the interactive model configuration command:</p> <pre><code>data-designer config models\n</code></pre> <p>Provider Required</p> <p>You need at least one provider configured before adding models. Run <code>data-designer config providers</code> first if none exist.</p>"},{"location":"concepts/models/configure-model-settings-with-the-cli/#available-operations_1","title":"Available Operations","text":"<p>Add a new model configuration</p> <p>Create a new model configuration with the following fields:</p> <ul> <li>Alias: A unique name for referencing this model in a column configuration.</li> <li>Model ID: The model identifier (e.g., <code>nvidia/nvidia-nemotron-nano-9b-v2</code>)</li> <li>Provider: Select from available providers (if multiple exist)</li> <li>Temperature: Sampling temperature (0.0 to 2.0)</li> <li>Top P: Nucleus sampling parameter (0.0 to 1.0)</li> <li>Max Tokens: Maximum output length (1 to 100000)</li> </ul> <p>Additional Settings</p> <p>To configure additional inference parameter settings or use distribution-based inference parameters, edit the <code>model_configs.yaml</code> file directly.</p> <p>Update an existing model configuration: Modify an existing model's configuration. All fields are pre-filled with current values.</p> <p>Delete a model configuration: Remove a single model configuration.</p> <p>Delete all model configurations: Remove all model configurations. The CLI will ask for confirmation before proceeding.</p>"},{"location":"concepts/models/configure-model-settings-with-the-cli/#listing-configurations","title":"Listing Configurations","text":"<p>View all current configurations:</p> <pre><code>data-designer config list\n</code></pre> <p>This command displays:</p> <ul> <li>Model Providers: All configured providers with their endpoints (API keys are masked)</li> <li>Default Provider: The currently selected default provider</li> <li>Model Configurations: All configured models with their settings</li> </ul>"},{"location":"concepts/models/configure-model-settings-with-the-cli/#resetting-configurations","title":"Resetting Configurations","text":"<p>Delete all configuration files:</p> <pre><code>data-designer config reset\n</code></pre> <p>The CLI will show which configuration files exist and ask for confirmation before deleting them.</p> <p>Destructive Operation</p> <p>This command permanently deletes all configuration files and resets to the default model providers and configurations. You'll need to reconfigure your custom configurations from scratch.</p>"},{"location":"concepts/models/configure-model-settings-with-the-cli/#see-also","title":"See Also","text":"<ul> <li>Model Providers: Learn about the <code>ModelProvider</code> class and provider configuration</li> <li>Model Configurations: Learn about <code>ModelConfig</code> and <code>InferenceParameters</code></li> <li>Default Model Settings: Pre-configured providers and model settings included with Data Designer</li> <li>Quick Start Guide: Get started with a simple example</li> </ul>"},{"location":"concepts/models/default-model-settings/","title":"Default Model Settings","text":"<p>Data Designer ships with pre-configured model providers and model configurations that make it easy to start generating synthetic data without manual setup.</p>"},{"location":"concepts/models/default-model-settings/#model-providers","title":"Model Providers","text":"<p>Data Designer includes two default model providers that are configured automatically:</p>"},{"location":"concepts/models/default-model-settings/#nvidia-provider-nvidia","title":"NVIDIA Provider (<code>nvidia</code>)","text":"<ul> <li>Endpoint: <code>https://integrate.api.nvidia.com/v1</code></li> <li>API Key: Set via <code>NVIDIA_API_KEY</code> environment variable</li> <li>Models: Access to NVIDIA's hosted models from build.nvidia.com</li> <li>Getting Started: Sign up and get your API key at build.nvidia.com</li> </ul> <p>The NVIDIA provider gives you access to state-of-the-art models including Nemotron and other NVIDIA-optimized models.</p>"},{"location":"concepts/models/default-model-settings/#openai-provider-openai","title":"OpenAI Provider (<code>openai</code>)","text":"<ul> <li>Endpoint: <code>https://api.openai.com/v1</code></li> <li>API Key: Set via <code>OPENAI_API_KEY</code> environment variable</li> <li>Models: Access to OpenAI's model catalog</li> <li>Getting Started: Get your API key from platform.openai.com/api-keys</li> </ul> <p>The OpenAI provider gives you access to GPT models and other OpenAI offerings.</p>"},{"location":"concepts/models/default-model-settings/#model-configurations","title":"Model Configurations","text":"<p>Data Designer provides pre-configured model aliases for common use cases. When you create a <code>DataDesignerConfigBuilder</code> without specifying <code>model_configs</code>, these default configurations are automatically available.</p>"},{"location":"concepts/models/default-model-settings/#nvidia-models","title":"NVIDIA Models","text":"<p>The following model configurations are automatically available when <code>NVIDIA_API_KEY</code> is set:</p> Alias Model Use Case Temperature Top P <code>nvidia-text</code> <code>nvidia/nvidia-nemotron-nano-9b-v2</code> General text generation 0.85 0.95 <code>nvidia-reasoning</code> <code>openai/gpt-oss-20b</code> Reasoning and analysis tasks 0.35 0.95 <code>nvidia-vision</code> <code>nvidia/nemotron-nano-12b-v2-vl</code> Vision and image understanding 0.85 0.95"},{"location":"concepts/models/default-model-settings/#openai-models","title":"OpenAI Models","text":"<p>The following model configurations are automatically available when <code>OPENAI_API_KEY</code> is set:</p> Alias Model Use Case Temperature Top P <code>openai-text</code> <code>gpt-4.1</code> General text generation 0.85 0.95 <code>openai-reasoning</code> <code>gpt-5</code> Reasoning and analysis tasks 0.35 0.95 <code>openai-vision</code> <code>gpt-5</code> Vision and image understanding 0.85 0.95"},{"location":"concepts/models/default-model-settings/#how-default-model-providers-and-configurations-work","title":"How Default Model Providers and Configurations Work","text":"<p>When the Data Designer library or the CLI is initialized, default model configurations and providers are stored in the Data Designer home directory for easy access and customization if they do not already exist. These configuration files serve as the single source of truth for model settings. By default they are saved to the following paths:</p> <ul> <li>Model Configs: <code>~/.data-designer/model_configs.yaml</code></li> <li>Model Providers: <code>~/.data-designer/model_providers.yaml</code></li> </ul> <p>Tip</p> <p>While these files provide a convenient way to specify settings for your model providers and configuration you use most often, they can always be set programatically in your SDG workflow.</p> <p>You can customize the home directory location by setting the <code>DATA_DESIGNER_HOME</code> environment variable:</p> <pre><code># In your .bashrc, .zshrc, or similar\nexport DATA_DESIGNER_HOME=\"/path/to/your/custom/directory\"\n</code></pre> <p>These configuration files can be modified in two ways:</p> <ol> <li>Using the CLI: Run CLI commands to add, update, or delete model configurations and providers</li> <li>Manual editing: Directly edit the YAML files with your preferred text editor</li> </ol> <p>Both methods operate on the same files, ensuring consistency across your entire Data Designer setup.</p>"},{"location":"concepts/models/default-model-settings/#important-notes","title":"Important Notes","text":"<p>API Key Requirements</p> <p>While default model configurations are always available, you need to set the appropriate API key environment variable (<code>NVIDIA_API_KEY</code> or <code>OPENAI_API_KEY</code>) to actually use the corresponding models for data generation. Without a valid API key, any attempt to generate data using that provider's models will fail.</p> <p>Environment Variables</p> <p>Store your API keys in environment variables rather than hardcoding them in your scripts:</p> <pre><code># In your .bashrc, .zshrc, or similar\nexport NVIDIA_API_KEY=\"your-api-key-here\"\nexport OPENAI_API_KEY=\"your-openai-api-key-here\"\n</code></pre>"},{"location":"concepts/models/default-model-settings/#see-also","title":"See Also","text":"<ul> <li>Configure Model Settings With the CLI: Learn how to use the CLI to manage model settings.</li> <li>Quick Start Guide: Get started with a simple example</li> <li>Model Configurations: Learn about model configurations</li> </ul>"},{"location":"concepts/models/model-configs/","title":"Model Configurations","text":"<p>Model configurations define the specific models you use for synthetic data generation and their associated inference parameters. Each <code>ModelConfig</code> represents a named model that can be referenced throughout your data generation workflows.</p>"},{"location":"concepts/models/model-configs/#overview","title":"Overview","text":"<p>A <code>ModelConfig</code> specifies which LLM model to use and how it should behave during generation. When you create column configurations (like <code>LLMText</code>, <code>LLMCode</code>, or <code>LLMStructured</code>), you reference a model by its alias. Data Designer uses the model configuration to determine which model to call and with what parameters.</p>"},{"location":"concepts/models/model-configs/#modelconfig-structure","title":"ModelConfig Structure","text":"<p>The <code>ModelConfig</code> class has the following fields:</p> Field Type Required Description <code>alias</code> <code>str</code> Yes Unique identifier for this model configuration (e.g., <code>\"my-text-model\"</code>, <code>\"reasoning-model\"</code>) <code>model</code> <code>str</code> Yes Model identifier as recognized by the provider (e.g., <code>\"nvidia/nvidia-nemotron-nano-9b-v2\"</code>, <code>\"gpt-4\"</code>) <code>inference_parameters</code> <code>InferenceParameters</code> No Controls model behavior during generation (temperature, top_p, max_tokens, etc). Defaults from constructing an empty <code>InferenceParameters</code> object are picked up when not provided. <code>provider</code> <code>str</code> No Reference to the name of the Provider to use (e.g., <code>\"nvidia\"</code>, <code>\"openai\"</code>). If not specified, one set as the default provider, which may resolve to the first provider if there are more than one"},{"location":"concepts/models/model-configs/#inferenceparameters","title":"InferenceParameters","text":"<p>The <code>InferenceParameters</code> class controls how the model generates responses. It provides fine-grained control over generation behavior and supports both static values and dynamic distribution-based sampling.</p>"},{"location":"concepts/models/model-configs/#fields","title":"Fields","text":"Field Type Required Description <code>temperature</code> <code>float</code> or <code>Distribution</code> No Controls randomness in generation (0.0 to 2.0). Higher values = more creative/random <code>top_p</code> <code>float</code> or <code>Distribution</code> No Nucleus sampling parameter (0.0 to 1.0). Controls diversity by filtering low-probability tokens <code>max_tokens</code> <code>int</code> No Maximum number of tokens for the request, including both input and output tokens (\u2265 1) <code>max_parallel_requests</code> <code>int</code> No Maximum concurrent API requests (default: 4, \u2265 1) <code>timeout</code> <code>int</code> No API request timeout in seconds (\u2265 1) <code>extra_body</code> <code>dict[str, Any]</code> No Additional parameters to include in the API request body <p>Default Values</p> <p>If <code>temperature</code>, <code>top_p</code>, or <code>max_tokens</code> are not provided, the model provider's default values will be used. Different providers and models may have different defaults.</p> <p>Controlling Reasoning Effort for GPT-OSS Models</p> <p>For gpt-oss models like <code>gpt-oss-20b</code> and <code>gpt-oss-120b</code>, you can control the reasoning effort using the <code>extra_body</code> parameter:</p> <pre><code># High reasoning effort (more thorough, slower)\ninference_parameters = InferenceParameters(\n    extra_body={\"reasoning_effort\": \"high\"}\n)\n\n# Medium reasoning effort (balanced)\ninference_parameters = InferenceParameters(\n    extra_body={\"reasoning_effort\": \"medium\"}\n)\n\n# Low reasoning effort (faster, less thorough)\ninference_parameters = InferenceParameters(\n    extra_body={\"reasoning_effort\": \"low\"}\n)\n</code></pre>"},{"location":"concepts/models/model-configs/#temperature-and-top-p-guidelines","title":"Temperature and Top P Guidelines","text":"<ul> <li> <p>Temperature:</p> <ul> <li><code>0.0-0.3</code>: Highly deterministic, focused outputs (ideal for structured/reasoning tasks)</li> <li><code>0.4-0.7</code>: Balanced creativity and coherence (general purpose)</li> <li><code>0.8-1.0</code>: Creative, diverse outputs (ideal for creative writing)</li> <li><code>1.0+</code>: Highly random and experimental</li> </ul> </li> <li> <p>Top P:</p> <ul> <li><code>0.1-0.5</code>: Very focused, only most likely tokens</li> <li><code>0.6-0.9</code>: Balanced diversity</li> <li><code>0.95-1.0</code>: Maximum diversity, including less likely tokens</li> </ul> </li> </ul> <p>Adjusting Temperature and Top P Together</p> <p>When tuning both parameters simultaneously, consider these combinations:</p> <ul> <li>For deterministic/structured outputs: Low temperature (<code>0.0-0.3</code>) + moderate-to-high top_p (<code>0.8-0.95</code>)<ul> <li>The low temperature ensures focus, while top_p allows some token diversity</li> </ul> </li> <li>For balanced generation: Moderate temperature (<code>0.5-0.7</code>) + high top_p (<code>0.9-0.95</code>)<ul> <li>This is a good starting point for most use cases</li> </ul> </li> <li>For creative outputs: Higher temperature (<code>0.8-1.0</code>) + high top_p (<code>0.95-1.0</code>)<ul> <li>Both parameters work together to maximize diversity</li> </ul> </li> </ul> <p>Avoid: Setting both very low (overly restrictive) or adjusting both dramatically at once. When experimenting, adjust one parameter at a time to understand its individual effect.</p>"},{"location":"concepts/models/model-configs/#distribution-based-inference-parameters","title":"Distribution-Based Inference Parameters","text":"<p>For <code>temperature</code> and <code>top_p</code>, you can specify distributions instead of fixed values. This allows Data Designer to sample different values for each generation request, introducing controlled variability into your synthetic data.</p>"},{"location":"concepts/models/model-configs/#uniform-distribution","title":"Uniform Distribution","text":"<p>Samples values uniformly between a low and high bound:</p> <pre><code>from data_designer.essentials import (\n    InferenceParameters,\n    UniformDistribution,\n    UniformDistributionParams,\n)\n\ninference_params = InferenceParameters(\n    temperature=UniformDistribution(\n        params=UniformDistributionParams(low=0.7, high=1.0)\n    ),\n)\n</code></pre>"},{"location":"concepts/models/model-configs/#manual-distribution","title":"Manual Distribution","text":"<p>Samples from a discrete set of values with optional weights:</p> <pre><code>from data_designer.essentials import (\n    InferenceParameters,\n    ManualDistribution,\n    ManualDistributionParams,\n)\n\n# Equal probability for each value\ninference_params = InferenceParameters(\n    temperature=ManualDistribution(\n        params=ManualDistributionParams(values=[0.5, 0.7, 0.9])\n    ),\n)\n\n# Weighted probabilities (normalized automatically)\ninference_params = InferenceParameters(\n    top_p=ManualDistribution(\n        params=ManualDistributionParams(\n            values=[0.8, 0.9, 0.95],\n            weights=[0.2, 0.5, 0.3]  # 20%, 50%, 30% probability\n        )\n    ),\n)\n</code></pre>"},{"location":"concepts/models/model-configs/#examples","title":"Examples","text":""},{"location":"concepts/models/model-configs/#basic-model-configuration","title":"Basic Model Configuration","text":"<pre><code>from data_designer.essentials import InferenceParameters, ModelConfig\n\n# Simple model configuration with fixed parameters\nmodel_config = ModelConfig(\n    alias=\"my-text-model\",\n    model=\"nvidia/nvidia-nemotron-nano-9b-v2\",\n    provider=\"nvidia\",\n    inference_parameters=InferenceParameters(\n        temperature=0.85,\n        top_p=0.95,\n        max_tokens=2048,\n    ),\n)\n</code></pre>"},{"location":"concepts/models/model-configs/#multiple-model-configurations-for-different-tasks","title":"Multiple Model Configurations for Different Tasks","text":"<pre><code>from data_designer.essentials import InferenceParameters, ModelConfig\n\nmodel_configs = [\n    # Creative tasks\n    ModelConfig(\n        alias=\"creative-model\",\n        model=\"nvidia/nvidia-nemotron-nano-9b-v2\",\n        provider=\"nvidia\",\n        inference_parameters=InferenceParameters(\n            temperature=0.9,\n            top_p=0.95,\n            max_tokens=2048,\n        ),\n    ),\n    # Critic tasks\n    ModelConfig(\n        alias=\"critic-model\",\n        model=\"nvidia/nvidia-nemotron-nano-9b-v2\",\n        provider=\"nvidia\",\n        inference_parameters=InferenceParameters(\n            temperature=0.25,\n            top_p=0.95,\n            max_tokens=2048,\n        ),\n    ),\n    # Reasoning and structured tasks\n    ModelConfig(\n        alias=\"reasoning-model\",\n        model=\"openai/gpt-oss-20b\",\n        provider=\"nvidia\",\n        inference_parameters=InferenceParameters(\n            temperature=0.3,\n            top_p=0.9,\n            max_tokens=4096,\n        ),\n    ),\n    # Vision tasks\n    ModelConfig(\n        alias=\"vision-model\",\n        model=\"nvidia/nemotron-nano-12b-v2-vl\",\n        provider=\"nvidia\",\n        inference_parameters=InferenceParameters(\n            temperature=0.7,\n            top_p=0.95,\n            max_tokens=2048,\n        ),\n    ),\n]\n</code></pre> <p>Experiment with max_tokens for Task-Specific model configurations</p> <p>The number of tokens required to generate a single data entry can vary significantly with use case. For example, reasoning models often need more tokens to \"think through\" problems before generating a response. Note that <code>max_tokens</code> includes both input and output tokens (the total context window used), so factor in your prompt length, any context data, and the expected response length when setting this parameter.</p>"},{"location":"concepts/models/model-configs/#using-distribution-based-parameters","title":"Using Distribution-Based Parameters","text":"<pre><code>from data_designer.essentials import (\n    InferenceParameters,\n    ManualDistribution,\n    ManualDistributionParams,\n    ModelConfig,\n    UniformDistribution,\n    UniformDistributionParams,\n)\n\n# Model with variable temperature and top_p\nmodel_config = ModelConfig(\n    alias=\"variable-model\",\n    model=\"nvidia/nvidia-nemotron-nano-9b-v2\",\n    inference_parameters=InferenceParameters(\n        # Temperature varies uniformly between 0.7 and 1.0\n        temperature=UniformDistribution(\n            params=UniformDistributionParams(low=0.7, high=1.0)\n        ),\n        # Top P samples from discrete values with equal probability\n        top_p=ManualDistribution(\n            params=ManualDistributionParams(values=[0.85, 0.90, 0.95])\n        ),\n        max_tokens=2048,\n    ),\n)\n</code></pre>"},{"location":"concepts/models/model-configs/#see-also","title":"See Also","text":"<ul> <li>Model Providers: Learn about configuring model providers</li> <li>Default Model Settings: Pre-configured model settings included with Data Designer</li> <li>Configure Model Settings With the CLI: Use the CLI to manage model settings</li> <li>Column Configurations: Learn how to use models in column configurations</li> </ul>"},{"location":"concepts/models/model-providers/","title":"Model Providers","text":"<p>Model providers are external services that host and serve models. Data Designer uses the <code>ModelProvider</code> class to configure connections to these services.</p>"},{"location":"concepts/models/model-providers/#overview","title":"Overview","text":"<p>A <code>ModelProvider</code> defines how Data Designer connects to a provider's API endpoint. When you create a <code>ModelConfig</code>, you reference a provider by name, and Data Designer uses that provider's settings to make API calls to the appropriate endpoint.</p>"},{"location":"concepts/models/model-providers/#modelprovider-configuration","title":"ModelProvider Configuration","text":"<p>The <code>ModelProvider</code> class has the following fields:</p> Field Type Required Description <code>name</code> <code>str</code> Yes Unique identifier for the provider (e.g., <code>\"nvidia\"</code>, <code>\"openai\"</code>) <code>endpoint</code> <code>str</code> Yes API endpoint URL (e.g., <code>\"https://integrate.api.nvidia.com/v1\"</code>) <code>provider_type</code> <code>str</code> No Provider type (default: <code>\"openai\"</code>). Uses OpenAI-compatible API format <code>api_key</code> <code>str</code> No API key or environment variable name (e.g., <code>\"NVIDIA_API_KEY\"</code>) <code>extra_body</code> <code>dict[str, Any]</code> No Additional parameters to include in the request body of all API requests to the provider."},{"location":"concepts/models/model-providers/#api-key-configuration","title":"API Key Configuration","text":"<p>The <code>api_key</code> field can be specified in two ways:</p> <ol> <li> <p>Environment variable name (recommended): Set <code>api_key</code> to the name of an environment variable (e.g., <code>\"NVIDIA_API_KEY\"</code>). Data Designer will automatically resolve it at runtime.</p> </li> <li> <p>Plain-text value: Set <code>api_key</code> to the actual API key string. This is less secure and not recommended for production use.</p> </li> </ol> <pre><code># Method 1: Environment variable (recommended)\nprovider = ModelProvider(\n    name=\"nvidia\",\n    endpoint=\"https://integrate.api.nvidia.com/v1\",\n    api_key=\"NVIDIA_API_KEY\",  # Will be resolved from environment\n)\n\n# Method 2: Direct value (not recommended)\nprovider = ModelProvider(\n    name=\"nvidia\",\n    endpoint=\"https://integrate.api.nvidia.com/v1\",\n    api_key=\"nvapi-abc123...\",  # Direct API key\n)\n</code></pre>"},{"location":"concepts/models/model-providers/#see-also","title":"See Also","text":"<ul> <li>Model Configurations: Learn about configuring models and inference parameters</li> <li>Default Model Settings: Pre-configured providers and model settings included with Data Designer</li> <li>Configure Model Settings With the CLI: Use the CLI to manage providers and model settings</li> <li>Quick Start Guide: Get started with a simple example</li> </ul>"},{"location":"notebook_source/","title":"\ud83d\udcd3 Notebooks in <code>.py</code> Format","text":"<p>In this folder you can find all our tutorial notebooks in <code>.py</code> format. They can be converted to actual Jupyter notebooks by typing</p> <pre><code>make convert-execute-notebooks\n</code></pre> <p>from the root of the repository. This will not only convert but also execute all of the notebooks -- for that to work, make sure you went through our Quick Start and have API keys set. A new folder <code>docs/notebooks</code> will be created, including <code>README.md</code> and <code>pyproject.toml</code> files.</p> <p>Alternatively, you can use Jupytext directly</p> <pre><code>uv run --group notebooks --group docs jupytext --to ipynb *.py\n</code></pre>"},{"location":"notebook_source/#converting-jupyter-notebooks-to-py","title":"\ud83d\udd04 Converting Jupyter notebooks to <code>.py</code>","text":"<p>If you want to contribute with your own notebook, you can use the following command to generate <code>.py</code> files in the same format as the ones in this folder:</p> <pre><code>uv run jupytext --to py [notebook-name].ipynb -o [notebook-name].py\n</code></pre>"},{"location":"notebook_source/1-the-basics/","title":"1 the basics","text":"In\u00a0[\u00a0]: Copied! <pre>from data_designer.essentials import (\n    CategorySamplerParams,\n    DataDesigner,\n    DataDesignerConfigBuilder,\n    InferenceParameters,\n    LLMTextColumnConfig,\n    ModelConfig,\n    PersonFromFakerSamplerParams,\n    SamplerColumnConfig,\n    SamplerType,\n    SubcategorySamplerParams,\n    UniformSamplerParams,\n)\n</pre> from data_designer.essentials import (     CategorySamplerParams,     DataDesigner,     DataDesignerConfigBuilder,     InferenceParameters,     LLMTextColumnConfig,     ModelConfig,     PersonFromFakerSamplerParams,     SamplerColumnConfig,     SamplerType,     SubcategorySamplerParams,     UniformSamplerParams, ) In\u00a0[\u00a0]: Copied! <pre>data_designer = DataDesigner()\n</pre> data_designer = DataDesigner() In\u00a0[\u00a0]: Copied! <pre># This name is set in the model provider configuration.\nMODEL_PROVIDER = \"nvidia\"\n\n# The model ID is from build.nvidia.com.\nMODEL_ID = \"nvidia/nvidia-nemotron-nano-9b-v2\"\n\n# We choose this alias to be descriptive for our use case.\nMODEL_ALIAS = \"nemotron-nano-v2\"\n\n# This sets reasoning to False for the nemotron-nano-v2 model.\nSYSTEM_PROMPT = \"/no_think\"\n\nmodel_configs = [\n    ModelConfig(\n        alias=MODEL_ALIAS,\n        model=MODEL_ID,\n        provider=MODEL_PROVIDER,\n        inference_parameters=InferenceParameters(\n            temperature=0.5,\n            top_p=1.0,\n            max_tokens=1024,\n        ),\n    )\n]\n</pre> # This name is set in the model provider configuration. MODEL_PROVIDER = \"nvidia\"  # The model ID is from build.nvidia.com. MODEL_ID = \"nvidia/nvidia-nemotron-nano-9b-v2\"  # We choose this alias to be descriptive for our use case. MODEL_ALIAS = \"nemotron-nano-v2\"  # This sets reasoning to False for the nemotron-nano-v2 model. SYSTEM_PROMPT = \"/no_think\"  model_configs = [     ModelConfig(         alias=MODEL_ALIAS,         model=MODEL_ID,         provider=MODEL_PROVIDER,         inference_parameters=InferenceParameters(             temperature=0.5,             top_p=1.0,             max_tokens=1024,         ),     ) ] In\u00a0[\u00a0]: Copied! <pre>config_builder = DataDesignerConfigBuilder(model_configs=model_configs)\n</pre> config_builder = DataDesignerConfigBuilder(model_configs=model_configs) In\u00a0[\u00a0]: Copied! <pre>config_builder.info.display(\"samplers\")\n</pre> config_builder.info.display(\"samplers\") <p>Let's start designing our product review dataset by adding product category and subcategory columns.</p> In\u00a0[\u00a0]: Copied! <pre>config_builder.add_column(\n    SamplerColumnConfig(\n        name=\"product_category\",\n        sampler_type=SamplerType.CATEGORY,\n        params=CategorySamplerParams(\n            values=[\n                \"Electronics\",\n                \"Clothing\",\n                \"Home &amp; Kitchen\",\n                \"Books\",\n                \"Home Office\",\n            ],\n        ),\n    )\n)\n\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"product_subcategory\",\n        sampler_type=SamplerType.SUBCATEGORY,\n        params=SubcategorySamplerParams(\n            category=\"product_category\",\n            values={\n                \"Electronics\": [\n                    \"Smartphones\",\n                    \"Laptops\",\n                    \"Headphones\",\n                    \"Cameras\",\n                    \"Accessories\",\n                ],\n                \"Clothing\": [\n                    \"Men's Clothing\",\n                    \"Women's Clothing\",\n                    \"Winter Coats\",\n                    \"Activewear\",\n                    \"Accessories\",\n                ],\n                \"Home &amp; Kitchen\": [\n                    \"Appliances\",\n                    \"Cookware\",\n                    \"Furniture\",\n                    \"Decor\",\n                    \"Organization\",\n                ],\n                \"Books\": [\n                    \"Fiction\",\n                    \"Non-Fiction\",\n                    \"Self-Help\",\n                    \"Textbooks\",\n                    \"Classics\",\n                ],\n                \"Home Office\": [\n                    \"Desks\",\n                    \"Chairs\",\n                    \"Storage\",\n                    \"Office Supplies\",\n                    \"Lighting\",\n                ],\n            },\n        ),\n    )\n)\n\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"target_age_range\",\n        sampler_type=SamplerType.CATEGORY,\n        params=CategorySamplerParams(values=[\"18-25\", \"25-35\", \"35-50\", \"50-65\", \"65+\"]),\n    )\n)\n\n# Optionally validate that the columns are configured correctly.\nconfig_builder.validate()\n</pre> config_builder.add_column(     SamplerColumnConfig(         name=\"product_category\",         sampler_type=SamplerType.CATEGORY,         params=CategorySamplerParams(             values=[                 \"Electronics\",                 \"Clothing\",                 \"Home &amp; Kitchen\",                 \"Books\",                 \"Home Office\",             ],         ),     ) )  config_builder.add_column(     SamplerColumnConfig(         name=\"product_subcategory\",         sampler_type=SamplerType.SUBCATEGORY,         params=SubcategorySamplerParams(             category=\"product_category\",             values={                 \"Electronics\": [                     \"Smartphones\",                     \"Laptops\",                     \"Headphones\",                     \"Cameras\",                     \"Accessories\",                 ],                 \"Clothing\": [                     \"Men's Clothing\",                     \"Women's Clothing\",                     \"Winter Coats\",                     \"Activewear\",                     \"Accessories\",                 ],                 \"Home &amp; Kitchen\": [                     \"Appliances\",                     \"Cookware\",                     \"Furniture\",                     \"Decor\",                     \"Organization\",                 ],                 \"Books\": [                     \"Fiction\",                     \"Non-Fiction\",                     \"Self-Help\",                     \"Textbooks\",                     \"Classics\",                 ],                 \"Home Office\": [                     \"Desks\",                     \"Chairs\",                     \"Storage\",                     \"Office Supplies\",                     \"Lighting\",                 ],             },         ),     ) )  config_builder.add_column(     SamplerColumnConfig(         name=\"target_age_range\",         sampler_type=SamplerType.CATEGORY,         params=CategorySamplerParams(values=[\"18-25\", \"25-35\", \"35-50\", \"50-65\", \"65+\"]),     ) )  # Optionally validate that the columns are configured correctly. config_builder.validate() <p>Next, let's add samplers to generate data related to the customer and their review.</p> In\u00a0[\u00a0]: Copied! <pre>config_builder.add_column(\n    SamplerColumnConfig(\n        name=\"customer\",\n        sampler_type=SamplerType.PERSON_FROM_FAKER,\n        params=PersonFromFakerSamplerParams(age_range=[18, 70], locale=\"en_US\"),\n    )\n)\n\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"number_of_stars\",\n        sampler_type=SamplerType.UNIFORM,\n        params=UniformSamplerParams(low=1, high=5),\n        convert_to=\"int\",  # Convert the sampled float to an integer.\n    )\n)\n\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"review_style\",\n        sampler_type=SamplerType.CATEGORY,\n        params=CategorySamplerParams(\n            values=[\"rambling\", \"brief\", \"detailed\", \"structured with bullet points\"],\n            weights=[1, 2, 2, 1],\n        ),\n    )\n)\n\nconfig_builder.validate()\n</pre> config_builder.add_column(     SamplerColumnConfig(         name=\"customer\",         sampler_type=SamplerType.PERSON_FROM_FAKER,         params=PersonFromFakerSamplerParams(age_range=[18, 70], locale=\"en_US\"),     ) )  config_builder.add_column(     SamplerColumnConfig(         name=\"number_of_stars\",         sampler_type=SamplerType.UNIFORM,         params=UniformSamplerParams(low=1, high=5),         convert_to=\"int\",  # Convert the sampled float to an integer.     ) )  config_builder.add_column(     SamplerColumnConfig(         name=\"review_style\",         sampler_type=SamplerType.CATEGORY,         params=CategorySamplerParams(             values=[\"rambling\", \"brief\", \"detailed\", \"structured with bullet points\"],             weights=[1, 2, 2, 1],         ),     ) )  config_builder.validate() In\u00a0[\u00a0]: Copied! <pre>config_builder.add_column(\n    LLMTextColumnConfig(\n        name=\"product_name\",\n        prompt=(\n            \"You are a helpful assistant that generates product names. DO NOT add quotes around the product name.\\n\\n\"\n            \"Come up with a creative product name for a product in the '{{ product_category }}' category, focusing \"\n            \"on products related to '{{ product_subcategory }}'. The target age range of the ideal customer is \"\n            \"{{ target_age_range }} years old. Respond with only the product name, no other text.\"\n        ),\n        system_prompt=SYSTEM_PROMPT,\n        model_alias=MODEL_ALIAS,\n    )\n)\n\nconfig_builder.add_column(\n    LLMTextColumnConfig(\n        name=\"customer_review\",\n        prompt=(\n            \"You are a customer named {{ customer.first_name }} from {{ customer.city }}, {{ customer.state }}. \"\n            \"You are {{ customer.age }} years old and recently purchased a product called {{ product_name }}. \"\n            \"Write a review of this product, which you gave a rating of {{ number_of_stars }} stars. \"\n            \"The style of the review should be '{{ review_style }}'.\"\n        ),\n        system_prompt=SYSTEM_PROMPT,\n        model_alias=MODEL_ALIAS,\n    )\n)\n\nconfig_builder.validate()\n</pre> config_builder.add_column(     LLMTextColumnConfig(         name=\"product_name\",         prompt=(             \"You are a helpful assistant that generates product names. DO NOT add quotes around the product name.\\n\\n\"             \"Come up with a creative product name for a product in the '{{ product_category }}' category, focusing \"             \"on products related to '{{ product_subcategory }}'. The target age range of the ideal customer is \"             \"{{ target_age_range }} years old. Respond with only the product name, no other text.\"         ),         system_prompt=SYSTEM_PROMPT,         model_alias=MODEL_ALIAS,     ) )  config_builder.add_column(     LLMTextColumnConfig(         name=\"customer_review\",         prompt=(             \"You are a customer named {{ customer.first_name }} from {{ customer.city }}, {{ customer.state }}. \"             \"You are {{ customer.age }} years old and recently purchased a product called {{ product_name }}. \"             \"Write a review of this product, which you gave a rating of {{ number_of_stars }} stars. \"             \"The style of the review should be '{{ review_style }}'.\"         ),         system_prompt=SYSTEM_PROMPT,         model_alias=MODEL_ALIAS,     ) )  config_builder.validate() In\u00a0[\u00a0]: Copied! <pre>preview = data_designer.preview(config_builder, num_records=2)\n</pre> preview = data_designer.preview(config_builder, num_records=2) In\u00a0[\u00a0]: Copied! <pre># Run this cell multiple times to cycle through the 2 preview records.\npreview.display_sample_record()\n</pre> # Run this cell multiple times to cycle through the 2 preview records. preview.display_sample_record() In\u00a0[\u00a0]: Copied! <pre># The preview dataset is available as a pandas DataFrame.\npreview.dataset\n</pre> # The preview dataset is available as a pandas DataFrame. preview.dataset In\u00a0[\u00a0]: Copied! <pre># Print the analysis as a table.\npreview.analysis.to_report()\n</pre> # Print the analysis as a table. preview.analysis.to_report() In\u00a0[\u00a0]: Copied! <pre>results = data_designer.create(config_builder, num_records=10)\n</pre> results = data_designer.create(config_builder, num_records=10) In\u00a0[\u00a0]: Copied! <pre># Load the generated dataset as a pandas DataFrame.\ndataset = results.load_dataset()\n\ndataset.head()\n</pre> # Load the generated dataset as a pandas DataFrame. dataset = results.load_dataset()  dataset.head() In\u00a0[\u00a0]: Copied! <pre># Load the analysis results into memory.\nanalysis = results.load_analysis()\n\nanalysis.to_report()\n</pre> # Load the analysis results into memory. analysis = results.load_analysis()  analysis.to_report()"},{"location":"notebook_source/1-the-basics/#data-designer-tutorial-the-basics","title":"\ud83c\udfa8 Data Designer Tutorial: The Basics\u00b6","text":""},{"location":"notebook_source/1-the-basics/#what-youll-learn","title":"\ud83d\udcda What you'll learn\u00b6","text":"<p>This notebook demonstrates the basics of Data Designer by generating a simple product review dataset.</p>"},{"location":"notebook_source/1-the-basics/#import-the-essentials","title":"\ud83d\udce6 Import the essentials\u00b6","text":"<ul> <li>The <code>essentials</code> module provides quick access to the most commonly used objects.</li> </ul>"},{"location":"notebook_source/1-the-basics/#initialize-the-data-designer-interface","title":"\u2699\ufe0f Initialize the Data Designer interface\u00b6","text":"<ul> <li><p><code>DataDesigner</code> is the main object is responsible for managing the data generation process.</p> </li> <li><p>When initialized without arguments, the default model providers are used.</p> </li> </ul>"},{"location":"notebook_source/1-the-basics/#define-model-configurations","title":"\ud83c\udf9b\ufe0f Define model configurations\u00b6","text":"<ul> <li><p>Each <code>ModelConfig</code> defines a model that can be used during the generation process.</p> </li> <li><p>The \"model alias\" is used to reference the model in the Data Designer config (as we will see below).</p> </li> <li><p>The \"model provider\" is the external service that hosts the model (see the model config docs for more details).</p> </li> <li><p>By default, we use build.nvidia.com as the model provider.</p> </li> </ul>"},{"location":"notebook_source/1-the-basics/#initialize-the-data-designer-config-builder","title":"\ud83c\udfd7\ufe0f Initialize the Data Designer Config Builder\u00b6","text":"<ul> <li><p>The Data Designer config defines the dataset schema and generation process.</p> </li> <li><p>The config builder provides an intuitive interface for building this configuration.</p> </li> <li><p>The list of model configs is provided to the builder at initialization.</p> </li> </ul>"},{"location":"notebook_source/1-the-basics/#getting-started-with-sampler-columns","title":"\ud83c\udfb2 Getting started with sampler columns\u00b6","text":"<ul> <li><p>Sampler columns offer non-LLM based generation of synthetic data.</p> </li> <li><p>They are particularly useful for steering the diversity of the generated data, as we demonstrate below.</p> </li> </ul> <p>You can view available samplers using the config builder's <code>info</code> property:</p>"},{"location":"notebook_source/1-the-basics/#llm-generated-columns","title":"\ud83e\udd9c LLM-generated columns\u00b6","text":"<ul> <li><p>The real power of Data Designer comes from leveraging LLMs to generate text, code, and structured data.</p> </li> <li><p>When prompting the LLM, we can use Jinja templating to reference other columns in the dataset.</p> </li> <li><p>As we see below, nested json fields can be accessed using dot notation.</p> </li> </ul>"},{"location":"notebook_source/1-the-basics/#iteration-is-key-preview-the-dataset","title":"\ud83d\udd01 Iteration is key \u2013\u00a0preview the dataset!\u00b6","text":"<ol> <li><p>Use the <code>preview</code> method to generate a sample of records quickly.</p> </li> <li><p>Inspect the results for quality and format issues.</p> </li> <li><p>Adjust column configurations, prompts, or parameters as needed.</p> </li> <li><p>Re-run the preview until satisfied.</p> </li> </ol>"},{"location":"notebook_source/1-the-basics/#analyze-the-generated-data","title":"\ud83d\udcca Analyze the generated data\u00b6","text":"<ul> <li><p>Data Designer automatically generates a basic statistical analysis of the generated data.</p> </li> <li><p>This analysis is available via the <code>analysis</code> property of generation result objects.</p> </li> </ul>"},{"location":"notebook_source/1-the-basics/#scale-up","title":"\ud83c\udd99 Scale up!\u00b6","text":"<ul> <li><p>Happy with your preview data?</p> </li> <li><p>Use the <code>create</code> method to submit larger Data Designer generation jobs.</p> </li> </ul>"},{"location":"notebook_source/1-the-basics/#next-steps","title":"\u23ed\ufe0f Next Steps\u00b6","text":"<p>Now that you've seen the basics of Data Designer, check out the following notebooks to learn more about:</p> <ul> <li><p>Structured outputs and jinja expressions</p> </li> <li><p>Seeding synthetic data generation with an external dataset</p> </li> </ul>"},{"location":"notebook_source/2-structured-outputs-and-jinja-expressions/","title":"2 structured outputs and jinja expressions","text":"In\u00a0[\u00a0]: Copied! <pre>from data_designer.essentials import (\n    CategorySamplerParams,\n    DataDesigner,\n    DataDesignerConfigBuilder,\n    ExpressionColumnConfig,\n    InferenceParameters,\n    LLMStructuredColumnConfig,\n    ModelConfig,\n    PersonFromFakerSamplerParams,\n    SamplerColumnConfig,\n    SamplerType,\n    SubcategorySamplerParams,\n)\n</pre> from data_designer.essentials import (     CategorySamplerParams,     DataDesigner,     DataDesignerConfigBuilder,     ExpressionColumnConfig,     InferenceParameters,     LLMStructuredColumnConfig,     ModelConfig,     PersonFromFakerSamplerParams,     SamplerColumnConfig,     SamplerType,     SubcategorySamplerParams, ) In\u00a0[\u00a0]: Copied! <pre>data_designer_client = DataDesigner()\n</pre> data_designer_client = DataDesigner() In\u00a0[\u00a0]: Copied! <pre># This name is set in the model provider configuration.\nMODEL_PROVIDER = \"nvidia\"\n\n# The model ID is from build.nvidia.com.\nMODEL_ID = \"nvidia/nvidia-nemotron-nano-9b-v2\"\n\n# We choose this alias to be descriptive for our use case.\nMODEL_ALIAS = \"nemotron-nano-v2\"\n\n# This sets reasoning to False for the nemotron-nano-v2 model.\nSYSTEM_PROMPT = \"/no_think\"\n\nmodel_configs = [\n    ModelConfig(\n        alias=MODEL_ALIAS,\n        model=MODEL_ID,\n        provider=MODEL_PROVIDER,\n        inference_parameters=InferenceParameters(\n            temperature=0.5,\n            top_p=1.0,\n            max_tokens=1024,\n        ),\n    )\n]\n</pre> # This name is set in the model provider configuration. MODEL_PROVIDER = \"nvidia\"  # The model ID is from build.nvidia.com. MODEL_ID = \"nvidia/nvidia-nemotron-nano-9b-v2\"  # We choose this alias to be descriptive for our use case. MODEL_ALIAS = \"nemotron-nano-v2\"  # This sets reasoning to False for the nemotron-nano-v2 model. SYSTEM_PROMPT = \"/no_think\"  model_configs = [     ModelConfig(         alias=MODEL_ALIAS,         model=MODEL_ID,         provider=MODEL_PROVIDER,         inference_parameters=InferenceParameters(             temperature=0.5,             top_p=1.0,             max_tokens=1024,         ),     ) ] In\u00a0[\u00a0]: Copied! <pre>config_builder = DataDesignerConfigBuilder(model_configs=model_configs)\n</pre> config_builder = DataDesignerConfigBuilder(model_configs=model_configs) In\u00a0[\u00a0]: Copied! <pre>from decimal import Decimal\nfrom typing import Literal\n\nfrom pydantic import BaseModel, Field\n\n\n# We define a Product schema so that the name, description, and price are generated\n# in one go, with the types and constraints specified.\nclass Product(BaseModel):\n    name: str = Field(description=\"The name of the product\")\n    description: str = Field(description=\"A description of the product\")\n    price: Decimal = Field(description=\"The price of the product\", ge=10, le=1000, decimal_places=2)\n\n\nclass ProductReview(BaseModel):\n    rating: int = Field(description=\"The rating of the product\", ge=1, le=5)\n    customer_mood: Literal[\"irritated\", \"mad\", \"happy\", \"neutral\", \"excited\"] = Field(\n        description=\"The mood of the customer\"\n    )\n    review: str = Field(description=\"A review of the product\")\n</pre> from decimal import Decimal from typing import Literal  from pydantic import BaseModel, Field   # We define a Product schema so that the name, description, and price are generated # in one go, with the types and constraints specified. class Product(BaseModel):     name: str = Field(description=\"The name of the product\")     description: str = Field(description=\"A description of the product\")     price: Decimal = Field(description=\"The price of the product\", ge=10, le=1000, decimal_places=2)   class ProductReview(BaseModel):     rating: int = Field(description=\"The rating of the product\", ge=1, le=5)     customer_mood: Literal[\"irritated\", \"mad\", \"happy\", \"neutral\", \"excited\"] = Field(         description=\"The mood of the customer\"     )     review: str = Field(description=\"A review of the product\") <p>Next, let's design our product review dataset using a few more tricks compared to the previous notebook.</p> In\u00a0[\u00a0]: Copied! <pre># Since we often only want a few attributes from Person objects, we can\n# set drop=True in the column config to drop the column from the final dataset.\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"customer\",\n        sampler_type=SamplerType.PERSON_FROM_FAKER,\n        params=PersonFromFakerSamplerParams(),\n        drop=True,\n    )\n)\n\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"product_category\",\n        sampler_type=SamplerType.CATEGORY,\n        params=CategorySamplerParams(\n            values=[\n                \"Electronics\",\n                \"Clothing\",\n                \"Home &amp; Kitchen\",\n                \"Books\",\n                \"Home Office\",\n            ],\n        ),\n    )\n)\n\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"product_subcategory\",\n        sampler_type=SamplerType.SUBCATEGORY,\n        params=SubcategorySamplerParams(\n            category=\"product_category\",\n            values={\n                \"Electronics\": [\n                    \"Smartphones\",\n                    \"Laptops\",\n                    \"Headphones\",\n                    \"Cameras\",\n                    \"Accessories\",\n                ],\n                \"Clothing\": [\n                    \"Men's Clothing\",\n                    \"Women's Clothing\",\n                    \"Winter Coats\",\n                    \"Activewear\",\n                    \"Accessories\",\n                ],\n                \"Home &amp; Kitchen\": [\n                    \"Appliances\",\n                    \"Cookware\",\n                    \"Furniture\",\n                    \"Decor\",\n                    \"Organization\",\n                ],\n                \"Books\": [\n                    \"Fiction\",\n                    \"Non-Fiction\",\n                    \"Self-Help\",\n                    \"Textbooks\",\n                    \"Classics\",\n                ],\n                \"Home Office\": [\n                    \"Desks\",\n                    \"Chairs\",\n                    \"Storage\",\n                    \"Office Supplies\",\n                    \"Lighting\",\n                ],\n            },\n        ),\n    )\n)\n\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"target_age_range\",\n        sampler_type=SamplerType.CATEGORY,\n        params=CategorySamplerParams(values=[\"18-25\", \"25-35\", \"35-50\", \"50-65\", \"65+\"]),\n    )\n)\n\n# Sampler columns support conditional params, which are used if the condition is met.\n# In this example, we set the review style to rambling if the target age range is 18-25.\n# Note conditional parameters are only supported for Sampler column types.\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"review_style\",\n        sampler_type=SamplerType.CATEGORY,\n        params=CategorySamplerParams(\n            values=[\"rambling\", \"brief\", \"detailed\", \"structured with bullet points\"],\n            weights=[1, 2, 2, 1],\n        ),\n        conditional_params={\n            \"target_age_range == '18-25'\": CategorySamplerParams(values=[\"rambling\"]),\n        },\n    )\n)\n\n# Optionally validate that the columns are configured correctly.\nconfig_builder.validate()\n</pre> # Since we often only want a few attributes from Person objects, we can # set drop=True in the column config to drop the column from the final dataset. config_builder.add_column(     SamplerColumnConfig(         name=\"customer\",         sampler_type=SamplerType.PERSON_FROM_FAKER,         params=PersonFromFakerSamplerParams(),         drop=True,     ) )  config_builder.add_column(     SamplerColumnConfig(         name=\"product_category\",         sampler_type=SamplerType.CATEGORY,         params=CategorySamplerParams(             values=[                 \"Electronics\",                 \"Clothing\",                 \"Home &amp; Kitchen\",                 \"Books\",                 \"Home Office\",             ],         ),     ) )  config_builder.add_column(     SamplerColumnConfig(         name=\"product_subcategory\",         sampler_type=SamplerType.SUBCATEGORY,         params=SubcategorySamplerParams(             category=\"product_category\",             values={                 \"Electronics\": [                     \"Smartphones\",                     \"Laptops\",                     \"Headphones\",                     \"Cameras\",                     \"Accessories\",                 ],                 \"Clothing\": [                     \"Men's Clothing\",                     \"Women's Clothing\",                     \"Winter Coats\",                     \"Activewear\",                     \"Accessories\",                 ],                 \"Home &amp; Kitchen\": [                     \"Appliances\",                     \"Cookware\",                     \"Furniture\",                     \"Decor\",                     \"Organization\",                 ],                 \"Books\": [                     \"Fiction\",                     \"Non-Fiction\",                     \"Self-Help\",                     \"Textbooks\",                     \"Classics\",                 ],                 \"Home Office\": [                     \"Desks\",                     \"Chairs\",                     \"Storage\",                     \"Office Supplies\",                     \"Lighting\",                 ],             },         ),     ) )  config_builder.add_column(     SamplerColumnConfig(         name=\"target_age_range\",         sampler_type=SamplerType.CATEGORY,         params=CategorySamplerParams(values=[\"18-25\", \"25-35\", \"35-50\", \"50-65\", \"65+\"]),     ) )  # Sampler columns support conditional params, which are used if the condition is met. # In this example, we set the review style to rambling if the target age range is 18-25. # Note conditional parameters are only supported for Sampler column types. config_builder.add_column(     SamplerColumnConfig(         name=\"review_style\",         sampler_type=SamplerType.CATEGORY,         params=CategorySamplerParams(             values=[\"rambling\", \"brief\", \"detailed\", \"structured with bullet points\"],             weights=[1, 2, 2, 1],         ),         conditional_params={             \"target_age_range == '18-25'\": CategorySamplerParams(values=[\"rambling\"]),         },     ) )  # Optionally validate that the columns are configured correctly. config_builder.validate() <p>Next, we will use more advanced Jinja expressions to create new columns.</p> <p>Jinja expressions let you:</p> <ul> <li><p>Access nested attributes: <code>{{ customer.first_name }}</code></p> </li> <li><p>Combine values: <code>{{ customer.first_name }} {{ customer.last_name }}</code></p> </li> <li><p>Use conditional logic: <code>{% if condition %}...{% endif %}</code></p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre># We can create new columns using Jinja expressions that reference\n# existing columns, including attributes of nested objects.\nconfig_builder.add_column(\n    ExpressionColumnConfig(name=\"customer_name\", expr=\"{{ customer.first_name }} {{ customer.last_name }}\")\n)\n\nconfig_builder.add_column(ExpressionColumnConfig(name=\"customer_age\", expr=\"{{ customer.age }}\"))\n\nconfig_builder.add_column(\n    LLMStructuredColumnConfig(\n        name=\"product\",\n        prompt=(\n            \"Create a product in the '{{ product_category }}' category, focusing on products  \"\n            \"related to '{{ product_subcategory }}'. The target age range of the ideal customer is \"\n            \"{{ target_age_range }} years old. The product should be priced between $10 and $1000.\"\n        ),\n        system_prompt=SYSTEM_PROMPT,\n        output_format=Product,\n        model_alias=MODEL_ALIAS,\n    )\n)\n\n# We can even use if/else logic in our Jinja expressions to create more complex prompt patterns.\nconfig_builder.add_column(\n    LLMStructuredColumnConfig(\n        name=\"customer_review\",\n        prompt=(\n            \"Your task is to write a review for the following product:\\n\\n\"\n            \"Product Name: {{ product.name }}\\n\"\n            \"Product Description: {{ product.description }}\\n\"\n            \"Price: {{ product.price }}\\n\\n\"\n            \"Imagine your name is {{ customer_name }} and you are from {{ customer.city }}, {{ customer.state }}. \"\n            \"Write the review in a style that is '{{ review_style }}'.\"\n            \"{% if target_age_range == '18-25' %}\"\n            \"Make sure the review is more informal and conversational.\"\n            \"{% else %}\"\n            \"Make sure the review is more formal and structured.\"\n            \"{% endif %}\"\n        ),\n        system_prompt=SYSTEM_PROMPT,\n        output_format=ProductReview,\n        model_alias=MODEL_ALIAS,\n    )\n)\n\nconfig_builder.validate()\n</pre> # We can create new columns using Jinja expressions that reference # existing columns, including attributes of nested objects. config_builder.add_column(     ExpressionColumnConfig(name=\"customer_name\", expr=\"{{ customer.first_name }} {{ customer.last_name }}\") )  config_builder.add_column(ExpressionColumnConfig(name=\"customer_age\", expr=\"{{ customer.age }}\"))  config_builder.add_column(     LLMStructuredColumnConfig(         name=\"product\",         prompt=(             \"Create a product in the '{{ product_category }}' category, focusing on products  \"             \"related to '{{ product_subcategory }}'. The target age range of the ideal customer is \"             \"{{ target_age_range }} years old. The product should be priced between $10 and $1000.\"         ),         system_prompt=SYSTEM_PROMPT,         output_format=Product,         model_alias=MODEL_ALIAS,     ) )  # We can even use if/else logic in our Jinja expressions to create more complex prompt patterns. config_builder.add_column(     LLMStructuredColumnConfig(         name=\"customer_review\",         prompt=(             \"Your task is to write a review for the following product:\\n\\n\"             \"Product Name: {{ product.name }}\\n\"             \"Product Description: {{ product.description }}\\n\"             \"Price: {{ product.price }}\\n\\n\"             \"Imagine your name is {{ customer_name }} and you are from {{ customer.city }}, {{ customer.state }}. \"             \"Write the review in a style that is '{{ review_style }}'.\"             \"{% if target_age_range == '18-25' %}\"             \"Make sure the review is more informal and conversational.\"             \"{% else %}\"             \"Make sure the review is more formal and structured.\"             \"{% endif %}\"         ),         system_prompt=SYSTEM_PROMPT,         output_format=ProductReview,         model_alias=MODEL_ALIAS,     ) )  config_builder.validate() In\u00a0[\u00a0]: Copied! <pre>preview = data_designer_client.preview(config_builder, num_records=2)\n</pre> preview = data_designer_client.preview(config_builder, num_records=2) In\u00a0[\u00a0]: Copied! <pre># Run this cell multiple times to cycle through the 2 preview records.\npreview.display_sample_record()\n</pre> # Run this cell multiple times to cycle through the 2 preview records. preview.display_sample_record() In\u00a0[\u00a0]: Copied! <pre># The preview dataset is available as a pandas DataFrame.\npreview.dataset\n</pre> # The preview dataset is available as a pandas DataFrame. preview.dataset In\u00a0[\u00a0]: Copied! <pre># Print the analysis as a table.\npreview.analysis.to_report()\n</pre> # Print the analysis as a table. preview.analysis.to_report() In\u00a0[\u00a0]: Copied! <pre>job_results = data_designer_client.create(config_builder, num_records=10)\n</pre> job_results = data_designer_client.create(config_builder, num_records=10) In\u00a0[\u00a0]: Copied! <pre># Load the generated dataset as a pandas DataFrame.\ndataset = job_results.load_dataset()\n\ndataset.head()\n</pre> # Load the generated dataset as a pandas DataFrame. dataset = job_results.load_dataset()  dataset.head() In\u00a0[\u00a0]: Copied! <pre># Load the analysis results into memory.\nanalysis = job_results.load_analysis()\n\nanalysis.to_report()\n</pre> # Load the analysis results into memory. analysis = job_results.load_analysis()  analysis.to_report()"},{"location":"notebook_source/2-structured-outputs-and-jinja-expressions/#data-designer-tutorial-structured-outputs-and-jinja-expressions","title":"\ud83c\udfa8 Data Designer Tutorial: Structured Outputs and Jinja Expressions\u00b6","text":""},{"location":"notebook_source/2-structured-outputs-and-jinja-expressions/#what-youll-learn","title":"\ud83d\udcda What you'll learn\u00b6","text":"<p>In this notebook, we will continue our exploration of Data Designer, demonstrating more advanced data generation using structured outputs and Jinja expressions.</p> <p>If this is your first time using Data Designer, we recommend starting with the first notebook in this tutorial series.</p>"},{"location":"notebook_source/2-structured-outputs-and-jinja-expressions/#import-the-essentials","title":"\ud83d\udce6 Import the essentials\u00b6","text":"<ul> <li>The <code>essentials</code> module provides quick access to the most commonly used objects.</li> </ul>"},{"location":"notebook_source/2-structured-outputs-and-jinja-expressions/#initialize-the-data-designer-interface","title":"\u2699\ufe0f Initialize the Data Designer interface\u00b6","text":"<ul> <li><p><code>DataDesigner</code> is the main object that is used to interface with the library.</p> </li> <li><p>When initialized without arguments, the default model providers are used.</p> </li> </ul>"},{"location":"notebook_source/2-structured-outputs-and-jinja-expressions/#define-model-configurations","title":"\ud83c\udf9b\ufe0f Define model configurations\u00b6","text":"<ul> <li><p>Each <code>ModelConfig</code> defines a model that can be used during the generation process.</p> </li> <li><p>The \"model alias\" is used to reference the model in the Data Designer config (as we will see below).</p> </li> <li><p>The \"model provider\" is the external service that hosts the model (see the model config docs for more details).</p> </li> <li><p>By default, we use build.nvidia.com as the model provider.</p> </li> </ul>"},{"location":"notebook_source/2-structured-outputs-and-jinja-expressions/#initialize-the-data-designer-config-builder","title":"\ud83c\udfd7\ufe0f Initialize the Data Designer Config Builder\u00b6","text":"<ul> <li><p>The Data Designer config defines the dataset schema and generation process.</p> </li> <li><p>The config builder provides an intuitive interface for building this configuration.</p> </li> <li><p>The list of model configs is provided to the builder at initialization.</p> </li> </ul>"},{"location":"notebook_source/2-structured-outputs-and-jinja-expressions/#designing-our-data","title":"\ud83e\uddd1\u200d\ud83c\udfa8 Designing our data\u00b6","text":"<ul> <li><p>We will again create a product review dataset, but this time we will use structured outputs and Jinja expressions.</p> </li> <li><p>Structured outputs let you specify the exact schema of the data you want to generate.</p> </li> <li><p>Data Designer supports schemas specified using either json schema or Pydantic data models (recommended).</p> </li> </ul> <p>We'll define our structured outputs using Pydantic data models</p> <p>\ud83d\udca1 Why Pydantic?</p> <ul> <li><p>Pydantic models provide better IDE support and type validation.</p> </li> <li><p>They are more Pythonic than raw JSON schemas.</p> </li> <li><p>They integrate seamlessly with Data Designer's structured output system.</p> </li> </ul>"},{"location":"notebook_source/2-structured-outputs-and-jinja-expressions/#iteration-is-key-preview-the-dataset","title":"\ud83d\udd01 Iteration is key \u2013\u00a0preview the dataset!\u00b6","text":"<ol> <li><p>Use the <code>preview</code> method to generate a sample of records quickly.</p> </li> <li><p>Inspect the results for quality and format issues.</p> </li> <li><p>Adjust column configurations, prompts, or parameters as needed.</p> </li> <li><p>Re-run the preview until satisfied.</p> </li> </ol>"},{"location":"notebook_source/2-structured-outputs-and-jinja-expressions/#analyze-the-generated-data","title":"\ud83d\udcca Analyze the generated data\u00b6","text":"<ul> <li><p>Data Designer automatically generates a basic statistical analysis of the generated data.</p> </li> <li><p>This analysis is available via the <code>analysis</code> property of generation result objects.</p> </li> </ul>"},{"location":"notebook_source/2-structured-outputs-and-jinja-expressions/#scale-up","title":"\ud83c\udd99 Scale up!\u00b6","text":"<ul> <li><p>Happy with your preview data?</p> </li> <li><p>Use the <code>create</code> method to submit larger Data Designer generation jobs.</p> </li> </ul>"},{"location":"notebook_source/2-structured-outputs-and-jinja-expressions/#next-steps","title":"\u23ed\ufe0f Next Steps\u00b6","text":"<p>Check out the following notebook to learn more about:</p> <ul> <li>Seeding synthetic data generation with an external dataset</li> </ul>"},{"location":"notebook_source/3-seeding-with-a-dataset/","title":"3 seeding with a dataset","text":"In\u00a0[\u00a0]: Copied! <pre>from data_designer.essentials import (\n    DataDesigner,\n    DataDesignerConfigBuilder,\n    InferenceParameters,\n    ModelConfig,\n    SeedConfig,\n)\n</pre> from data_designer.essentials import (     DataDesigner,     DataDesignerConfigBuilder,     InferenceParameters,     ModelConfig,     SeedConfig, ) In\u00a0[\u00a0]: Copied! <pre>data_designer_client = DataDesigner()\n</pre> data_designer_client = DataDesigner() In\u00a0[\u00a0]: Copied! <pre># This name is set in the model provider configuration.\nMODEL_PROVIDER = \"nvidia\"\n\n# The model ID is from build.nvidia.com.\nMODEL_ID = \"nvidia/nvidia-nemotron-nano-9b-v2\"\n\n# We choose this alias to be descriptive for our use case.\nMODEL_ALIAS = \"nemotron-nano-v2\"\n\n# This sets reasoning to False for the nemotron-nano-v2 model.\nSYSTEM_PROMPT = \"/no_think\"\n\nmodel_configs = [\n    ModelConfig(\n        alias=MODEL_ALIAS,\n        model=MODEL_ID,\n        provider=MODEL_PROVIDER,\n        inference_parameters=InferenceParameters(\n            temperature=0.5,\n            top_p=1.0,\n            max_tokens=1024,\n        ),\n    )\n]\n</pre> # This name is set in the model provider configuration. MODEL_PROVIDER = \"nvidia\"  # The model ID is from build.nvidia.com. MODEL_ID = \"nvidia/nvidia-nemotron-nano-9b-v2\"  # We choose this alias to be descriptive for our use case. MODEL_ALIAS = \"nemotron-nano-v2\"  # This sets reasoning to False for the nemotron-nano-v2 model. SYSTEM_PROMPT = \"/no_think\"  model_configs = [     ModelConfig(         alias=MODEL_ALIAS,         model=MODEL_ID,         provider=MODEL_PROVIDER,         inference_parameters=InferenceParameters(             temperature=0.5,             top_p=1.0,             max_tokens=1024,         ),     ) ] In\u00a0[\u00a0]: Copied! <pre>config_builder = DataDesignerConfigBuilder(model_configs=model_configs)\n</pre> config_builder = DataDesignerConfigBuilder(model_configs=model_configs) In\u00a0[\u00a0]: Copied! <pre># Download sample dataset from Github\nimport urllib.request\n\nurl = \"https://raw.githubusercontent.com/NVIDIA/GenerativeAIExamples/refs/heads/main/nemo/NeMo-Data-Designer/data/gretelai_symptom_to_diagnosis.csv\"\nlocal_filename, headers = urllib.request.urlretrieve(url, \"gretelai_symptom_to_diagnosis.csv\")\n\nseed_dataset = SeedConfig(dataset=local_filename)\n\n# Pass the reference to the config builder for use during generation.\nconfig_builder.with_seed_dataset(seed_dataset)\n</pre> # Download sample dataset from Github import urllib.request  url = \"https://raw.githubusercontent.com/NVIDIA/GenerativeAIExamples/refs/heads/main/nemo/NeMo-Data-Designer/data/gretelai_symptom_to_diagnosis.csv\" local_filename, headers = urllib.request.urlretrieve(url, \"gretelai_symptom_to_diagnosis.csv\")  seed_dataset = SeedConfig(dataset=local_filename)  # Pass the reference to the config builder for use during generation. config_builder.with_seed_dataset(seed_dataset) In\u00a0[\u00a0]: Copied! <pre>config_builder.add_column(\n    name=\"patient_sampler\",\n    column_type=\"sampler\",\n    sampler_type=\"person_from_faker\",\n)\n\nconfig_builder.add_column(\n    name=\"doctor_sampler\",\n    column_type=\"sampler\",\n    sampler_type=\"person_from_faker\",\n)\n\nconfig_builder.add_column(\n    name=\"patient_id\",\n    column_type=\"sampler\",\n    sampler_type=\"uuid\",\n    params={\n        \"prefix\": \"PT-\",\n        \"short_form\": True,\n        \"uppercase\": True,\n    },\n)\n\nconfig_builder.add_column(\n    name=\"first_name\",\n    column_type=\"expression\",\n    expr=\"{{ patient_sampler.first_name}}\",\n)\n\nconfig_builder.add_column(\n    name=\"last_name\",\n    column_type=\"expression\",\n    expr=\"{{ patient_sampler.last_name }}\",\n)\n\n\nconfig_builder.add_column(\n    name=\"dob\",\n    column_type=\"expression\",\n    expr=\"{{ patient_sampler.birth_date }}\",\n)\n\nconfig_builder.add_column(\n    name=\"symptom_onset_date\",\n    column_type=\"sampler\",\n    sampler_type=\"datetime\",\n    params={\"start\": \"2024-01-01\", \"end\": \"2024-12-31\"},\n)\n\nconfig_builder.add_column(\n    name=\"date_of_visit\",\n    column_type=\"sampler\",\n    sampler_type=\"timedelta\",\n    params={\"dt_min\": 1, \"dt_max\": 30, \"reference_column_name\": \"symptom_onset_date\"},\n)\n\nconfig_builder.add_column(\n    name=\"physician\",\n    column_type=\"expression\",\n    expr=\"Dr. {{ doctor_sampler.last_name }}\",\n)\n\nconfig_builder.add_column(\n    name=\"physician_notes\",\n    column_type=\"llm-text\",\n    prompt=\"\"\"\\\nYou are a primary-care physician who just had an appointment with {{ first_name }} {{ last_name }},\nwho has been struggling with symptoms from {{ diagnosis }} since {{ symptom_onset_date }}.\nThe date of today's visit is {{ date_of_visit }}.\n\n{{ patient_summary }}\n\nWrite careful notes about your visit with {{ first_name }},\nas Dr. {{ doctor_sampler.first_name }} {{ doctor_sampler.last_name }}.\n\nFormat the notes as a busy doctor might.\n\"\"\",\n    model_alias=MODEL_ALIAS,\n    system_prompt=SYSTEM_PROMPT,\n)\n\nconfig_builder.validate()\n</pre> config_builder.add_column(     name=\"patient_sampler\",     column_type=\"sampler\",     sampler_type=\"person_from_faker\", )  config_builder.add_column(     name=\"doctor_sampler\",     column_type=\"sampler\",     sampler_type=\"person_from_faker\", )  config_builder.add_column(     name=\"patient_id\",     column_type=\"sampler\",     sampler_type=\"uuid\",     params={         \"prefix\": \"PT-\",         \"short_form\": True,         \"uppercase\": True,     }, )  config_builder.add_column(     name=\"first_name\",     column_type=\"expression\",     expr=\"{{ patient_sampler.first_name}}\", )  config_builder.add_column(     name=\"last_name\",     column_type=\"expression\",     expr=\"{{ patient_sampler.last_name }}\", )   config_builder.add_column(     name=\"dob\",     column_type=\"expression\",     expr=\"{{ patient_sampler.birth_date }}\", )  config_builder.add_column(     name=\"symptom_onset_date\",     column_type=\"sampler\",     sampler_type=\"datetime\",     params={\"start\": \"2024-01-01\", \"end\": \"2024-12-31\"}, )  config_builder.add_column(     name=\"date_of_visit\",     column_type=\"sampler\",     sampler_type=\"timedelta\",     params={\"dt_min\": 1, \"dt_max\": 30, \"reference_column_name\": \"symptom_onset_date\"}, )  config_builder.add_column(     name=\"physician\",     column_type=\"expression\",     expr=\"Dr. {{ doctor_sampler.last_name }}\", )  config_builder.add_column(     name=\"physician_notes\",     column_type=\"llm-text\",     prompt=\"\"\"\\ You are a primary-care physician who just had an appointment with {{ first_name }} {{ last_name }}, who has been struggling with symptoms from {{ diagnosis }} since {{ symptom_onset_date }}. The date of today's visit is {{ date_of_visit }}.  {{ patient_summary }}  Write careful notes about your visit with {{ first_name }}, as Dr. {{ doctor_sampler.first_name }} {{ doctor_sampler.last_name }}.  Format the notes as a busy doctor might. \"\"\",     model_alias=MODEL_ALIAS,     system_prompt=SYSTEM_PROMPT, )  config_builder.validate() In\u00a0[\u00a0]: Copied! <pre>preview = data_designer_client.preview(config_builder, num_records=2)\n</pre> preview = data_designer_client.preview(config_builder, num_records=2) In\u00a0[\u00a0]: Copied! <pre># Run this cell multiple times to cycle through the 2 preview records.\npreview.display_sample_record()\n</pre> # Run this cell multiple times to cycle through the 2 preview records. preview.display_sample_record() In\u00a0[\u00a0]: Copied! <pre># The preview dataset is available as a pandas DataFrame.\npreview.dataset\n</pre> # The preview dataset is available as a pandas DataFrame. preview.dataset In\u00a0[\u00a0]: Copied! <pre># Print the analysis as a table.\npreview.analysis.to_report()\n</pre> # Print the analysis as a table. preview.analysis.to_report() In\u00a0[\u00a0]: Copied! <pre>job_results = data_designer_client.create(config_builder, num_records=10)\n</pre> job_results = data_designer_client.create(config_builder, num_records=10) In\u00a0[\u00a0]: Copied! <pre># Load the generated dataset as a pandas DataFrame.\ndataset = job_results.load_dataset()\n\ndataset.head()\n</pre> # Load the generated dataset as a pandas DataFrame. dataset = job_results.load_dataset()  dataset.head() In\u00a0[\u00a0]: Copied! <pre># Load the analysis results into memory.\nanalysis = job_results.load_analysis()\n\nanalysis.to_report()\n</pre> # Load the analysis results into memory. analysis = job_results.load_analysis()  analysis.to_report()"},{"location":"notebook_source/3-seeding-with-a-dataset/#data-designer-tutorial-seeding-synthetic-data-generation-with-an-external-dataset","title":"\ud83c\udfa8 Data Designer Tutorial: Seeding Synthetic Data Generation with an External Dataset\u00b6","text":""},{"location":"notebook_source/3-seeding-with-a-dataset/#what-youll-learn","title":"\ud83d\udcda What you'll learn\u00b6","text":"<p>In this notebook, we will demonstrate how to seed synthetic data generation in Data Designer with an external dataset.</p> <p>If this is your first time using Data Designer, we recommend starting with the first notebook in this tutorial series.</p>"},{"location":"notebook_source/3-seeding-with-a-dataset/#import-the-essentials","title":"\ud83d\udce6 Import the essentials\u00b6","text":"<ul> <li>The <code>essentials</code> module provides quick access to the most commonly used objects.</li> </ul>"},{"location":"notebook_source/3-seeding-with-a-dataset/#initialize-the-data-designer-interface","title":"\u2699\ufe0f Initialize the Data Designer interface\u00b6","text":"<ul> <li><p><code>DataDesigner</code> is the main object is responsible for managing the data generation process.</p> </li> <li><p>When initialized without arguments, the default model providers are used.</p> </li> </ul>"},{"location":"notebook_source/3-seeding-with-a-dataset/#define-model-configurations","title":"\ud83c\udf9b\ufe0f Define model configurations\u00b6","text":"<ul> <li><p>Each <code>ModelConfig</code> defines a model that can be used during the generation process.</p> </li> <li><p>The \"model alias\" is used to reference the model in the Data Designer config (as we will see below).</p> </li> <li><p>The \"model provider\" is the external service that hosts the model (see the model config docs for more details).</p> </li> <li><p>By default, we use build.nvidia.com as the model provider.</p> </li> </ul>"},{"location":"notebook_source/3-seeding-with-a-dataset/#initialize-the-data-designer-config-builder","title":"\ud83c\udfd7\ufe0f Initialize the Data Designer Config Builder\u00b6","text":"<ul> <li><p>The Data Designer config defines the dataset schema and generation process.</p> </li> <li><p>The config builder provides an intuitive interface for building this configuration.</p> </li> <li><p>The list of model configs is provided to the builder at initialization.</p> </li> </ul>"},{"location":"notebook_source/3-seeding-with-a-dataset/#prepare-a-seed-dataset","title":"\ud83c\udfe5 Prepare a seed dataset\u00b6","text":"<ul> <li><p>For this notebook, we'll create a synthetic dataset of patient notes.</p> </li> <li><p>We will seed the generation process with a symptom-to-diagnosis dataset.</p> </li> <li><p>We already have the dataset downloaded in the data directory of this repository.</p> </li> </ul> <p>\ud83c\udf31 Why use a seed dataset?</p> <ul> <li><p>Seed datasets let you steer the generation process by providing context that is specific to your use case.</p> </li> <li><p>Seed datasets are also an excellent way to inject real-world diversity into your synthetic data.</p> </li> <li><p>During generation, prompt templates can reference any of the seed dataset fields.</p> </li> </ul>"},{"location":"notebook_source/3-seeding-with-a-dataset/#designing-our-synthetic-patient-notes-dataset","title":"\ud83c\udfa8 Designing our synthetic patient notes dataset\u00b6","text":"<ul> <li><p>Here we use <code>add_column</code> with keyword arguments (rather than imported config objects).</p> </li> <li><p>Generally, we recommend using concrete objects, but this is a convenient shorthand.</p> </li> <li><p>Note: The prompt template can reference fields from our seed dataset:</p> <ul> <li><code>{{ diagnosis }}</code> - the medical diagnosis from the seed data</li> <li><code>{{ patient_summary }}</code> - the symptom description from the seed data</li> </ul> </li> </ul>"},{"location":"notebook_source/3-seeding-with-a-dataset/#iteration-is-key-preview-the-dataset","title":"\ud83d\udd01 Iteration is key \u2013\u00a0preview the dataset!\u00b6","text":"<ol> <li><p>Use the <code>preview</code> method to generate a sample of records quickly.</p> </li> <li><p>Inspect the results for quality and format issues.</p> </li> <li><p>Adjust column configurations, prompts, or parameters as needed.</p> </li> <li><p>Re-run the preview until satisfied.</p> </li> </ol>"},{"location":"notebook_source/3-seeding-with-a-dataset/#analyze-the-generated-data","title":"\ud83d\udcca Analyze the generated data\u00b6","text":"<ul> <li><p>Data Designer automatically generates a basic statistical analysis of the generated data.</p> </li> <li><p>This analysis is available via the <code>analysis</code> property of generation result objects.</p> </li> </ul>"},{"location":"notebook_source/3-seeding-with-a-dataset/#scale-up","title":"\ud83c\udd99 Scale up!\u00b6","text":"<ul> <li><p>Happy with your preview data?</p> </li> <li><p>Use the <code>create</code> method to submit larger Data Designer generation jobs.</p> </li> </ul>"},{"location":"notebook_source/3-seeding-with-a-dataset/#next-steps","title":"\u23ed\ufe0f Next Steps\u00b6","text":"<p>Use Data Designer to generate synthetic data for your specific use case!</p>"},{"location":"notebook_source/4-providing-images-as-context/","title":"4 providing images as context","text":"In\u00a0[\u00a0]: Copied! <pre>!uv pip install pillow\n</pre> !uv pip install pillow In\u00a0[\u00a0]: Copied! <pre># Standard library imports\nimport base64\nimport io\nimport uuid\n\n# Third-party imports\nimport pandas as pd\nimport rich\nfrom datasets import load_dataset\nfrom IPython.display import display\nfrom rich.panel import Panel\n\n# Data Designer imports\nfrom data_designer.essentials import (\n    DataDesigner,\n    DataDesignerConfigBuilder,\n    ImageContext,\n    ImageFormat,\n    InferenceParameters,\n    LLMTextColumnConfig,\n    ModalityDataType,\n    ModelConfig,\n)\n</pre> # Standard library imports import base64 import io import uuid  # Third-party imports import pandas as pd import rich from datasets import load_dataset from IPython.display import display from rich.panel import Panel  # Data Designer imports from data_designer.essentials import (     DataDesigner,     DataDesignerConfigBuilder,     ImageContext,     ImageFormat,     InferenceParameters,     LLMTextColumnConfig,     ModalityDataType,     ModelConfig, ) In\u00a0[\u00a0]: Copied! <pre>data_designer = DataDesigner()\n</pre> data_designer = DataDesigner() In\u00a0[\u00a0]: Copied! <pre># This name is set in the model provider configuration.\nMODEL_PROVIDER = \"nvidia\"\n\nmodel_configs = [\n    ModelConfig(\n        alias=\"vision\",\n        model=\"meta/llama-4-scout-17b-16e-instruct\",\n        provider=MODEL_PROVIDER,\n        inference_parameters=InferenceParameters(\n            temperature=0.60,\n            top_p=0.95,\n            max_tokens=2048,\n        ),\n    ),\n]\n</pre> # This name is set in the model provider configuration. MODEL_PROVIDER = \"nvidia\"  model_configs = [     ModelConfig(         alias=\"vision\",         model=\"meta/llama-4-scout-17b-16e-instruct\",         provider=MODEL_PROVIDER,         inference_parameters=InferenceParameters(             temperature=0.60,             top_p=0.95,             max_tokens=2048,         ),     ), ] In\u00a0[\u00a0]: Copied! <pre>config_builder = DataDesignerConfigBuilder(model_configs=model_configs)\n</pre> config_builder = DataDesignerConfigBuilder(model_configs=model_configs) In\u00a0[\u00a0]: Copied! <pre># Dataset processing configuration\nIMG_COUNT = 512  # Number of images to process\nBASE64_IMAGE_HEIGHT = 512  # Standardized height for model input\n\n# Load ColPali dataset for visual documents\nimg_dataset_cfg = {\"path\": \"vidore/colpali_train_set\", \"split\": \"train\", \"streaming\": True}\n</pre> # Dataset processing configuration IMG_COUNT = 512  # Number of images to process BASE64_IMAGE_HEIGHT = 512  # Standardized height for model input  # Load ColPali dataset for visual documents img_dataset_cfg = {\"path\": \"vidore/colpali_train_set\", \"split\": \"train\", \"streaming\": True} In\u00a0[\u00a0]: Copied! <pre>def resize_image(image, height: int):\n    \"\"\"\n    Resize image while maintaining aspect ratio.\n\n    Args:\n        image: PIL Image object\n        height: Target height in pixels\n\n    Returns:\n        Resized PIL Image object\n    \"\"\"\n    original_width, original_height = image.size\n    width = int(original_width * (height / original_height))\n    return image.resize((width, height))\n\n\ndef convert_image_to_chat_format(record, height: int) -&gt; dict:\n    \"\"\"\n    Convert PIL image to base64 format for chat template usage.\n\n    Args:\n        record: Dataset record containing image and metadata\n        height: Target height for image resizing\n\n    Returns:\n        Updated record with base64_image and uuid fields\n    \"\"\"\n    # Resize image for consistent processing\n    image = resize_image(record[\"image\"], height)\n\n    # Convert to base64 string\n    img_buffer = io.BytesIO()\n    image.save(img_buffer, format=\"PNG\")\n    byte_data = img_buffer.getvalue()\n    base64_encoded_data = base64.b64encode(byte_data)\n    base64_string = base64_encoded_data.decode(\"utf-8\")\n\n    # Return updated record\n    return record | {\"base64_image\": base64_string, \"uuid\": str(uuid.uuid4())}\n</pre> def resize_image(image, height: int):     \"\"\"     Resize image while maintaining aspect ratio.      Args:         image: PIL Image object         height: Target height in pixels      Returns:         Resized PIL Image object     \"\"\"     original_width, original_height = image.size     width = int(original_width * (height / original_height))     return image.resize((width, height))   def convert_image_to_chat_format(record, height: int) -&gt; dict:     \"\"\"     Convert PIL image to base64 format for chat template usage.      Args:         record: Dataset record containing image and metadata         height: Target height for image resizing      Returns:         Updated record with base64_image and uuid fields     \"\"\"     # Resize image for consistent processing     image = resize_image(record[\"image\"], height)      # Convert to base64 string     img_buffer = io.BytesIO()     image.save(img_buffer, format=\"PNG\")     byte_data = img_buffer.getvalue()     base64_encoded_data = base64.b64encode(byte_data)     base64_string = base64_encoded_data.decode(\"utf-8\")      # Return updated record     return record | {\"base64_image\": base64_string, \"uuid\": str(uuid.uuid4())} In\u00a0[\u00a0]: Copied! <pre># Load and process the visual document dataset\nprint(\"\ud83d\udce5 Loading and processing document images...\")\n\nimg_dataset_iter = iter(\n    load_dataset(**img_dataset_cfg).map(convert_image_to_chat_format, fn_kwargs={\"height\": BASE64_IMAGE_HEIGHT})\n)\nimg_dataset = pd.DataFrame([next(img_dataset_iter) for _ in range(IMG_COUNT)])\n\nprint(f\"\u2705 Loaded {len(img_dataset)} images with columns: {list(img_dataset.columns)}\")\n</pre> # Load and process the visual document dataset print(\"\ud83d\udce5 Loading and processing document images...\")  img_dataset_iter = iter(     load_dataset(**img_dataset_cfg).map(convert_image_to_chat_format, fn_kwargs={\"height\": BASE64_IMAGE_HEIGHT}) ) img_dataset = pd.DataFrame([next(img_dataset_iter) for _ in range(IMG_COUNT)])  print(f\"\u2705 Loaded {len(img_dataset)} images with columns: {list(img_dataset.columns)}\") In\u00a0[\u00a0]: Copied! <pre>img_dataset.head()\n</pre> img_dataset.head() In\u00a0[\u00a0]: Copied! <pre># Add the seed dataset containing our processed images\ndf_seed = pd.DataFrame(img_dataset)[[\"uuid\", \"image_filename\", \"base64_image\", \"page\", \"options\", \"source\"]]\nconfig_builder.with_seed_dataset(\n    DataDesigner.make_seed_reference_from_dataframe(df_seed, file_path=\"colpali_train_set.csv\")\n)\n</pre> # Add the seed dataset containing our processed images df_seed = pd.DataFrame(img_dataset)[[\"uuid\", \"image_filename\", \"base64_image\", \"page\", \"options\", \"source\"]] config_builder.with_seed_dataset(     DataDesigner.make_seed_reference_from_dataframe(df_seed, file_path=\"colpali_train_set.csv\") ) In\u00a0[\u00a0]: Copied! <pre># Add a column to generate detailed document summaries\nconfig_builder.add_column(\n    LLMTextColumnConfig(\n        name=\"summary\",\n        model_alias=\"vision\",\n        prompt=(\n            \"Provide a detailed summary of the content in this image in Markdown format. \"\n            \"Start from the top of the image and then describe it from top to bottom. \"\n            \"Place a summary at the bottom.\"\n        ),\n        multi_modal_context=[\n            ImageContext(\n                column_name=\"base64_image\",\n                data_type=ModalityDataType.BASE64,\n                image_format=ImageFormat.PNG,\n            )\n        ],\n    )\n)\n</pre> # Add a column to generate detailed document summaries config_builder.add_column(     LLMTextColumnConfig(         name=\"summary\",         model_alias=\"vision\",         prompt=(             \"Provide a detailed summary of the content in this image in Markdown format. \"             \"Start from the top of the image and then describe it from top to bottom. \"             \"Place a summary at the bottom.\"         ),         multi_modal_context=[             ImageContext(                 column_name=\"base64_image\",                 data_type=ModalityDataType.BASE64,                 image_format=ImageFormat.PNG,             )         ],     ) ) In\u00a0[\u00a0]: Copied! <pre>preview = data_designer.preview(config_builder, num_records=2)\n</pre> preview = data_designer.preview(config_builder, num_records=2) In\u00a0[\u00a0]: Copied! <pre># Run this cell multiple times to cycle through the 2 preview records.\npreview.display_sample_record()\n</pre> # Run this cell multiple times to cycle through the 2 preview records. preview.display_sample_record() In\u00a0[\u00a0]: Copied! <pre># The preview dataset is available as a pandas DataFrame.\npreview.dataset\n</pre> # The preview dataset is available as a pandas DataFrame. preview.dataset In\u00a0[\u00a0]: Copied! <pre># Print the analysis as a table.\npreview.analysis.to_report()\n</pre> # Print the analysis as a table. preview.analysis.to_report() In\u00a0[\u00a0]: Copied! <pre># Compare original document with generated summary\nindex = 0  # Change this to view different examples\n\n# Merge preview data with original images for comparison\ncomparison_dataset = preview.dataset.merge(pd.DataFrame(img_dataset)[[\"uuid\", \"image\"]], how=\"left\", on=\"uuid\")\n\n# Extract the record for display\nrecord = comparison_dataset.iloc[index]\n\nprint(\"\ud83d\udcc4 Original Document Image:\")\ndisplay(resize_image(record.image, BASE64_IMAGE_HEIGHT))\n\nprint(\"\\n\ud83d\udcdd Generated Summary:\")\nrich.print(Panel(record.summary, title=\"Document Summary\", title_align=\"left\"))\n</pre> # Compare original document with generated summary index = 0  # Change this to view different examples  # Merge preview data with original images for comparison comparison_dataset = preview.dataset.merge(pd.DataFrame(img_dataset)[[\"uuid\", \"image\"]], how=\"left\", on=\"uuid\")  # Extract the record for display record = comparison_dataset.iloc[index]  print(\"\ud83d\udcc4 Original Document Image:\") display(resize_image(record.image, BASE64_IMAGE_HEIGHT))  print(\"\\n\ud83d\udcdd Generated Summary:\") rich.print(Panel(record.summary, title=\"Document Summary\", title_align=\"left\")) In\u00a0[\u00a0]: Copied! <pre>results = data_designer.create(config_builder, num_records=10)\n</pre> results = data_designer.create(config_builder, num_records=10) In\u00a0[\u00a0]: Copied! <pre># Load the generated dataset as a pandas DataFrame.\ndataset = results.load_dataset()\n\ndataset.head()\n</pre> # Load the generated dataset as a pandas DataFrame. dataset = results.load_dataset()  dataset.head() In\u00a0[\u00a0]: Copied! <pre># Load the analysis results into memory.\nanalysis = results.load_analysis()\n\nanalysis.to_report()\n</pre> # Load the analysis results into memory. analysis = results.load_analysis()  analysis.to_report()"},{"location":"notebook_source/4-providing-images-as-context/#data-designer-tutorial-providing-images-as-context-for-vision-based-data-generation","title":"\ud83c\udfa8 Data Designer Tutorial: Providing Images as Context for Vision-Based Data Generation\u00b6","text":""},{"location":"notebook_source/4-providing-images-as-context/#what-youll-learn","title":"\ud83d\udcda What you'll learn\u00b6","text":"<p>This notebook demonstrates how to provide images as context to generate text descriptions using vision-language models.</p> <ul> <li>\u2728 Visual Document Processing: Converting images to chat-ready format for model consumption</li> <li>\ud83d\udd0d Vision-Language Generation: Using vision models to generate detailed summaries from images</li> </ul> <p>If this is your first time using Data Designer, we recommend starting with the first notebook in this tutorial series.</p>"},{"location":"notebook_source/4-providing-images-as-context/#install-dependencies-if-required","title":"\u2b07\ufe0f Install dependencies (if required)\u00b6","text":""},{"location":"notebook_source/4-providing-images-as-context/#import-the-essentials","title":"\ud83d\udce6 Import the essentials\u00b6","text":"<ul> <li>The <code>essentials</code> module provides quick access to the most commonly used objects.</li> </ul>"},{"location":"notebook_source/4-providing-images-as-context/#initialize-the-data-designer-interface","title":"\u2699\ufe0f Initialize the Data Designer interface\u00b6","text":"<ul> <li><p><code>DataDesigner</code> is the main object is responsible for managing the data generation process.</p> </li> <li><p>When initialized without arguments, the default model providers are used.</p> </li> </ul>"},{"location":"notebook_source/4-providing-images-as-context/#define-model-configurations","title":"\ud83c\udf9b\ufe0f Define model configurations\u00b6","text":"<ul> <li><p>Each <code>ModelConfig</code> defines a model that can be used during the generation process.</p> </li> <li><p>The \"model alias\" is used to reference the model in the Data Designer config (as we will see below).</p> </li> <li><p>The \"model provider\" is the external service that hosts the model (see the model config docs for more details).</p> </li> <li><p>By default, we use build.nvidia.com as the model provider.</p> </li> </ul>"},{"location":"notebook_source/4-providing-images-as-context/#initialize-the-data-designer-config-builder","title":"\ud83c\udfd7\ufe0f Initialize the Data Designer Config Builder\u00b6","text":"<ul> <li><p>The Data Designer config defines the dataset schema and generation process.</p> </li> <li><p>The config builder provides an intuitive interface for building this configuration.</p> </li> <li><p>The list of model configs is provided to the builder at initialization.</p> </li> </ul>"},{"location":"notebook_source/4-providing-images-as-context/#seed-dataset-creation","title":"\ud83c\udf31 Seed Dataset Creation\u00b6","text":"<p>In this section, we'll prepare our visual documents as a seed dataset for summarization:</p> <ul> <li>Loading Visual Documents: We use the ColPali dataset containing document images</li> <li>Image Processing: Convert images to base64 format for vision model consumption</li> <li>Metadata Extraction: Preserve relevant document information (filename, page number, source, etc.)</li> </ul> <p>The seed dataset will be used to generate detailed text summaries of each document image.</p>"},{"location":"notebook_source/4-providing-images-as-context/#iteration-is-key-preview-the-dataset","title":"\ud83d\udd01 Iteration is key \u2013 preview the dataset!\u00b6","text":"<ol> <li><p>Use the <code>preview</code> method to generate a sample of records quickly.</p> </li> <li><p>Inspect the results for quality and format issues.</p> </li> <li><p>Adjust column configurations, prompts, or parameters as needed.</p> </li> <li><p>Re-run the preview until satisfied.</p> </li> </ol>"},{"location":"notebook_source/4-providing-images-as-context/#analyze-the-generated-data","title":"\ud83d\udcca Analyze the generated data\u00b6","text":"<ul> <li><p>Data Designer automatically generates a basic statistical analysis of the generated data.</p> </li> <li><p>This analysis is available via the <code>analysis</code> property of generation result objects.</p> </li> </ul>"},{"location":"notebook_source/4-providing-images-as-context/#visual-inspection","title":"\ud83d\udd0e Visual Inspection\u00b6","text":"<p>Let's compare the original document image with the generated summary to validate quality:</p>"},{"location":"notebook_source/4-providing-images-as-context/#scale-up","title":"\ud83c\udd99 Scale up!\u00b6","text":"<ul> <li><p>Happy with your preview data?</p> </li> <li><p>Use the <code>create</code> method to submit larger Data Designer generation jobs.</p> </li> </ul>"},{"location":"notebook_source/4-providing-images-as-context/#next-steps","title":"\u23ed\ufe0f Next Steps\u00b6","text":"<p>Now that you've learned how to use visual context for image summarization in Data Designer, explore more:</p> <ul> <li>Experiment with different vision models for specific document types</li> <li>Try different prompt variations to generate specialized descriptions (e.g., technical details, key findings)</li> <li>Combine vision-based summaries with other column types for multi-modal workflows</li> <li>Apply this pattern to other vision tasks like image captioning, OCR validation, or visual question answering</li> </ul>"},{"location":"notebook_source/_README/","title":"Overview","text":"<p>Welcome to the Data Designer tutorial series! These hands-on notebooks will guide you through the core concepts and features of Data Designer, from basic synthetic data generation to advanced techniques like structured outputs and dataset seeding.</p>"},{"location":"notebook_source/_README/#setting-up-your-environment","title":"\ud83d\ude80 Setting Up Your Environment","text":""},{"location":"notebook_source/_README/#local-setup-best-practices","title":"Local Setup Best Practices","text":"<p>First, download the tutorial from the release assets. To run the tutorial notebooks locally, we recommend using a virtual environment to manage dependencies:</p> uv (Recommended)pip + venv <pre><code># Extract tutorial notebooks\nunzip data_designer_tutorial.zip\ncd data_designer_tutorial\n\n# Launch Jupyter\nuv run jupyter notebook\n</code></pre> <pre><code># Extract tutorial notebooks\nunzip data_designer_tutorial.zip\ncd data_designer_tutorial\n\n# Create Python virtual environment and install required packages\npython -m venv venv\nsource venv/bin/activate\npip install data-designer jupyter\n\n# Launch Jupyter\njupyter notebook\n</code></pre>"},{"location":"notebook_source/_README/#api-keys-and-authentication","title":"API Keys and Authentication","text":"<p>Data Designer is able to interface with various LLM providers. You'll need to set up API keys for the models you want to use:</p> <pre><code># For NVIDIA API Catalog (build.nvidia.com)\nexport NVIDIA_API_KEY=\"your-api-key-here\"\n\n# For OpenAI\nexport OPENAI_API_KEY=\"your-api-key-here\"\n</code></pre> <p>For more information, check the Quick Start, Default Model Settings and how to Configure Model Settings Using The CLI.</p>"},{"location":"notebook_source/_README/#tutorial-series","title":"\ud83d\udcda Tutorial Series","text":"<p>The tutorials are designed to be completed in sequence, building upon concepts introduced in previous notebooks:</p>"},{"location":"notebook_source/_README/#1-the-basics","title":"1. The Basics","text":"<p>Learn the fundamentals of Data Designer by generating a simple product review dataset. This notebook covers:</p> <ul> <li>Setting up the <code>DataDesigner</code> interface</li> <li>Configuring models and inference parameters</li> <li>Using built-in samplers (Category, Person, Uniform)</li> <li>Generating LLM text columns with dependencies</li> <li>Understanding the generation workflow</li> </ul> <p>Start here if you're new to Data Designer!</p>"},{"location":"notebook_source/_README/#2-structured-outputs-and-jinja-expressions","title":"2. Structured Outputs and Jinja Expressions","text":"<p>Explore more advanced data generation capabilities:</p> <ul> <li>Creating structured JSON outputs with schemas</li> <li>Using Jinja expressions for derived columns</li> <li>Combining samplers with structured data</li> <li>Building complex data dependencies</li> <li>Working with nested data structures</li> </ul>"},{"location":"notebook_source/_README/#3-seeding-with-an-external-dataset","title":"3. Seeding with an External Dataset","text":"<p>Learn how to leverage existing datasets to guide synthetic data generation:</p> <ul> <li>Loading and using seed datasets</li> <li>Sampling from real data distributions</li> <li>Combining seed data with LLM generation</li> <li>Creating realistic synthetic data based on existing patterns</li> </ul>"},{"location":"notebook_source/_README/#4-providing-images-as-context","title":"4. Providing Images as Context","text":"<p>Learn how to use vision-language models to generate text descriptions from images:</p> <ul> <li>Processing and converting images to base64 format for model consumption</li> <li>Using vision-language models (VLMs) to analyze visual documents</li> <li>Generating detailed summaries from document images</li> <li>Inspecting and validating vision-based generation results</li> </ul>"},{"location":"notebook_source/_README/#important-documentation-sections","title":"\ud83d\udcd6 Important Documentation Sections","text":"<p>Before diving into the tutorials, familiarize yourself with these key documentation sections:</p>"},{"location":"notebook_source/_README/#getting-started","title":"Getting Started","text":"<ul> <li>Installation - Detailed installation instructions for various setups</li> <li>Welcome Guide - Overview of Data Designer capabilities and architecture</li> </ul>"},{"location":"notebook_source/_README/#core-concepts","title":"Core Concepts","text":"<p>Understanding these concepts will help you make the most of the tutorials:</p> <ul> <li>Columns - Learn about different column types (Sampler, LLM, Expression, Validation, etc.)</li> <li>Validators - Understand how to validate generated data with Python, SQL, and remote validators</li> <li>Person Sampling - Learn how to sample realistic person data with demographic attributes</li> </ul>"},{"location":"notebook_source/_README/#code-reference","title":"Code Reference","text":"<p>Quick reference guides for the main configuration objects:</p> <ul> <li>column_configs - All column configuration types</li> <li>config_builder - The <code>DataDesignerConfigBuilder</code> API</li> <li>data_designer_config - Main configuration schema</li> <li>validator_params - Validator configuration options</li> </ul>"},{"location":"notebooks/","title":"Overview","text":"<p>Welcome to the Data Designer tutorial series! These hands-on notebooks will guide you through the core concepts and features of Data Designer, from basic synthetic data generation to advanced techniques like structured outputs and dataset seeding.</p>"},{"location":"notebooks/#setting-up-your-environment","title":"\ud83d\ude80 Setting Up Your Environment","text":""},{"location":"notebooks/#local-setup-best-practices","title":"Local Setup Best Practices","text":"<p>First, download the tutorial from the release assets. To run the tutorial notebooks locally, we recommend using a virtual environment to manage dependencies:</p> uv (Recommended)pip + venv <pre><code># Extract tutorial notebooks\nunzip data_designer_tutorial.zip\ncd data_designer_tutorial\n\n# Launch Jupyter\nuv run jupyter notebook\n</code></pre> <pre><code># Extract tutorial notebooks\nunzip data_designer_tutorial.zip\ncd data_designer_tutorial\n\n# Create Python virtual environment and install required packages\npython -m venv venv\nsource venv/bin/activate\npip install data-designer jupyter\n\n# Launch Jupyter\njupyter notebook\n</code></pre>"},{"location":"notebooks/#api-keys-and-authentication","title":"API Keys and Authentication","text":"<p>Data Designer is able to interface with various LLM providers. You'll need to set up API keys for the models you want to use:</p> <pre><code># For NVIDIA API Catalog (build.nvidia.com)\nexport NVIDIA_API_KEY=\"your-api-key-here\"\n\n# For OpenAI\nexport OPENAI_API_KEY=\"your-api-key-here\"\n</code></pre> <p>For more information, check the Quick Start, Default Model Settings and how to Configure Model Settings Using The CLI.</p>"},{"location":"notebooks/#tutorial-series","title":"\ud83d\udcda Tutorial Series","text":"<p>The tutorials are designed to be completed in sequence, building upon concepts introduced in previous notebooks:</p>"},{"location":"notebooks/#1-the-basics","title":"1. The Basics","text":"<p>Learn the fundamentals of Data Designer by generating a simple product review dataset. This notebook covers:</p> <ul> <li>Setting up the <code>DataDesigner</code> interface</li> <li>Configuring models and inference parameters</li> <li>Using built-in samplers (Category, Person, Uniform)</li> <li>Generating LLM text columns with dependencies</li> <li>Understanding the generation workflow</li> </ul> <p>Start here if you're new to Data Designer!</p>"},{"location":"notebooks/#2-structured-outputs-and-jinja-expressions","title":"2. Structured Outputs and Jinja Expressions","text":"<p>Explore more advanced data generation capabilities:</p> <ul> <li>Creating structured JSON outputs with schemas</li> <li>Using Jinja expressions for derived columns</li> <li>Combining samplers with structured data</li> <li>Building complex data dependencies</li> <li>Working with nested data structures</li> </ul>"},{"location":"notebooks/#3-seeding-with-an-external-dataset","title":"3. Seeding with an External Dataset","text":"<p>Learn how to leverage existing datasets to guide synthetic data generation:</p> <ul> <li>Loading and using seed datasets</li> <li>Sampling from real data distributions</li> <li>Combining seed data with LLM generation</li> <li>Creating realistic synthetic data based on existing patterns</li> </ul>"},{"location":"notebooks/#4-providing-images-as-context","title":"4. Providing Images as Context","text":"<p>Learn how to use vision-language models to generate text descriptions from images:</p> <ul> <li>Processing and converting images to base64 format for model consumption</li> <li>Using vision-language models (VLMs) to analyze visual documents</li> <li>Generating detailed summaries from document images</li> <li>Inspecting and validating vision-based generation results</li> </ul>"},{"location":"notebooks/#important-documentation-sections","title":"\ud83d\udcd6 Important Documentation Sections","text":"<p>Before diving into the tutorials, familiarize yourself with these key documentation sections:</p>"},{"location":"notebooks/#getting-started","title":"Getting Started","text":"<ul> <li>Installation - Detailed installation instructions for various setups</li> <li>Welcome Guide - Overview of Data Designer capabilities and architecture</li> </ul>"},{"location":"notebooks/#core-concepts","title":"Core Concepts","text":"<p>Understanding these concepts will help you make the most of the tutorials:</p> <ul> <li>Columns - Learn about different column types (Sampler, LLM, Expression, Validation, etc.)</li> <li>Validators - Understand how to validate generated data with Python, SQL, and remote validators</li> <li>Person Sampling - Learn how to sample realistic person data with demographic attributes</li> </ul>"},{"location":"notebooks/#code-reference","title":"Code Reference","text":"<p>Quick reference guides for the main configuration objects:</p> <ul> <li>column_configs - All column configuration types</li> <li>config_builder - The <code>DataDesignerConfigBuilder</code> API</li> <li>data_designer_config - Main configuration schema</li> <li>validator_params - Validator configuration options</li> </ul>"},{"location":"notebooks/1-the-basics/","title":"The Basics","text":"In\u00a0[1]: Copied! <pre>from data_designer.essentials import (\n    CategorySamplerParams,\n    DataDesigner,\n    DataDesignerConfigBuilder,\n    InferenceParameters,\n    LLMTextColumnConfig,\n    ModelConfig,\n    PersonFromFakerSamplerParams,\n    SamplerColumnConfig,\n    SamplerType,\n    SubcategorySamplerParams,\n    UniformSamplerParams,\n)\n</pre> from data_designer.essentials import (     CategorySamplerParams,     DataDesigner,     DataDesignerConfigBuilder,     InferenceParameters,     LLMTextColumnConfig,     ModelConfig,     PersonFromFakerSamplerParams,     SamplerColumnConfig,     SamplerType,     SubcategorySamplerParams,     UniformSamplerParams, ) In\u00a0[2]: Copied! <pre>data_designer = DataDesigner()\n</pre> data_designer = DataDesigner() In\u00a0[3]: Copied! <pre># This name is set in the model provider configuration.\nMODEL_PROVIDER = \"nvidia\"\n\n# The model ID is from build.nvidia.com.\nMODEL_ID = \"nvidia/nvidia-nemotron-nano-9b-v2\"\n\n# We choose this alias to be descriptive for our use case.\nMODEL_ALIAS = \"nemotron-nano-v2\"\n\n# This sets reasoning to False for the nemotron-nano-v2 model.\nSYSTEM_PROMPT = \"/no_think\"\n\nmodel_configs = [\n    ModelConfig(\n        alias=MODEL_ALIAS,\n        model=MODEL_ID,\n        provider=MODEL_PROVIDER,\n        inference_parameters=InferenceParameters(\n            temperature=0.5,\n            top_p=1.0,\n            max_tokens=1024,\n        ),\n    )\n]\n</pre> # This name is set in the model provider configuration. MODEL_PROVIDER = \"nvidia\"  # The model ID is from build.nvidia.com. MODEL_ID = \"nvidia/nvidia-nemotron-nano-9b-v2\"  # We choose this alias to be descriptive for our use case. MODEL_ALIAS = \"nemotron-nano-v2\"  # This sets reasoning to False for the nemotron-nano-v2 model. SYSTEM_PROMPT = \"/no_think\"  model_configs = [     ModelConfig(         alias=MODEL_ALIAS,         model=MODEL_ID,         provider=MODEL_PROVIDER,         inference_parameters=InferenceParameters(             temperature=0.5,             top_p=1.0,             max_tokens=1024,         ),     ) ] In\u00a0[4]: Copied! <pre>config_builder = DataDesignerConfigBuilder(model_configs=model_configs)\n</pre> config_builder = DataDesignerConfigBuilder(model_configs=model_configs) In\u00a0[5]: Copied! <pre>config_builder.info.display(\"samplers\")\n</pre> config_builder.info.display(\"samplers\") <pre>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 NeMo Data Designer Samplers \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Type               \u2503 Parameter                \u2503 Data Type                         \u2503 Required \u2503 Constraints      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 bernoulli          \u2502 p                        \u2502 number                            \u2502    \u2713     \u2502 &gt;= 0.0, &lt;= 1.0   \u2502\n\u2502                    \u2502 sampler_type             \u2502 string                            \u2502          \u2502                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bernoulli_mixture  \u2502 p                        \u2502 number                            \u2502    \u2713     \u2502 &gt;= 0.0, &lt;= 1.0   \u2502\n\u2502                    \u2502 dist_name                \u2502 string                            \u2502    \u2713     \u2502                  \u2502\n\u2502                    \u2502 dist_params              \u2502 dict                              \u2502    \u2713     \u2502                  \u2502\n\u2502                    \u2502 sampler_type             \u2502 string                            \u2502          \u2502                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 binomial           \u2502 n                        \u2502 integer                           \u2502    \u2713     \u2502                  \u2502\n\u2502                    \u2502 p                        \u2502 number                            \u2502    \u2713     \u2502 &gt;= 0.0, &lt;= 1.0   \u2502\n\u2502                    \u2502 sampler_type             \u2502 string                            \u2502          \u2502                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 category           \u2502 values                   \u2502 string[] | integer[] | number[]   \u2502    \u2713     \u2502 len &gt; 1          \u2502\n\u2502                    \u2502 weights                  \u2502 number[] | null                   \u2502          \u2502                  \u2502\n\u2502                    \u2502 sampler_type             \u2502 string                            \u2502          \u2502                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 datetime           \u2502 start                    \u2502 string                            \u2502    \u2713     \u2502                  \u2502\n\u2502                    \u2502 end                      \u2502 string                            \u2502    \u2713     \u2502                  \u2502\n\u2502                    \u2502 unit                     \u2502 string                            \u2502          \u2502                  \u2502\n\u2502                    \u2502 sampler_type             \u2502 string                            \u2502          \u2502                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 gaussian           \u2502 mean                     \u2502 number                            \u2502    \u2713     \u2502                  \u2502\n\u2502                    \u2502 stddev                   \u2502 number                            \u2502    \u2713     \u2502                  \u2502\n\u2502                    \u2502 decimal_places           \u2502 integer | null                    \u2502          \u2502                  \u2502\n\u2502                    \u2502 sampler_type             \u2502 string                            \u2502          \u2502                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 person             \u2502 locale                   \u2502 string                            \u2502          \u2502                  \u2502\n\u2502                    \u2502 sex                      \u2502 string | null                     \u2502          \u2502                  \u2502\n\u2502                    \u2502 city                     \u2502 string | string[] | null          \u2502          \u2502                  \u2502\n\u2502                    \u2502 age_range                \u2502 integer[]                         \u2502          \u2502 len &gt; 2, len &lt; 2 \u2502\n\u2502                    \u2502 select_field_values      \u2502 object | null                     \u2502          \u2502                  \u2502\n\u2502                    \u2502 with_synthetic_personas  \u2502 boolean                           \u2502          \u2502                  \u2502\n\u2502                    \u2502 sampler_type             \u2502 string                            \u2502          \u2502                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 person_from_faker  \u2502 locale                   \u2502 string                            \u2502          \u2502                  \u2502\n\u2502                    \u2502 sex                      \u2502 string | null                     \u2502          \u2502                  \u2502\n\u2502                    \u2502 city                     \u2502 string | string[] | null          \u2502          \u2502                  \u2502\n\u2502                    \u2502 age_range                \u2502 integer[]                         \u2502          \u2502 len &gt; 2, len &lt; 2 \u2502\n\u2502                    \u2502 sampler_type             \u2502 string                            \u2502          \u2502                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 poisson            \u2502 mean                     \u2502 number                            \u2502    \u2713     \u2502                  \u2502\n\u2502                    \u2502 sampler_type             \u2502 string                            \u2502          \u2502                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 scipy              \u2502 dist_name                \u2502 string                            \u2502    \u2713     \u2502                  \u2502\n\u2502                    \u2502 dist_params              \u2502 dict                              \u2502    \u2713     \u2502                  \u2502\n\u2502                    \u2502 decimal_places           \u2502 integer | null                    \u2502          \u2502                  \u2502\n\u2502                    \u2502 sampler_type             \u2502 string                            \u2502          \u2502                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 subcategory        \u2502 category                 \u2502 string                            \u2502    \u2713     \u2502                  \u2502\n\u2502                    \u2502 values                   \u2502 dict                              \u2502    \u2713     \u2502                  \u2502\n\u2502                    \u2502 sampler_type             \u2502 string                            \u2502          \u2502                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 timedelta          \u2502 dt_min                   \u2502 integer                           \u2502    \u2713     \u2502 &gt;= 0             \u2502\n\u2502                    \u2502 dt_max                   \u2502 integer                           \u2502    \u2713     \u2502 &gt; 0              \u2502\n\u2502                    \u2502 reference_column_name    \u2502 string                            \u2502    \u2713     \u2502                  \u2502\n\u2502                    \u2502 unit                     \u2502 string                            \u2502          \u2502                  \u2502\n\u2502                    \u2502 sampler_type             \u2502 string                            \u2502          \u2502                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 uniform            \u2502 low                      \u2502 number                            \u2502    \u2713     \u2502                  \u2502\n\u2502                    \u2502 high                     \u2502 number                            \u2502    \u2713     \u2502                  \u2502\n\u2502                    \u2502 decimal_places           \u2502 integer | null                    \u2502          \u2502                  \u2502\n\u2502                    \u2502 sampler_type             \u2502 string                            \u2502          \u2502                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 uuid               \u2502 prefix                   \u2502 string | null                     \u2502          \u2502                  \u2502\n\u2502                    \u2502 short_form               \u2502 boolean                           \u2502          \u2502                  \u2502\n\u2502                    \u2502 uppercase                \u2502 boolean                           \u2502          \u2502                  \u2502\n\u2502                    \u2502 sampler_type             \u2502 string                            \u2502          \u2502                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Let's start designing our product review dataset by adding product category and subcategory columns.</p> In\u00a0[6]: Copied! <pre>config_builder.add_column(\n    SamplerColumnConfig(\n        name=\"product_category\",\n        sampler_type=SamplerType.CATEGORY,\n        params=CategorySamplerParams(\n            values=[\n                \"Electronics\",\n                \"Clothing\",\n                \"Home &amp; Kitchen\",\n                \"Books\",\n                \"Home Office\",\n            ],\n        ),\n    )\n)\n\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"product_subcategory\",\n        sampler_type=SamplerType.SUBCATEGORY,\n        params=SubcategorySamplerParams(\n            category=\"product_category\",\n            values={\n                \"Electronics\": [\n                    \"Smartphones\",\n                    \"Laptops\",\n                    \"Headphones\",\n                    \"Cameras\",\n                    \"Accessories\",\n                ],\n                \"Clothing\": [\n                    \"Men's Clothing\",\n                    \"Women's Clothing\",\n                    \"Winter Coats\",\n                    \"Activewear\",\n                    \"Accessories\",\n                ],\n                \"Home &amp; Kitchen\": [\n                    \"Appliances\",\n                    \"Cookware\",\n                    \"Furniture\",\n                    \"Decor\",\n                    \"Organization\",\n                ],\n                \"Books\": [\n                    \"Fiction\",\n                    \"Non-Fiction\",\n                    \"Self-Help\",\n                    \"Textbooks\",\n                    \"Classics\",\n                ],\n                \"Home Office\": [\n                    \"Desks\",\n                    \"Chairs\",\n                    \"Storage\",\n                    \"Office Supplies\",\n                    \"Lighting\",\n                ],\n            },\n        ),\n    )\n)\n\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"target_age_range\",\n        sampler_type=SamplerType.CATEGORY,\n        params=CategorySamplerParams(values=[\"18-25\", \"25-35\", \"35-50\", \"50-65\", \"65+\"]),\n    )\n)\n\n# Optionally validate that the columns are configured correctly.\nconfig_builder.validate()\n</pre> config_builder.add_column(     SamplerColumnConfig(         name=\"product_category\",         sampler_type=SamplerType.CATEGORY,         params=CategorySamplerParams(             values=[                 \"Electronics\",                 \"Clothing\",                 \"Home &amp; Kitchen\",                 \"Books\",                 \"Home Office\",             ],         ),     ) )  config_builder.add_column(     SamplerColumnConfig(         name=\"product_subcategory\",         sampler_type=SamplerType.SUBCATEGORY,         params=SubcategorySamplerParams(             category=\"product_category\",             values={                 \"Electronics\": [                     \"Smartphones\",                     \"Laptops\",                     \"Headphones\",                     \"Cameras\",                     \"Accessories\",                 ],                 \"Clothing\": [                     \"Men's Clothing\",                     \"Women's Clothing\",                     \"Winter Coats\",                     \"Activewear\",                     \"Accessories\",                 ],                 \"Home &amp; Kitchen\": [                     \"Appliances\",                     \"Cookware\",                     \"Furniture\",                     \"Decor\",                     \"Organization\",                 ],                 \"Books\": [                     \"Fiction\",                     \"Non-Fiction\",                     \"Self-Help\",                     \"Textbooks\",                     \"Classics\",                 ],                 \"Home Office\": [                     \"Desks\",                     \"Chairs\",                     \"Storage\",                     \"Office Supplies\",                     \"Lighting\",                 ],             },         ),     ) )  config_builder.add_column(     SamplerColumnConfig(         name=\"target_age_range\",         sampler_type=SamplerType.CATEGORY,         params=CategorySamplerParams(values=[\"18-25\", \"25-35\", \"35-50\", \"50-65\", \"65+\"]),     ) )  # Optionally validate that the columns are configured correctly. config_builder.validate() <pre>[16:18:07] [INFO] \u2705 Validation passed\n</pre> Out[6]: <pre>DataDesignerConfigBuilder(\n    sampler_columns: ['product_category', 'product_subcategory', 'target_age_range']\n)\n</pre> <p>Next, let's add samplers to generate data related to the customer and their review.</p> In\u00a0[7]: Copied! <pre>config_builder.add_column(\n    SamplerColumnConfig(\n        name=\"customer\",\n        sampler_type=SamplerType.PERSON_FROM_FAKER,\n        params=PersonFromFakerSamplerParams(age_range=[18, 70], locale=\"en_US\"),\n    )\n)\n\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"number_of_stars\",\n        sampler_type=SamplerType.UNIFORM,\n        params=UniformSamplerParams(low=1, high=5),\n        convert_to=\"int\",  # Convert the sampled float to an integer.\n    )\n)\n\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"review_style\",\n        sampler_type=SamplerType.CATEGORY,\n        params=CategorySamplerParams(\n            values=[\"rambling\", \"brief\", \"detailed\", \"structured with bullet points\"],\n            weights=[1, 2, 2, 1],\n        ),\n    )\n)\n\nconfig_builder.validate()\n</pre> config_builder.add_column(     SamplerColumnConfig(         name=\"customer\",         sampler_type=SamplerType.PERSON_FROM_FAKER,         params=PersonFromFakerSamplerParams(age_range=[18, 70], locale=\"en_US\"),     ) )  config_builder.add_column(     SamplerColumnConfig(         name=\"number_of_stars\",         sampler_type=SamplerType.UNIFORM,         params=UniformSamplerParams(low=1, high=5),         convert_to=\"int\",  # Convert the sampled float to an integer.     ) )  config_builder.add_column(     SamplerColumnConfig(         name=\"review_style\",         sampler_type=SamplerType.CATEGORY,         params=CategorySamplerParams(             values=[\"rambling\", \"brief\", \"detailed\", \"structured with bullet points\"],             weights=[1, 2, 2, 1],         ),     ) )  config_builder.validate() <pre>[16:18:07] [INFO] \u2705 Validation passed\n</pre> Out[7]: <pre>DataDesignerConfigBuilder(\n    sampler_columns: [\n        \"product_category\",\n        \"product_subcategory\",\n        \"target_age_range\",\n        \"customer\",\n        \"number_of_stars\",\n        \"review_style\"\n    ]\n)\n</pre> In\u00a0[8]: Copied! <pre>config_builder.add_column(\n    LLMTextColumnConfig(\n        name=\"product_name\",\n        prompt=(\n            \"You are a helpful assistant that generates product names. DO NOT add quotes around the product name.\\n\\n\"\n            \"Come up with a creative product name for a product in the '{{ product_category }}' category, focusing \"\n            \"on products related to '{{ product_subcategory }}'. The target age range of the ideal customer is \"\n            \"{{ target_age_range }} years old. Respond with only the product name, no other text.\"\n        ),\n        system_prompt=SYSTEM_PROMPT,\n        model_alias=MODEL_ALIAS,\n    )\n)\n\nconfig_builder.add_column(\n    LLMTextColumnConfig(\n        name=\"customer_review\",\n        prompt=(\n            \"You are a customer named {{ customer.first_name }} from {{ customer.city }}, {{ customer.state }}. \"\n            \"You are {{ customer.age }} years old and recently purchased a product called {{ product_name }}. \"\n            \"Write a review of this product, which you gave a rating of {{ number_of_stars }} stars. \"\n            \"The style of the review should be '{{ review_style }}'.\"\n        ),\n        system_prompt=SYSTEM_PROMPT,\n        model_alias=MODEL_ALIAS,\n    )\n)\n\nconfig_builder.validate()\n</pre> config_builder.add_column(     LLMTextColumnConfig(         name=\"product_name\",         prompt=(             \"You are a helpful assistant that generates product names. DO NOT add quotes around the product name.\\n\\n\"             \"Come up with a creative product name for a product in the '{{ product_category }}' category, focusing \"             \"on products related to '{{ product_subcategory }}'. The target age range of the ideal customer is \"             \"{{ target_age_range }} years old. Respond with only the product name, no other text.\"         ),         system_prompt=SYSTEM_PROMPT,         model_alias=MODEL_ALIAS,     ) )  config_builder.add_column(     LLMTextColumnConfig(         name=\"customer_review\",         prompt=(             \"You are a customer named {{ customer.first_name }} from {{ customer.city }}, {{ customer.state }}. \"             \"You are {{ customer.age }} years old and recently purchased a product called {{ product_name }}. \"             \"Write a review of this product, which you gave a rating of {{ number_of_stars }} stars. \"             \"The style of the review should be '{{ review_style }}'.\"         ),         system_prompt=SYSTEM_PROMPT,         model_alias=MODEL_ALIAS,     ) )  config_builder.validate() <pre>[16:18:07] [INFO] \u2705 Validation passed\n</pre> Out[8]: <pre>DataDesignerConfigBuilder(\n    sampler_columns: [\n        \"product_category\",\n        \"product_subcategory\",\n        \"target_age_range\",\n        \"customer\",\n        \"number_of_stars\",\n        \"review_style\"\n    ]\n    llm_text_columns: ['product_name', 'customer_review']\n)\n</pre> In\u00a0[9]: Copied! <pre>preview = data_designer.preview(config_builder, num_records=2)\n</pre> preview = data_designer.preview(config_builder, num_records=2) <pre>[16:18:07] [INFO] \ud83d\udd01 Preview generation in progress\n</pre> <pre>[16:18:07] [INFO] \u2705 Validation passed\n</pre> <pre>[16:18:07] [INFO] \u26d3\ufe0f Sorting column configs into a Directed Acyclic Graph\n</pre> <pre>[16:18:07] [INFO] \ud83e\ude7a Running health checks for models...\n</pre> <pre>[16:18:07] [INFO]   |-- \ud83d\udc40 Checking 'nvidia/nvidia-nemotron-nano-9b-v2' in provider named 'nvidia' for model alias 'nemotron-nano-v2'...\n</pre> <pre>[16:18:09] [INFO]   |-- \u2705 Passed!\n</pre> <pre>[16:18:09] [INFO] \ud83c\udfb2 Preparing samplers to generate 2 records across 6 columns\n</pre> <pre>[16:18:09] [INFO] \ud83d\udcdd Preparing llm-text column generation\n</pre> <pre>[16:18:09] [INFO]   |-- column name: 'product_name'\n</pre> <pre>[16:18:09] [INFO]   |-- model config:\n{\n    \"alias\": \"nemotron-nano-v2\",\n    \"model\": \"nvidia/nvidia-nemotron-nano-9b-v2\",\n    \"inference_parameters\": {\n        \"temperature\": 0.5,\n        \"top_p\": 1.0,\n        \"max_tokens\": 1024,\n        \"max_parallel_requests\": 4,\n        \"timeout\": null,\n        \"extra_body\": null\n    },\n    \"provider\": \"nvidia\"\n}\n</pre> <pre>[16:18:09] [INFO] \ud83d\udc19 Processing llm-text column 'product_name' with 4 concurrent workers\n</pre> <pre>[16:18:10] [INFO] \ud83d\udcdd Preparing llm-text column generation\n</pre> <pre>[16:18:10] [INFO]   |-- column name: 'customer_review'\n</pre> <pre>[16:18:10] [INFO]   |-- model config:\n{\n    \"alias\": \"nemotron-nano-v2\",\n    \"model\": \"nvidia/nvidia-nemotron-nano-9b-v2\",\n    \"inference_parameters\": {\n        \"temperature\": 0.5,\n        \"top_p\": 1.0,\n        \"max_tokens\": 1024,\n        \"max_parallel_requests\": 4,\n        \"timeout\": null,\n        \"extra_body\": null\n    },\n    \"provider\": \"nvidia\"\n}\n</pre> <pre>[16:18:10] [INFO] \ud83d\udc19 Processing llm-text column 'customer_review' with 4 concurrent workers\n</pre> <pre>[16:18:17] [INFO] \ud83d\udcca Model usage summary:\n{\n    \"nvidia/nvidia-nemotron-nano-9b-v2\": {\n        \"token_usage\": {\n            \"prompt_tokens\": 328,\n            \"completion_tokens\": 1613,\n            \"total_tokens\": 1941\n        },\n        \"request_usage\": {\n            \"successful_requests\": 4,\n            \"failed_requests\": 0,\n            \"total_requests\": 4\n        },\n        \"tokens_per_second\": 262,\n        \"requests_per_minute\": 32\n    }\n}\n</pre> <pre>[16:18:17] [INFO] \ud83d\udcd0 Measuring dataset column statistics:\n</pre> <pre>[16:18:17] [INFO]   |-- \ud83c\udfb2 column: 'product_category'\n</pre> <pre>[16:18:17] [INFO]   |-- \ud83c\udfb2 column: 'product_subcategory'\n</pre> <pre>[16:18:17] [INFO]   |-- \ud83c\udfb2 column: 'target_age_range'\n</pre> <pre>[16:18:17] [INFO]   |-- \ud83c\udfb2 column: 'customer'\n</pre> <pre>[16:18:17] [INFO]   |-- \ud83c\udfb2 column: 'number_of_stars'\n</pre> <pre>[16:18:17] [INFO]   |-- \ud83c\udfb2 column: 'review_style'\n</pre> <pre>[16:18:17] [INFO]   |-- \ud83d\udcdd column: 'product_name'\n</pre> <pre>[16:18:17] [INFO]   |-- \ud83d\udcdd column: 'customer_review'\n</pre> <pre>[16:18:17] [INFO] \ud83c\udf7e Preview complete!\n</pre> In\u00a0[10]: Copied! <pre># Run this cell multiple times to cycle through the 2 preview records.\npreview.display_sample_record()\n</pre> # Run this cell multiple times to cycle through the 2 preview records. preview.display_sample_record() <pre>                                                                                                                   \n                                                 Generated Columns                                                 \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Name                \u2503 Value                                                                                     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 product_category    \u2502 Home &amp; Kitchen                                                                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 product_subcategory \u2502 Appliances                                                                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 target_age_range    \u2502 65+                                                                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer            \u2502 {                                                                                         \u2502\n\u2502                     \u2502     'uuid': '5379f936-0a99-4811-b002-8397b39f96f8',                                       \u2502\n\u2502                     \u2502     'locale': 'en_US',                                                                    \u2502\n\u2502                     \u2502     'first_name': 'Bianca',                                                               \u2502\n\u2502                     \u2502     'last_name': 'Grant',                                                                 \u2502\n\u2502                     \u2502     'middle_name': None,                                                                  \u2502\n\u2502                     \u2502     'sex': 'Female',                                                                      \u2502\n\u2502                     \u2502     'street_number': '4973',                                                              \u2502\n\u2502                     \u2502     'street_name': 'John Camp',                                                           \u2502\n\u2502                     \u2502     'city': 'Anthonyland',                                                                \u2502\n\u2502                     \u2502     'state': 'Arkansas',                                                                  \u2502\n\u2502                     \u2502     'postcode': '66139',                                                                  \u2502\n\u2502                     \u2502     'age': 65,                                                                            \u2502\n\u2502                     \u2502     'birth_date': '1959-12-10',                                                           \u2502\n\u2502                     \u2502     'country': 'Suriname',                                                                \u2502\n\u2502                     \u2502     'marital_status': 'separated',                                                        \u2502\n\u2502                     \u2502     'education_level': 'bachelors',                                                       \u2502\n\u2502                     \u2502     'unit': '',                                                                           \u2502\n\u2502                     \u2502     'occupation': 'TEFL teacher',                                                         \u2502\n\u2502                     \u2502     'phone_number': '379-906-5541x9921',                                                  \u2502\n\u2502                     \u2502     'bachelors_field': 'arts_humanities'                                                  \u2502\n\u2502                     \u2502 }                                                                                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 number_of_stars     \u2502 3                                                                                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 review_style        \u2502 detailed                                                                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 product_name        \u2502 SeniorSaver Appliance                                                                     \u2502\n\u2502                     \u2502                                                                                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer_review     \u2502 **Product Review: SeniorSaver Appliance by Bianca from Anthonyland, Arkansas**            \u2502\n\u2502                     \u2502 **Rating: 3 Stars**                                                                       \u2502\n\u2502                     \u2502                                                                                           \u2502\n\u2502                     \u2502 As a 65-year-old resident of Anthonyland, Arkansas, I recently purchased the SeniorSaver  \u2502\n\u2502                     \u2502 Appliance with the hope that it would simplify daily tasks and provide some much-needed   \u2502\n\u2502                     \u2502 convenience in my home. While I appreciate the effort behind this product and understand  \u2502\n\u2502                     \u2502 its intended purpose, my experience has been a mix of practical benefits and notable      \u2502\n\u2502                     \u2502 drawbacks, which I\u2019ll detail below.                                                       \u2502\n\u2502                     \u2502                                                                                           \u2502\n\u2502                     \u2502 **What I Liked:**                                                                         \u2502\n\u2502                     \u2502 First, the SeniorSaver Appliance is designed with seniors in mind, which is commendable.  \u2502\n\u2502                     \u2502 The company clearly aimed to address common challenges faced by older adults, such as     \u2502\n\u2502                     \u2502 difficulty with complex controls or physical strain. The appliance itself is sturdy and   \u2502\n\u2502                     \u2502 well-built, which is a plus for something you want to last. I particularly liked the      \u2502\n\u2502                     \u2502 large, clearly labeled buttons\u2014something that can be a real relief for someone with       \u2502\n\u2502                     \u2502 limited dexterity or vision issues. The setup process was relatively straightforward, and \u2502\n\u2502                     \u2502 the included manual, while a bit dense, did offer step-by-step instructions that helped   \u2502\n\u2502                     \u2502 me get started without too much frustration.                                              \u2502\n\u2502                     \u2502                                                                                           \u2502\n\u2502                     \u2502 The appliance also has a few useful features. For instance, it includes a timer function  \u2502\n\u2502                     \u2502 that allows you to pre-set cooking or cleaning cycles, which I found helpful for managing \u2502\n\u2502                     \u2502 my time, especially on days when I\u2019m feeling tired or unwell. Additionally, the           \u2502\n\u2502                     \u2502 energy-saving mode is a nice touch, as it aligns with my goal of reducing utility costs.  \u2502\n\u2502                     \u2502 These aspects made me feel like the product was thoughtfully designed for its target      \u2502\n\u2502                     \u2502 audience.                                                                                 \u2502\n\u2502                     \u2502                                                                                           \u2502\n\u2502                     \u2502 **What Didn\u2019t Meet Expectations:**                                                        \u2502\n\u2502                     \u2502 However, there are several areas where the SeniorSaver Appliance fell short of my         \u2502\n\u2502                     \u2502 expectations. One of the main issues is the learning curve. While the buttons are large,  \u2502\n\u2502                     \u2502 the overall interface feels unintuitive. For someone who isn\u2019t tech-savvy\u2014like myself\u2014the \u2502\n\u2502                     \u2502 lack of a digital display or voice-guided instructions made it challenging to navigate    \u2502\n\u2502                     \u2502 certain functions. I spent a significant amount of time trial-and-error to figure out how \u2502\n\u2502                     \u2502 to adjust settings or troubleshoot minor issues, which was both time-consuming and        \u2502\n\u2502                     \u2502 slightly discouraging.                                                                    \u2502\n\u2502                     \u2502                                                                                           \u2502\n\u2502                     \u2502 Another concern is the durability of certain components. After about three months of      \u2502\n\u2502                     \u2502 regular use, I noticed that the plastic casing on the top of the appliance began to       \u2502\n\u2502                     \u2502 crack, especially around the areas where I frequently pressed buttons. While this might   \u2502\n\u2502                     \u2502 not be a dealbreaker for everyone, it\u2019s disappointing for a product marketed as a         \u2502\n\u2502                     \u2502 long-term solution for seniors. Additionally, the noise level during operation is louder  \u2502\n\u2502                     \u2502 than I anticipated. For someone who values quiet operation\u2014especially in a home           \u2502\n\u2502                     \u2502 setting\u2014this was a bit of a surprise.                                                     \u2502\n\u2502                     \u2502                                                                                           \u2502\n\u2502                     \u2502 **Customer Service Experience:**                                                          \u2502\n\u2502                     \u2502 I did reach out to the company\u2019s customer service regarding the noise and the cracked     \u2502\n\u2502                     \u2502 casing. While the representative was polite and helpful, the resolution process was slow. \u2502\n\u2502                     \u2502 It took over a week to get a response, and the fix they offered (a replacement part)      \u2502\n\u2502                     \u2502 required me to ship the appliance back, which was inconvenient given my limited mobility. \u2502\n\u2502                     \u2502 This experience, while not directly related to the product itself, added to my overall    \u2502\n\u2502                     \u2502 frustration.                                                                              \u2502\n\u2502                     \u2502                                                                                           \u2502\n\u2502                     \u2502 **Final Thoughts:**                                                                       \u2502\n\u2502                     \u2502 The SeniorSaver Appliance has its merits, particularly in its design for seniors and some \u2502\n\u2502                     \u2502 practical features like the timer and energy-saving mode. However, the usability          \u2502\n\u2502                     \u2502 challenges, durability issues, and customer service delays prevented it from earning a    \u2502\n\u2502                     \u2502 higher rating. If I were to recommend this product, I\u2019d suggest it to someone who is      \u2502\n\u2502                     \u2502 comfortable with a bit of a learning curve and doesn\u2019t mind potential maintenance issues. \u2502\n\u2502                     \u2502 For a 3-star rating, I feel it\u2019s a product that works *somewhat* as intended but doesn\u2019t  \u2502\n\u2502                     \u2502 fully deliver on the convenience and reliability it promises.                             \u2502\n\u2502                     \u2502                                                                                           \u2502\n\u2502                     \u2502 Overall, I\u2019m not entirely dissatisfied, but I\u2019m also not fully impressed. It\u2019s a          \u2502\n\u2502                     \u2502 middle-of-the-road option that might suit certain needs but isn\u2019t perfect for everyone.   \u2502\n\u2502                     \u2502                                                                                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                    [index: 0]                                                     \n</pre> In\u00a0[11]: Copied! <pre># The preview dataset is available as a pandas DataFrame.\npreview.dataset\n</pre> # The preview dataset is available as a pandas DataFrame. preview.dataset Out[11]: product_category product_subcategory target_age_range customer number_of_stars review_style product_name customer_review 0 Home &amp; Kitchen Appliances 65+ {'uuid': '5379f936-0a99-4811-b002-8397b39f96f8... 3 detailed SeniorSaver Appliance\\n **Product Review: SeniorSaver Appliance by Bia... 1 Home &amp; Kitchen Cookware 35-50 {'uuid': 'f400880b-6cfb-44ba-b5d1-bf26e9ed4305... 2 detailed SizzleScape\\n **Title:** Disappointing Experience with Sizzl... In\u00a0[12]: Copied! <pre># Print the analysis as a table.\npreview.analysis.to_report()\n</pre> # Print the analysis as a table. preview.analysis.to_report() <pre>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83c\udfa8 Data Designer Dataset Profile \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n                                                                                                                   \n                                                 Dataset Overview                                                  \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 number of records               \u2503 number of columns               \u2503 percent complete records                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 2                               \u2502 8                               \u2502 100.0%                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                                \ud83c\udfb2 Sampler Columns                                                 \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 column name                    \u2503       data type \u2503            number unique values \u2503               sampler type \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 product_category               \u2502          string \u2502                       1 (50.0%) \u2502                   category \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 product_subcategory            \u2502          string \u2502                      2 (100.0%) \u2502                subcategory \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 target_age_range               \u2502          string \u2502                      2 (100.0%) \u2502                   category \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer                       \u2502            dict \u2502                      2 (100.0%) \u2502          person_from_faker \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 number_of_stars                \u2502             int \u2502                      2 (100.0%) \u2502                    uniform \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 review_style                   \u2502          string \u2502                       1 (50.0%) \u2502                   category \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                                \ud83d\udcdd LLM-Text Columns                                                \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503                       \u2503               \u2503                            \u2503     prompt tokens \u2503      completion tokens \u2503\n\u2503 column name           \u2503     data type \u2503       number unique values \u2503        per record \u2503             per record \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 product_name          \u2502        string \u2502                 2 (100.0%) \u2502      78.0 +/- 0.0 \u2502            5.5 +/- 0.7 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer_review       \u2502        string \u2502                 2 (100.0%) \u2502      63.5 +/- 0.5 \u2502         771.0 +/- 32.5 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Table Notes \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                                 \u2502\n\u2502  1. All token statistics are based on a sample of max(1000, len(dataset)) records.                              \u2502\n\u2502  2. Tokens are calculated using tiktoken's cl100k_base tokenizer.                                               \u2502\n\u2502                                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n                                                                                                                   \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</pre> In\u00a0[13]: Copied! <pre>results = data_designer.create(config_builder, num_records=10)\n</pre> results = data_designer.create(config_builder, num_records=10) <pre>[16:18:17] [INFO] \ud83c\udfa8 Creating Data Designer dataset\n</pre> <pre>[16:18:17] [INFO] \u2705 Validation passed\n</pre> <pre>[16:18:17] [INFO] \u26d3\ufe0f Sorting column configs into a Directed Acyclic Graph\n</pre> <pre>[16:18:17] [INFO] \ud83e\ude7a Running health checks for models...\n</pre> <pre>[16:18:17] [INFO]   |-- \ud83d\udc40 Checking 'nvidia/nvidia-nemotron-nano-9b-v2' in provider named 'nvidia' for model alias 'nemotron-nano-v2'...\n</pre> <pre>[16:18:18] [INFO]   |-- \u2705 Passed!\n</pre> <pre>[16:18:18] [INFO] \u23f3 Processing batch 1 of 1\n</pre> <pre>[16:18:18] [INFO] \ud83c\udfb2 Preparing samplers to generate 10 records across 6 columns\n</pre> <pre>[16:18:18] [INFO] \ud83d\udcdd Preparing llm-text column generation\n</pre> <pre>[16:18:18] [INFO]   |-- column name: 'product_name'\n</pre> <pre>[16:18:18] [INFO]   |-- model config:\n{\n    \"alias\": \"nemotron-nano-v2\",\n    \"model\": \"nvidia/nvidia-nemotron-nano-9b-v2\",\n    \"inference_parameters\": {\n        \"temperature\": 0.5,\n        \"top_p\": 1.0,\n        \"max_tokens\": 1024,\n        \"max_parallel_requests\": 4,\n        \"timeout\": null,\n        \"extra_body\": null\n    },\n    \"provider\": \"nvidia\"\n}\n</pre> <pre>[16:18:18] [INFO] \ud83d\udc19 Processing llm-text column 'product_name' with 4 concurrent workers\n</pre> <pre>[16:18:21] [INFO] \ud83d\udcdd Preparing llm-text column generation\n</pre> <pre>[16:18:21] [INFO]   |-- column name: 'customer_review'\n</pre> <pre>[16:18:21] [INFO]   |-- model config:\n{\n    \"alias\": \"nemotron-nano-v2\",\n    \"model\": \"nvidia/nvidia-nemotron-nano-9b-v2\",\n    \"inference_parameters\": {\n        \"temperature\": 0.5,\n        \"top_p\": 1.0,\n        \"max_tokens\": 1024,\n        \"max_parallel_requests\": 4,\n        \"timeout\": null,\n        \"extra_body\": null\n    },\n    \"provider\": \"nvidia\"\n}\n</pre> <pre>[16:18:21] [INFO] \ud83d\udc19 Processing llm-text column 'customer_review' with 4 concurrent workers\n</pre> <pre>[16:18:37] [INFO] \ud83d\udcca Model usage summary:\n{\n    \"nvidia/nvidia-nemotron-nano-9b-v2\": {\n        \"token_usage\": {\n            \"prompt_tokens\": 1624,\n            \"completion_tokens\": 5577,\n            \"total_tokens\": 7201\n        },\n        \"request_usage\": {\n            \"successful_requests\": 20,\n            \"failed_requests\": 0,\n            \"total_requests\": 20\n        },\n        \"tokens_per_second\": 369,\n        \"requests_per_minute\": 61\n    }\n}\n</pre> <pre>[16:18:37] [INFO] \ud83d\udcd0 Measuring dataset column statistics:\n</pre> <pre>[16:18:37] [INFO]   |-- \ud83c\udfb2 column: 'product_category'\n</pre> <pre>[16:18:37] [INFO]   |-- \ud83c\udfb2 column: 'product_subcategory'\n</pre> <pre>[16:18:37] [INFO]   |-- \ud83c\udfb2 column: 'target_age_range'\n</pre> <pre>[16:18:37] [INFO]   |-- \ud83c\udfb2 column: 'customer'\n</pre> <pre>[16:18:37] [INFO]   |-- \ud83c\udfb2 column: 'number_of_stars'\n</pre> <pre>[16:18:37] [INFO]   |-- \ud83c\udfb2 column: 'review_style'\n</pre> <pre>[16:18:37] [INFO]   |-- \ud83d\udcdd column: 'product_name'\n</pre> <pre>[16:18:37] [INFO]   |-- \ud83d\udcdd column: 'customer_review'\n</pre> In\u00a0[14]: Copied! <pre># Load the generated dataset as a pandas DataFrame.\ndataset = results.load_dataset()\n\ndataset.head()\n</pre> # Load the generated dataset as a pandas DataFrame. dataset = results.load_dataset()  dataset.head() Out[14]: product_category product_subcategory target_age_range customer number_of_stars review_style product_name customer_review 0 Books Textbooks 65+ {'age': 67, 'bachelors_field': 'stem_related',... 2 rambling TimelessTextbooks Well, I guess I\u2019ll just throw out some thought... 1 Clothing Activewear 65+ {'age': 59, 'bachelors_field': 'stem', 'birth_... 3 structured with bullet points TimelessActive **Review of TimelessActive by Rodney from Sout... 2 Electronics Accessories 25-35 {'age': 35, 'bachelors_field': 'education', 'b... 2 detailed NeonPulse **Product Review: NeonPulse \u2013 A Disappointing ... 3 Electronics Headphones 35-50 {'age': 47, 'bachelors_field': 'stem_related',... 4 detailed SoundSage **Product Review: SoundSage by Timothy from Gr... 4 Books Non-Fiction 25-35 {'age': 66, 'bachelors_field': 'no_degree', 'b... 4 detailed MindScape Chronicles **Product Review: MindScape Chronicles (Rating... In\u00a0[15]: Copied! <pre># Load the analysis results into memory.\nanalysis = results.load_analysis()\n\nanalysis.to_report()\n</pre> # Load the analysis results into memory. analysis = results.load_analysis()  analysis.to_report() <pre>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83c\udfa8 Data Designer Dataset Profile \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n                                                                                                                   \n                                                 Dataset Overview                                                  \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 number of records               \u2503 number of columns               \u2503 percent complete records                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 10                              \u2502 8                               \u2502 100.0%                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                                \ud83c\udfb2 Sampler Columns                                                 \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 column name                    \u2503       data type \u2503            number unique values \u2503               sampler type \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 product_category               \u2502          string \u2502                       4 (40.0%) \u2502                   category \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 product_subcategory            \u2502          string \u2502                       8 (80.0%) \u2502                subcategory \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 target_age_range               \u2502          string \u2502                       4 (40.0%) \u2502                   category \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer                       \u2502            dict \u2502                     10 (100.0%) \u2502          person_from_faker \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 number_of_stars                \u2502             int \u2502                       5 (50.0%) \u2502                    uniform \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 review_style                   \u2502          string \u2502                       4 (40.0%) \u2502                   category \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                                \ud83d\udcdd LLM-Text Columns                                                \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503                       \u2503               \u2503                            \u2503     prompt tokens \u2503      completion tokens \u2503\n\u2503 column name           \u2503     data type \u2503       number unique values \u2503        per record \u2503             per record \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 product_name          \u2502        string \u2502                  8 (80.0%) \u2502      77.0 +/- 0.7 \u2502            5.0 +/- 1.1 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer_review       \u2502        string \u2502                10 (100.0%) \u2502      62.5 +/- 1.4 \u2502        698.5 +/- 405.3 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Table Notes \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                                 \u2502\n\u2502  1. All token statistics are based on a sample of max(1000, len(dataset)) records.                              \u2502\n\u2502  2. Tokens are calculated using tiktoken's cl100k_base tokenizer.                                               \u2502\n\u2502                                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n                                                                                                                   \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</pre>"},{"location":"notebooks/1-the-basics/#data-designer-tutorial-the-basics","title":"\ud83c\udfa8 Data Designer Tutorial: The Basics\u00b6","text":""},{"location":"notebooks/1-the-basics/#what-youll-learn","title":"\ud83d\udcda What you'll learn\u00b6","text":"<p>This notebook demonstrates the basics of Data Designer by generating a simple product review dataset.</p>"},{"location":"notebooks/1-the-basics/#import-the-essentials","title":"\ud83d\udce6 Import the essentials\u00b6","text":"<ul> <li>The <code>essentials</code> module provides quick access to the most commonly used objects.</li> </ul>"},{"location":"notebooks/1-the-basics/#initialize-the-data-designer-interface","title":"\u2699\ufe0f Initialize the Data Designer interface\u00b6","text":"<ul> <li><p><code>DataDesigner</code> is the main object is responsible for managing the data generation process.</p> </li> <li><p>When initialized without arguments, the default model providers are used.</p> </li> </ul>"},{"location":"notebooks/1-the-basics/#define-model-configurations","title":"\ud83c\udf9b\ufe0f Define model configurations\u00b6","text":"<ul> <li><p>Each <code>ModelConfig</code> defines a model that can be used during the generation process.</p> </li> <li><p>The \"model alias\" is used to reference the model in the Data Designer config (as we will see below).</p> </li> <li><p>The \"model provider\" is the external service that hosts the model (see the model config docs for more details).</p> </li> <li><p>By default, we use build.nvidia.com as the model provider.</p> </li> </ul>"},{"location":"notebooks/1-the-basics/#initialize-the-data-designer-config-builder","title":"\ud83c\udfd7\ufe0f Initialize the Data Designer Config Builder\u00b6","text":"<ul> <li><p>The Data Designer config defines the dataset schema and generation process.</p> </li> <li><p>The config builder provides an intuitive interface for building this configuration.</p> </li> <li><p>The list of model configs is provided to the builder at initialization.</p> </li> </ul>"},{"location":"notebooks/1-the-basics/#getting-started-with-sampler-columns","title":"\ud83c\udfb2 Getting started with sampler columns\u00b6","text":"<ul> <li><p>Sampler columns offer non-LLM based generation of synthetic data.</p> </li> <li><p>They are particularly useful for steering the diversity of the generated data, as we demonstrate below.</p> </li> </ul> <p>You can view available samplers using the config builder's <code>info</code> property:</p>"},{"location":"notebooks/1-the-basics/#llm-generated-columns","title":"\ud83e\udd9c LLM-generated columns\u00b6","text":"<ul> <li><p>The real power of Data Designer comes from leveraging LLMs to generate text, code, and structured data.</p> </li> <li><p>When prompting the LLM, we can use Jinja templating to reference other columns in the dataset.</p> </li> <li><p>As we see below, nested json fields can be accessed using dot notation.</p> </li> </ul>"},{"location":"notebooks/1-the-basics/#iteration-is-key-preview-the-dataset","title":"\ud83d\udd01 Iteration is key \u2013\u00a0preview the dataset!\u00b6","text":"<ol> <li><p>Use the <code>preview</code> method to generate a sample of records quickly.</p> </li> <li><p>Inspect the results for quality and format issues.</p> </li> <li><p>Adjust column configurations, prompts, or parameters as needed.</p> </li> <li><p>Re-run the preview until satisfied.</p> </li> </ol>"},{"location":"notebooks/1-the-basics/#analyze-the-generated-data","title":"\ud83d\udcca Analyze the generated data\u00b6","text":"<ul> <li><p>Data Designer automatically generates a basic statistical analysis of the generated data.</p> </li> <li><p>This analysis is available via the <code>analysis</code> property of generation result objects.</p> </li> </ul>"},{"location":"notebooks/1-the-basics/#scale-up","title":"\ud83c\udd99 Scale up!\u00b6","text":"<ul> <li><p>Happy with your preview data?</p> </li> <li><p>Use the <code>create</code> method to submit larger Data Designer generation jobs.</p> </li> </ul>"},{"location":"notebooks/1-the-basics/#next-steps","title":"\u23ed\ufe0f Next Steps\u00b6","text":"<p>Now that you've seen the basics of Data Designer, check out the following notebooks to learn more about:</p> <ul> <li><p>Structured outputs and jinja expressions</p> </li> <li><p>Seeding synthetic data generation with an external dataset</p> </li> </ul>"},{"location":"notebooks/2-structured-outputs-and-jinja-expressions/","title":"Structured Outputs and Jinja Expressions","text":"In\u00a0[1]: Copied! <pre>from data_designer.essentials import (\n    CategorySamplerParams,\n    DataDesigner,\n    DataDesignerConfigBuilder,\n    ExpressionColumnConfig,\n    InferenceParameters,\n    LLMStructuredColumnConfig,\n    ModelConfig,\n    PersonFromFakerSamplerParams,\n    SamplerColumnConfig,\n    SamplerType,\n    SubcategorySamplerParams,\n)\n</pre> from data_designer.essentials import (     CategorySamplerParams,     DataDesigner,     DataDesignerConfigBuilder,     ExpressionColumnConfig,     InferenceParameters,     LLMStructuredColumnConfig,     ModelConfig,     PersonFromFakerSamplerParams,     SamplerColumnConfig,     SamplerType,     SubcategorySamplerParams, ) In\u00a0[2]: Copied! <pre>data_designer_client = DataDesigner()\n</pre> data_designer_client = DataDesigner() In\u00a0[3]: Copied! <pre># This name is set in the model provider configuration.\nMODEL_PROVIDER = \"nvidia\"\n\n# The model ID is from build.nvidia.com.\nMODEL_ID = \"nvidia/nvidia-nemotron-nano-9b-v2\"\n\n# We choose this alias to be descriptive for our use case.\nMODEL_ALIAS = \"nemotron-nano-v2\"\n\n# This sets reasoning to False for the nemotron-nano-v2 model.\nSYSTEM_PROMPT = \"/no_think\"\n\nmodel_configs = [\n    ModelConfig(\n        alias=MODEL_ALIAS,\n        model=MODEL_ID,\n        provider=MODEL_PROVIDER,\n        inference_parameters=InferenceParameters(\n            temperature=0.5,\n            top_p=1.0,\n            max_tokens=1024,\n        ),\n    )\n]\n</pre> # This name is set in the model provider configuration. MODEL_PROVIDER = \"nvidia\"  # The model ID is from build.nvidia.com. MODEL_ID = \"nvidia/nvidia-nemotron-nano-9b-v2\"  # We choose this alias to be descriptive for our use case. MODEL_ALIAS = \"nemotron-nano-v2\"  # This sets reasoning to False for the nemotron-nano-v2 model. SYSTEM_PROMPT = \"/no_think\"  model_configs = [     ModelConfig(         alias=MODEL_ALIAS,         model=MODEL_ID,         provider=MODEL_PROVIDER,         inference_parameters=InferenceParameters(             temperature=0.5,             top_p=1.0,             max_tokens=1024,         ),     ) ] In\u00a0[4]: Copied! <pre>config_builder = DataDesignerConfigBuilder(model_configs=model_configs)\n</pre> config_builder = DataDesignerConfigBuilder(model_configs=model_configs) In\u00a0[5]: Copied! <pre>from decimal import Decimal\nfrom typing import Literal\n\nfrom pydantic import BaseModel, Field\n\n\n# We define a Product schema so that the name, description, and price are generated\n# in one go, with the types and constraints specified.\nclass Product(BaseModel):\n    name: str = Field(description=\"The name of the product\")\n    description: str = Field(description=\"A description of the product\")\n    price: Decimal = Field(description=\"The price of the product\", ge=10, le=1000, decimal_places=2)\n\n\nclass ProductReview(BaseModel):\n    rating: int = Field(description=\"The rating of the product\", ge=1, le=5)\n    customer_mood: Literal[\"irritated\", \"mad\", \"happy\", \"neutral\", \"excited\"] = Field(\n        description=\"The mood of the customer\"\n    )\n    review: str = Field(description=\"A review of the product\")\n</pre> from decimal import Decimal from typing import Literal  from pydantic import BaseModel, Field   # We define a Product schema so that the name, description, and price are generated # in one go, with the types and constraints specified. class Product(BaseModel):     name: str = Field(description=\"The name of the product\")     description: str = Field(description=\"A description of the product\")     price: Decimal = Field(description=\"The price of the product\", ge=10, le=1000, decimal_places=2)   class ProductReview(BaseModel):     rating: int = Field(description=\"The rating of the product\", ge=1, le=5)     customer_mood: Literal[\"irritated\", \"mad\", \"happy\", \"neutral\", \"excited\"] = Field(         description=\"The mood of the customer\"     )     review: str = Field(description=\"A review of the product\") <p>Next, let's design our product review dataset using a few more tricks compared to the previous notebook.</p> In\u00a0[6]: Copied! <pre># Since we often only want a few attributes from Person objects, we can\n# set drop=True in the column config to drop the column from the final dataset.\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"customer\",\n        sampler_type=SamplerType.PERSON_FROM_FAKER,\n        params=PersonFromFakerSamplerParams(),\n        drop=True,\n    )\n)\n\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"product_category\",\n        sampler_type=SamplerType.CATEGORY,\n        params=CategorySamplerParams(\n            values=[\n                \"Electronics\",\n                \"Clothing\",\n                \"Home &amp; Kitchen\",\n                \"Books\",\n                \"Home Office\",\n            ],\n        ),\n    )\n)\n\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"product_subcategory\",\n        sampler_type=SamplerType.SUBCATEGORY,\n        params=SubcategorySamplerParams(\n            category=\"product_category\",\n            values={\n                \"Electronics\": [\n                    \"Smartphones\",\n                    \"Laptops\",\n                    \"Headphones\",\n                    \"Cameras\",\n                    \"Accessories\",\n                ],\n                \"Clothing\": [\n                    \"Men's Clothing\",\n                    \"Women's Clothing\",\n                    \"Winter Coats\",\n                    \"Activewear\",\n                    \"Accessories\",\n                ],\n                \"Home &amp; Kitchen\": [\n                    \"Appliances\",\n                    \"Cookware\",\n                    \"Furniture\",\n                    \"Decor\",\n                    \"Organization\",\n                ],\n                \"Books\": [\n                    \"Fiction\",\n                    \"Non-Fiction\",\n                    \"Self-Help\",\n                    \"Textbooks\",\n                    \"Classics\",\n                ],\n                \"Home Office\": [\n                    \"Desks\",\n                    \"Chairs\",\n                    \"Storage\",\n                    \"Office Supplies\",\n                    \"Lighting\",\n                ],\n            },\n        ),\n    )\n)\n\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"target_age_range\",\n        sampler_type=SamplerType.CATEGORY,\n        params=CategorySamplerParams(values=[\"18-25\", \"25-35\", \"35-50\", \"50-65\", \"65+\"]),\n    )\n)\n\n# Sampler columns support conditional params, which are used if the condition is met.\n# In this example, we set the review style to rambling if the target age range is 18-25.\n# Note conditional parameters are only supported for Sampler column types.\nconfig_builder.add_column(\n    SamplerColumnConfig(\n        name=\"review_style\",\n        sampler_type=SamplerType.CATEGORY,\n        params=CategorySamplerParams(\n            values=[\"rambling\", \"brief\", \"detailed\", \"structured with bullet points\"],\n            weights=[1, 2, 2, 1],\n        ),\n        conditional_params={\n            \"target_age_range == '18-25'\": CategorySamplerParams(values=[\"rambling\"]),\n        },\n    )\n)\n\n# Optionally validate that the columns are configured correctly.\nconfig_builder.validate()\n</pre> # Since we often only want a few attributes from Person objects, we can # set drop=True in the column config to drop the column from the final dataset. config_builder.add_column(     SamplerColumnConfig(         name=\"customer\",         sampler_type=SamplerType.PERSON_FROM_FAKER,         params=PersonFromFakerSamplerParams(),         drop=True,     ) )  config_builder.add_column(     SamplerColumnConfig(         name=\"product_category\",         sampler_type=SamplerType.CATEGORY,         params=CategorySamplerParams(             values=[                 \"Electronics\",                 \"Clothing\",                 \"Home &amp; Kitchen\",                 \"Books\",                 \"Home Office\",             ],         ),     ) )  config_builder.add_column(     SamplerColumnConfig(         name=\"product_subcategory\",         sampler_type=SamplerType.SUBCATEGORY,         params=SubcategorySamplerParams(             category=\"product_category\",             values={                 \"Electronics\": [                     \"Smartphones\",                     \"Laptops\",                     \"Headphones\",                     \"Cameras\",                     \"Accessories\",                 ],                 \"Clothing\": [                     \"Men's Clothing\",                     \"Women's Clothing\",                     \"Winter Coats\",                     \"Activewear\",                     \"Accessories\",                 ],                 \"Home &amp; Kitchen\": [                     \"Appliances\",                     \"Cookware\",                     \"Furniture\",                     \"Decor\",                     \"Organization\",                 ],                 \"Books\": [                     \"Fiction\",                     \"Non-Fiction\",                     \"Self-Help\",                     \"Textbooks\",                     \"Classics\",                 ],                 \"Home Office\": [                     \"Desks\",                     \"Chairs\",                     \"Storage\",                     \"Office Supplies\",                     \"Lighting\",                 ],             },         ),     ) )  config_builder.add_column(     SamplerColumnConfig(         name=\"target_age_range\",         sampler_type=SamplerType.CATEGORY,         params=CategorySamplerParams(values=[\"18-25\", \"25-35\", \"35-50\", \"50-65\", \"65+\"]),     ) )  # Sampler columns support conditional params, which are used if the condition is met. # In this example, we set the review style to rambling if the target age range is 18-25. # Note conditional parameters are only supported for Sampler column types. config_builder.add_column(     SamplerColumnConfig(         name=\"review_style\",         sampler_type=SamplerType.CATEGORY,         params=CategorySamplerParams(             values=[\"rambling\", \"brief\", \"detailed\", \"structured with bullet points\"],             weights=[1, 2, 2, 1],         ),         conditional_params={             \"target_age_range == '18-25'\": CategorySamplerParams(values=[\"rambling\"]),         },     ) )  # Optionally validate that the columns are configured correctly. config_builder.validate() <pre>[16:18:44] [INFO] \u2705 Validation passed\n</pre> Out[6]: <pre>DataDesignerConfigBuilder(\n    sampler_columns: [\n        \"customer\",\n        \"product_category\",\n        \"product_subcategory\",\n        \"target_age_range\",\n        \"review_style\"\n    ]\n)\n</pre> <p>Next, we will use more advanced Jinja expressions to create new columns.</p> <p>Jinja expressions let you:</p> <ul> <li><p>Access nested attributes: <code>{{ customer.first_name }}</code></p> </li> <li><p>Combine values: <code>{{ customer.first_name }} {{ customer.last_name }}</code></p> </li> <li><p>Use conditional logic: <code>{% if condition %}...{% endif %}</code></p> </li> </ul> In\u00a0[7]: Copied! <pre># We can create new columns using Jinja expressions that reference\n# existing columns, including attributes of nested objects.\nconfig_builder.add_column(\n    ExpressionColumnConfig(name=\"customer_name\", expr=\"{{ customer.first_name }} {{ customer.last_name }}\")\n)\n\nconfig_builder.add_column(ExpressionColumnConfig(name=\"customer_age\", expr=\"{{ customer.age }}\"))\n\nconfig_builder.add_column(\n    LLMStructuredColumnConfig(\n        name=\"product\",\n        prompt=(\n            \"Create a product in the '{{ product_category }}' category, focusing on products  \"\n            \"related to '{{ product_subcategory }}'. The target age range of the ideal customer is \"\n            \"{{ target_age_range }} years old. The product should be priced between $10 and $1000.\"\n        ),\n        system_prompt=SYSTEM_PROMPT,\n        output_format=Product,\n        model_alias=MODEL_ALIAS,\n    )\n)\n\n# We can even use if/else logic in our Jinja expressions to create more complex prompt patterns.\nconfig_builder.add_column(\n    LLMStructuredColumnConfig(\n        name=\"customer_review\",\n        prompt=(\n            \"Your task is to write a review for the following product:\\n\\n\"\n            \"Product Name: {{ product.name }}\\n\"\n            \"Product Description: {{ product.description }}\\n\"\n            \"Price: {{ product.price }}\\n\\n\"\n            \"Imagine your name is {{ customer_name }} and you are from {{ customer.city }}, {{ customer.state }}. \"\n            \"Write the review in a style that is '{{ review_style }}'.\"\n            \"{% if target_age_range == '18-25' %}\"\n            \"Make sure the review is more informal and conversational.\"\n            \"{% else %}\"\n            \"Make sure the review is more formal and structured.\"\n            \"{% endif %}\"\n        ),\n        system_prompt=SYSTEM_PROMPT,\n        output_format=ProductReview,\n        model_alias=MODEL_ALIAS,\n    )\n)\n\nconfig_builder.validate()\n</pre> # We can create new columns using Jinja expressions that reference # existing columns, including attributes of nested objects. config_builder.add_column(     ExpressionColumnConfig(name=\"customer_name\", expr=\"{{ customer.first_name }} {{ customer.last_name }}\") )  config_builder.add_column(ExpressionColumnConfig(name=\"customer_age\", expr=\"{{ customer.age }}\"))  config_builder.add_column(     LLMStructuredColumnConfig(         name=\"product\",         prompt=(             \"Create a product in the '{{ product_category }}' category, focusing on products  \"             \"related to '{{ product_subcategory }}'. The target age range of the ideal customer is \"             \"{{ target_age_range }} years old. The product should be priced between $10 and $1000.\"         ),         system_prompt=SYSTEM_PROMPT,         output_format=Product,         model_alias=MODEL_ALIAS,     ) )  # We can even use if/else logic in our Jinja expressions to create more complex prompt patterns. config_builder.add_column(     LLMStructuredColumnConfig(         name=\"customer_review\",         prompt=(             \"Your task is to write a review for the following product:\\n\\n\"             \"Product Name: {{ product.name }}\\n\"             \"Product Description: {{ product.description }}\\n\"             \"Price: {{ product.price }}\\n\\n\"             \"Imagine your name is {{ customer_name }} and you are from {{ customer.city }}, {{ customer.state }}. \"             \"Write the review in a style that is '{{ review_style }}'.\"             \"{% if target_age_range == '18-25' %}\"             \"Make sure the review is more informal and conversational.\"             \"{% else %}\"             \"Make sure the review is more formal and structured.\"             \"{% endif %}\"         ),         system_prompt=SYSTEM_PROMPT,         output_format=ProductReview,         model_alias=MODEL_ALIAS,     ) )  config_builder.validate() <pre>[16:18:44] [INFO] \u2705 Validation passed\n</pre> Out[7]: <pre>DataDesignerConfigBuilder(\n    sampler_columns: [\n        \"customer\",\n        \"product_category\",\n        \"product_subcategory\",\n        \"target_age_range\",\n        \"review_style\"\n    ]\n    llm_structured_columns: ['product', 'customer_review']\n    expression_columns: ['customer_name', 'customer_age']\n)\n</pre> In\u00a0[8]: Copied! <pre>preview = data_designer_client.preview(config_builder, num_records=2)\n</pre> preview = data_designer_client.preview(config_builder, num_records=2) <pre>[16:18:44] [INFO] \ud83d\udc41\ufe0f Preview generation in progress\n</pre> <pre>[16:18:44] [INFO] \u2705 Validation passed\n</pre> <pre>[16:18:44] [INFO] \u26d3\ufe0f Sorting column configs into a Directed Acyclic Graph\n</pre> <pre>[16:18:44] [INFO] \ud83e\ude7a Running health checks for models...\n</pre> <pre>[16:18:44] [INFO]   |-- \ud83d\udc40 Checking 'nvidia/nvidia-nemotron-nano-9b-v2' in provider named 'nvidia' for model alias 'nemotron-nano-v2'...\n</pre> <pre>[16:18:45] [INFO]   |-- \u2705 Passed!\n</pre> <pre>[16:18:45] [INFO] \ud83c\udfb2 Preparing samplers to generate 2 records across 5 columns\n</pre> <pre>[16:18:45] [INFO] \ud83e\udde9 Generating column `customer_name` from expression\n</pre> <pre>[16:18:45] [INFO] \ud83e\udde9 Generating column `customer_age` from expression\n</pre> <pre>[16:18:45] [INFO] \ud83d\uddc2\ufe0f Preparing llm-structured column generation\n</pre> <pre>[16:18:45] [INFO]   |-- column name: 'product'\n</pre> <pre>[16:18:45] [INFO]   |-- model config:\n{\n    \"alias\": \"nemotron-nano-v2\",\n    \"model\": \"nvidia/nvidia-nemotron-nano-9b-v2\",\n    \"inference_parameters\": {\n        \"temperature\": 0.5,\n        \"top_p\": 1.0,\n        \"max_tokens\": 1024,\n        \"max_parallel_requests\": 4,\n        \"timeout\": null,\n        \"extra_body\": null\n    },\n    \"provider\": \"nvidia\"\n}\n</pre> <pre>[16:18:45] [INFO] \ud83d\udc19 Processing llm-structured column 'product' with 4 concurrent workers\n</pre> <pre>[16:18:46] [INFO] \ud83d\uddc2\ufe0f Preparing llm-structured column generation\n</pre> <pre>[16:18:46] [INFO]   |-- column name: 'customer_review'\n</pre> <pre>[16:18:46] [INFO]   |-- model config:\n{\n    \"alias\": \"nemotron-nano-v2\",\n    \"model\": \"nvidia/nvidia-nemotron-nano-9b-v2\",\n    \"inference_parameters\": {\n        \"temperature\": 0.5,\n        \"top_p\": 1.0,\n        \"max_tokens\": 1024,\n        \"max_parallel_requests\": 4,\n        \"timeout\": null,\n        \"extra_body\": null\n    },\n    \"provider\": \"nvidia\"\n}\n</pre> <pre>[16:18:46] [INFO] \ud83d\udc19 Processing llm-structured column 'customer_review' with 4 concurrent workers\n</pre> <pre>[16:18:48] [INFO] \ud83d\udcca Model usage summary:\n{\n    \"nvidia/nvidia-nemotron-nano-9b-v2\": {\n        \"token_usage\": {\n            \"prompt_tokens\": 1238,\n            \"completion_tokens\": 502,\n            \"total_tokens\": 1740\n        },\n        \"request_usage\": {\n            \"successful_requests\": 4,\n            \"failed_requests\": 0,\n            \"total_requests\": 4\n        },\n        \"tokens_per_second\": 512,\n        \"requests_per_minute\": 70\n    }\n}\n</pre> <pre>[16:18:48] [INFO] \ud83d\ude48 Dropping columns: ['customer']\n</pre> <pre>[16:18:48] [INFO] \ud83d\udcd0 Measuring dataset column statistics:\n</pre> <pre>[16:18:48] [INFO]   |-- \ud83c\udfb2 column: 'product_category'\n</pre> <pre>[16:18:48] [INFO]   |-- \ud83c\udfb2 column: 'product_subcategory'\n</pre> <pre>[16:18:48] [INFO]   |-- \ud83c\udfb2 column: 'target_age_range'\n</pre> <pre>[16:18:48] [INFO]   |-- \ud83c\udfb2 column: 'review_style'\n</pre> <pre>[16:18:48] [INFO]   |-- \ud83e\udde9 column: 'customer_name'\n</pre> <pre>[16:18:48] [INFO]   |-- \ud83e\udde9 column: 'customer_age'\n</pre> <pre>[16:18:48] [INFO]   |-- \ud83d\uddc2\ufe0f column: 'product'\n</pre> <pre>[16:18:48] [INFO]   |-- \ud83d\uddc2\ufe0f column: 'customer_review'\n</pre> <pre>[16:18:48] [INFO] \u2705 Preview complete!\n</pre> In\u00a0[9]: Copied! <pre># Run this cell multiple times to cycle through the 2 preview records.\npreview.display_sample_record()\n</pre> # Run this cell multiple times to cycle through the 2 preview records. preview.display_sample_record() <pre>                                                                                                                   \n                                                 Generated Columns                                                 \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Name                \u2503 Value                                                                                     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 product_category    \u2502 Home Office                                                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 product_subcategory \u2502 Storage                                                                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 target_age_range    \u2502 25-35                                                                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 review_style        \u2502 brief                                                                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer_name       \u2502 Angela Jacobs                                                                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer_age        \u2502 114                                                                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 product             \u2502 {                                                                                         \u2502\n\u2502                     \u2502     'name': 'Modular Wall-Mounted Shelving Unit',                                         \u2502\n\u2502                     \u2502     'description': 'A sleek and adjustable storage solution designed for home offices,    \u2502\n\u2502                     \u2502 featuring modular wall-mounted shelves made from durable bamboo. Ideal for organizing     \u2502\n\u2502                     \u2502 documents, supplies, and electronics, it offers customizable space to fit various needs.  \u2502\n\u2502                     \u2502 The minimalist design complements modern home office aesthetics.',                        \u2502\n\u2502                     \u2502     'price': 89.99                                                                        \u2502\n\u2502                     \u2502 }                                                                                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer_review     \u2502 {                                                                                         \u2502\n\u2502                     \u2502     'rating': 5,                                                                          \u2502\n\u2502                     \u2502     'customer_mood': 'happy',                                                             \u2502\n\u2502                     \u2502     'review': 'The Modular Wall-Mounted Shelving Unit is an excellent storage solution    \u2502\n\u2502                     \u2502 for home offices. Its durable bamboo construction and adjustable design provide           \u2502\n\u2502                     \u2502 customizable space for organizing documents, supplies, and electronics. The sleek,        \u2502\n\u2502                     \u2502 minimalist aesthetic complements modern decor, making it both functional and visually     \u2502\n\u2502                     \u2502 appealing. At $89.99, it offers great value for its quality and versatility.'             \u2502\n\u2502                     \u2502 }                                                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                    [index: 0]                                                     \n</pre> In\u00a0[10]: Copied! <pre># The preview dataset is available as a pandas DataFrame.\npreview.dataset\n</pre> # The preview dataset is available as a pandas DataFrame. preview.dataset Out[10]: product_category product_subcategory target_age_range review_style customer_name customer_age product customer_review 0 Home Office Storage 25-35 brief Angela Jacobs 114 {'name': 'Modular Wall-Mounted Shelving Unit',... {'rating': 5, 'customer_mood': 'happy', 'revie... 1 Home Office Chairs 25-35 detailed William Norton 80 {'name': 'ErgoPro Mesh Task Chair', 'descripti... {'rating': 5, 'customer_mood': 'happy', 'revie... In\u00a0[11]: Copied! <pre># Print the analysis as a table.\npreview.analysis.to_report()\n</pre> # Print the analysis as a table. preview.analysis.to_report() <pre>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83c\udfa8 Data Designer Dataset Profile \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n                                                                                                                   \n                                                 Dataset Overview                                                  \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 number of records               \u2503 number of columns               \u2503 percent complete records                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 2                               \u2502 8                               \u2502 100.0%                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                                \ud83c\udfb2 Sampler Columns                                                 \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 column name                      \u2503        data type \u2503               number unique values \u2503         sampler type \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 product_category                 \u2502           string \u2502                          1 (50.0%) \u2502             category \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 product_subcategory              \u2502           string \u2502                         2 (100.0%) \u2502          subcategory \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 target_age_range                 \u2502           string \u2502                          1 (50.0%) \u2502             category \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 review_style                     \u2502           string \u2502                         2 (100.0%) \u2502             category \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                             \ud83d\uddc2\ufe0f LLM-Structured Columns                                              \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503                       \u2503               \u2503                            \u2503     prompt tokens \u2503      completion tokens \u2503\n\u2503 column name           \u2503     data type \u2503       number unique values \u2503        per record \u2503             per record \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 product               \u2502          dict \u2502                 2 (100.0%) \u2502     267.5 +/- 0.5 \u2502          67.0 +/- 12.7 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer_review       \u2502          dict \u2502                 2 (100.0%) \u2502     310.5 +/- 8.5 \u2502         151.0 +/- 86.3 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                               \ud83e\udde9 Expression Columns                                               \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 column name                       \u2503                data type \u2503                             number unique values \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 customer_name                     \u2502                   string \u2502                                       2 (100.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer_age                      \u2502                   string \u2502                                       2 (100.0%) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Table Notes \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                                 \u2502\n\u2502  1. All token statistics are based on a sample of max(1000, len(dataset)) records.                              \u2502\n\u2502  2. Tokens are calculated using tiktoken's cl100k_base tokenizer.                                               \u2502\n\u2502                                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n                                                                                                                   \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</pre> In\u00a0[12]: Copied! <pre>job_results = data_designer_client.create(config_builder, num_records=10)\n</pre> job_results = data_designer_client.create(config_builder, num_records=10) <pre>[16:18:48] [INFO] \ud83c\udfa8 Creating Data Designer dataset\n</pre> <pre>[16:18:48] [INFO] \u2705 Validation passed\n</pre> <pre>[16:18:48] [INFO] \u26d3\ufe0f Sorting column configs into a Directed Acyclic Graph\n</pre> <pre>[16:18:48] [INFO] \ud83d\udcc2 Dataset path '/home/runner/work/DataDesigner/DataDesigner/docs/notebook_source/artifacts/dataset' already exists. Dataset from this session\n\t\t     will be saved to '/home/runner/work/DataDesigner/DataDesigner/docs/notebook_source/artifacts/dataset_12-08-2025_161848' instead.\n</pre> <pre>[16:18:48] [INFO] \ud83e\ude7a Running health checks for models...\n</pre> <pre>[16:18:48] [INFO]   |-- \ud83d\udc40 Checking 'nvidia/nvidia-nemotron-nano-9b-v2' in provider named 'nvidia' for model alias 'nemotron-nano-v2'...\n</pre> <pre>[16:18:49] [INFO]   |-- \u2705 Passed!\n</pre> <pre>[16:18:49] [INFO] \u23f3 Processing batch 1 of 1\n</pre> <pre>[16:18:49] [INFO] \ud83c\udfb2 Preparing samplers to generate 10 records across 5 columns\n</pre> <pre>[16:18:50] [INFO] \ud83e\udde9 Generating column `customer_name` from expression\n</pre> <pre>[16:18:50] [INFO] \ud83e\udde9 Generating column `customer_age` from expression\n</pre> <pre>[16:18:50] [INFO] \ud83d\uddc2\ufe0f Preparing llm-structured column generation\n</pre> <pre>[16:18:50] [INFO]   |-- column name: 'product'\n</pre> <pre>[16:18:50] [INFO]   |-- model config:\n{\n    \"alias\": \"nemotron-nano-v2\",\n    \"model\": \"nvidia/nvidia-nemotron-nano-9b-v2\",\n    \"inference_parameters\": {\n        \"temperature\": 0.5,\n        \"top_p\": 1.0,\n        \"max_tokens\": 1024,\n        \"max_parallel_requests\": 4,\n        \"timeout\": null,\n        \"extra_body\": null\n    },\n    \"provider\": \"nvidia\"\n}\n</pre> <pre>[16:18:50] [INFO] \ud83d\udc19 Processing llm-structured column 'product' with 4 concurrent workers\n</pre> <pre>[16:18:55] [INFO] \ud83d\uddc2\ufe0f Preparing llm-structured column generation\n</pre> <pre>[16:18:55] [INFO]   |-- column name: 'customer_review'\n</pre> <pre>[16:18:55] [INFO]   |-- model config:\n{\n    \"alias\": \"nemotron-nano-v2\",\n    \"model\": \"nvidia/nvidia-nemotron-nano-9b-v2\",\n    \"inference_parameters\": {\n        \"temperature\": 0.5,\n        \"top_p\": 1.0,\n        \"max_tokens\": 1024,\n        \"max_parallel_requests\": 4,\n        \"timeout\": null,\n        \"extra_body\": null\n    },\n    \"provider\": \"nvidia\"\n}\n</pre> <pre>[16:18:55] [INFO] \ud83d\udc19 Processing llm-structured column 'customer_review' with 4 concurrent workers\n</pre> <pre>[16:19:02] [INFO] \ud83d\ude48 Dropping columns: ['customer']\n</pre> <pre>[16:19:02] [INFO] \ud83d\udcca Model usage summary:\n{\n    \"nvidia/nvidia-nemotron-nano-9b-v2\": {\n        \"token_usage\": {\n            \"prompt_tokens\": 6290,\n            \"completion_tokens\": 3588,\n            \"total_tokens\": 9878\n        },\n        \"request_usage\": {\n            \"successful_requests\": 20,\n            \"failed_requests\": 0,\n            \"total_requests\": 20\n        },\n        \"tokens_per_second\": 760,\n        \"requests_per_minute\": 92\n    }\n}\n</pre> <pre>[16:19:02] [INFO] \ud83d\udcd0 Measuring dataset column statistics:\n</pre> <pre>[16:19:02] [INFO]   |-- \ud83c\udfb2 column: 'product_category'\n</pre> <pre>[16:19:02] [INFO]   |-- \ud83c\udfb2 column: 'product_subcategory'\n</pre> <pre>[16:19:03] [INFO]   |-- \ud83c\udfb2 column: 'target_age_range'\n</pre> <pre>[16:19:03] [INFO]   |-- \ud83c\udfb2 column: 'review_style'\n</pre> <pre>[16:19:03] [INFO]   |-- \ud83e\udde9 column: 'customer_name'\n</pre> <pre>[16:19:03] [INFO]   |-- \ud83e\udde9 column: 'customer_age'\n</pre> <pre>[16:19:03] [INFO]   |-- \ud83d\uddc2\ufe0f column: 'product'\n</pre> <pre>[16:19:03] [INFO]   |-- \ud83d\uddc2\ufe0f column: 'customer_review'\n</pre> In\u00a0[13]: Copied! <pre># Load the generated dataset as a pandas DataFrame.\ndataset = job_results.load_dataset()\n\ndataset.head()\n</pre> # Load the generated dataset as a pandas DataFrame. dataset = job_results.load_dataset()  dataset.head() Out[13]: product_category product_subcategory target_age_range review_style customer_name customer_age product customer_review 0 Home &amp; Kitchen Decor 18-25 rambling Andrea Beasley 19 {'description': 'A stylish set of three abstra... {'customer_mood': 'happy', 'rating': 4, 'revie... 1 Home &amp; Kitchen Cookware 25-35 detailed John Bowers 33 {'description': 'A 5-piece cookware set featur... {'customer_mood': 'happy', 'rating': 5, 'revie... 2 Books Fiction 25-35 brief Sherri Hurley 53 {'description': \"A captivating fantasy novel f... {'customer_mood': 'excited', 'rating': 5, 'rev... 3 Electronics Smartphones 18-25 rambling Michaela Williams 94 {'description': 'A sustainable smartphone with... {'customer_mood': 'happy', 'rating': 4, 'revie... 4 Electronics Laptops 25-35 rambling Megan Roach 83 {'description': 'A high-performance laptop des... {'customer_mood': 'happy', 'rating': 5, 'revie... In\u00a0[14]: Copied! <pre># Load the analysis results into memory.\nanalysis = job_results.load_analysis()\n\nanalysis.to_report()\n</pre> # Load the analysis results into memory. analysis = job_results.load_analysis()  analysis.to_report() <pre>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83c\udfa8 Data Designer Dataset Profile \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n                                                                                                                   \n                                                 Dataset Overview                                                  \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 number of records               \u2503 number of columns               \u2503 percent complete records                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 10                              \u2502 8                               \u2502 100.0%                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                                \ud83c\udfb2 Sampler Columns                                                 \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 column name                      \u2503        data type \u2503               number unique values \u2503         sampler type \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 product_category                 \u2502           string \u2502                          4 (40.0%) \u2502             category \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 product_subcategory              \u2502           string \u2502                          7 (70.0%) \u2502          subcategory \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 target_age_range                 \u2502           string \u2502                          4 (40.0%) \u2502             category \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 review_style                     \u2502           string \u2502                          4 (40.0%) \u2502             category \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                             \ud83d\uddc2\ufe0f LLM-Structured Columns                                              \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503                       \u2503               \u2503                            \u2503     prompt tokens \u2503      completion tokens \u2503\n\u2503 column name           \u2503     data type \u2503       number unique values \u2503        per record \u2503             per record \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 product               \u2502          dict \u2502                10 (100.0%) \u2502     268.0 +/- 0.5 \u2502           73.0 +/- 9.5 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer_review       \u2502          dict \u2502                10 (100.0%) \u2502     318.0 +/- 9.2 \u2502         287.5 +/- 98.2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                               \ud83e\udde9 Expression Columns                                               \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 column name                       \u2503                data type \u2503                             number unique values \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 customer_name                     \u2502                   string \u2502                                      10 (100.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer_age                      \u2502                   string \u2502                                      10 (100.0%) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Table Notes \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                                 \u2502\n\u2502  1. All token statistics are based on a sample of max(1000, len(dataset)) records.                              \u2502\n\u2502  2. Tokens are calculated using tiktoken's cl100k_base tokenizer.                                               \u2502\n\u2502                                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n                                                                                                                   \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</pre>"},{"location":"notebooks/2-structured-outputs-and-jinja-expressions/#data-designer-tutorial-structured-outputs-and-jinja-expressions","title":"\ud83c\udfa8 Data Designer Tutorial: Structured Outputs and Jinja Expressions\u00b6","text":""},{"location":"notebooks/2-structured-outputs-and-jinja-expressions/#what-youll-learn","title":"\ud83d\udcda What you'll learn\u00b6","text":"<p>In this notebook, we will continue our exploration of Data Designer, demonstrating more advanced data generation using structured outputs and Jinja expressions.</p> <p>If this is your first time using Data Designer, we recommend starting with the first notebook in this tutorial series.</p>"},{"location":"notebooks/2-structured-outputs-and-jinja-expressions/#import-the-essentials","title":"\ud83d\udce6 Import the essentials\u00b6","text":"<ul> <li>The <code>essentials</code> module provides quick access to the most commonly used objects.</li> </ul>"},{"location":"notebooks/2-structured-outputs-and-jinja-expressions/#initialize-the-data-designer-interface","title":"\u2699\ufe0f Initialize the Data Designer interface\u00b6","text":"<ul> <li><p><code>DataDesigner</code> is the main object that is used to interface with the library.</p> </li> <li><p>When initialized without arguments, the default model providers are used.</p> </li> </ul>"},{"location":"notebooks/2-structured-outputs-and-jinja-expressions/#define-model-configurations","title":"\ud83c\udf9b\ufe0f Define model configurations\u00b6","text":"<ul> <li><p>Each <code>ModelConfig</code> defines a model that can be used during the generation process.</p> </li> <li><p>The \"model alias\" is used to reference the model in the Data Designer config (as we will see below).</p> </li> <li><p>The \"model provider\" is the external service that hosts the model (see the model config docs for more details).</p> </li> <li><p>By default, we use build.nvidia.com as the model provider.</p> </li> </ul>"},{"location":"notebooks/2-structured-outputs-and-jinja-expressions/#initialize-the-data-designer-config-builder","title":"\ud83c\udfd7\ufe0f Initialize the Data Designer Config Builder\u00b6","text":"<ul> <li><p>The Data Designer config defines the dataset schema and generation process.</p> </li> <li><p>The config builder provides an intuitive interface for building this configuration.</p> </li> <li><p>The list of model configs is provided to the builder at initialization.</p> </li> </ul>"},{"location":"notebooks/2-structured-outputs-and-jinja-expressions/#designing-our-data","title":"\ud83e\uddd1\u200d\ud83c\udfa8 Designing our data\u00b6","text":"<ul> <li><p>We will again create a product review dataset, but this time we will use structured outputs and Jinja expressions.</p> </li> <li><p>Structured outputs let you specify the exact schema of the data you want to generate.</p> </li> <li><p>Data Designer supports schemas specified using either json schema or Pydantic data models (recommended).</p> </li> </ul> <p>We'll define our structured outputs using Pydantic data models</p> <p>\ud83d\udca1 Why Pydantic?</p> <ul> <li><p>Pydantic models provide better IDE support and type validation.</p> </li> <li><p>They are more Pythonic than raw JSON schemas.</p> </li> <li><p>They integrate seamlessly with Data Designer's structured output system.</p> </li> </ul>"},{"location":"notebooks/2-structured-outputs-and-jinja-expressions/#iteration-is-key-preview-the-dataset","title":"\ud83d\udd01 Iteration is key \u2013\u00a0preview the dataset!\u00b6","text":"<ol> <li><p>Use the <code>preview</code> method to generate a sample of records quickly.</p> </li> <li><p>Inspect the results for quality and format issues.</p> </li> <li><p>Adjust column configurations, prompts, or parameters as needed.</p> </li> <li><p>Re-run the preview until satisfied.</p> </li> </ol>"},{"location":"notebooks/2-structured-outputs-and-jinja-expressions/#analyze-the-generated-data","title":"\ud83d\udcca Analyze the generated data\u00b6","text":"<ul> <li><p>Data Designer automatically generates a basic statistical analysis of the generated data.</p> </li> <li><p>This analysis is available via the <code>analysis</code> property of generation result objects.</p> </li> </ul>"},{"location":"notebooks/2-structured-outputs-and-jinja-expressions/#scale-up","title":"\ud83c\udd99 Scale up!\u00b6","text":"<ul> <li><p>Happy with your preview data?</p> </li> <li><p>Use the <code>create</code> method to submit larger Data Designer generation jobs.</p> </li> </ul>"},{"location":"notebooks/2-structured-outputs-and-jinja-expressions/#next-steps","title":"\u23ed\ufe0f Next Steps\u00b6","text":"<p>Check out the following notebook to learn more about:</p> <ul> <li>Seeding synthetic data generation with an external dataset</li> </ul>"},{"location":"notebooks/3-seeding-with-a-dataset/","title":"Seeding with an External Dataset","text":"In\u00a0[1]: Copied! <pre>from data_designer.essentials import (\n    DataDesigner,\n    DataDesignerConfigBuilder,\n    InferenceParameters,\n    ModelConfig,\n    SeedConfig,\n)\n</pre> from data_designer.essentials import (     DataDesigner,     DataDesignerConfigBuilder,     InferenceParameters,     ModelConfig,     SeedConfig, ) In\u00a0[2]: Copied! <pre>data_designer_client = DataDesigner()\n</pre> data_designer_client = DataDesigner() In\u00a0[3]: Copied! <pre># This name is set in the model provider configuration.\nMODEL_PROVIDER = \"nvidia\"\n\n# The model ID is from build.nvidia.com.\nMODEL_ID = \"nvidia/nvidia-nemotron-nano-9b-v2\"\n\n# We choose this alias to be descriptive for our use case.\nMODEL_ALIAS = \"nemotron-nano-v2\"\n\n# This sets reasoning to False for the nemotron-nano-v2 model.\nSYSTEM_PROMPT = \"/no_think\"\n\nmodel_configs = [\n    ModelConfig(\n        alias=MODEL_ALIAS,\n        model=MODEL_ID,\n        provider=MODEL_PROVIDER,\n        inference_parameters=InferenceParameters(\n            temperature=0.5,\n            top_p=1.0,\n            max_tokens=1024,\n        ),\n    )\n]\n</pre> # This name is set in the model provider configuration. MODEL_PROVIDER = \"nvidia\"  # The model ID is from build.nvidia.com. MODEL_ID = \"nvidia/nvidia-nemotron-nano-9b-v2\"  # We choose this alias to be descriptive for our use case. MODEL_ALIAS = \"nemotron-nano-v2\"  # This sets reasoning to False for the nemotron-nano-v2 model. SYSTEM_PROMPT = \"/no_think\"  model_configs = [     ModelConfig(         alias=MODEL_ALIAS,         model=MODEL_ID,         provider=MODEL_PROVIDER,         inference_parameters=InferenceParameters(             temperature=0.5,             top_p=1.0,             max_tokens=1024,         ),     ) ] In\u00a0[4]: Copied! <pre>config_builder = DataDesignerConfigBuilder(model_configs=model_configs)\n</pre> config_builder = DataDesignerConfigBuilder(model_configs=model_configs) In\u00a0[5]: Copied! <pre># Download sample dataset from Github\nimport urllib.request\n\nurl = \"https://raw.githubusercontent.com/NVIDIA/GenerativeAIExamples/refs/heads/main/nemo/NeMo-Data-Designer/data/gretelai_symptom_to_diagnosis.csv\"\nlocal_filename, headers = urllib.request.urlretrieve(url, \"gretelai_symptom_to_diagnosis.csv\")\n\nseed_dataset = SeedConfig(dataset=local_filename)\n\n# Pass the reference to the config builder for use during generation.\nconfig_builder.with_seed_dataset(seed_dataset)\n</pre> # Download sample dataset from Github import urllib.request  url = \"https://raw.githubusercontent.com/NVIDIA/GenerativeAIExamples/refs/heads/main/nemo/NeMo-Data-Designer/data/gretelai_symptom_to_diagnosis.csv\" local_filename, headers = urllib.request.urlretrieve(url, \"gretelai_symptom_to_diagnosis.csv\")  seed_dataset = SeedConfig(dataset=local_filename)  # Pass the reference to the config builder for use during generation. config_builder.with_seed_dataset(seed_dataset) Out[5]: <pre>DataDesignerConfigBuilder(\n    seed_dataset: 'gretelai_symptom_to_diagnosis.csv'\n    seed_dataset_columns: ['diagnosis', 'patient_summary']\n)\n</pre> In\u00a0[6]: Copied! <pre>config_builder.add_column(\n    name=\"patient_sampler\",\n    column_type=\"sampler\",\n    sampler_type=\"person_from_faker\",\n)\n\nconfig_builder.add_column(\n    name=\"doctor_sampler\",\n    column_type=\"sampler\",\n    sampler_type=\"person_from_faker\",\n)\n\nconfig_builder.add_column(\n    name=\"patient_id\",\n    column_type=\"sampler\",\n    sampler_type=\"uuid\",\n    params={\n        \"prefix\": \"PT-\",\n        \"short_form\": True,\n        \"uppercase\": True,\n    },\n)\n\nconfig_builder.add_column(\n    name=\"first_name\",\n    column_type=\"expression\",\n    expr=\"{{ patient_sampler.first_name}}\",\n)\n\nconfig_builder.add_column(\n    name=\"last_name\",\n    column_type=\"expression\",\n    expr=\"{{ patient_sampler.last_name }}\",\n)\n\n\nconfig_builder.add_column(\n    name=\"dob\",\n    column_type=\"expression\",\n    expr=\"{{ patient_sampler.birth_date }}\",\n)\n\nconfig_builder.add_column(\n    name=\"symptom_onset_date\",\n    column_type=\"sampler\",\n    sampler_type=\"datetime\",\n    params={\"start\": \"2024-01-01\", \"end\": \"2024-12-31\"},\n)\n\nconfig_builder.add_column(\n    name=\"date_of_visit\",\n    column_type=\"sampler\",\n    sampler_type=\"timedelta\",\n    params={\"dt_min\": 1, \"dt_max\": 30, \"reference_column_name\": \"symptom_onset_date\"},\n)\n\nconfig_builder.add_column(\n    name=\"physician\",\n    column_type=\"expression\",\n    expr=\"Dr. {{ doctor_sampler.last_name }}\",\n)\n\nconfig_builder.add_column(\n    name=\"physician_notes\",\n    column_type=\"llm-text\",\n    prompt=\"\"\"\\\nYou are a primary-care physician who just had an appointment with {{ first_name }} {{ last_name }},\nwho has been struggling with symptoms from {{ diagnosis }} since {{ symptom_onset_date }}.\nThe date of today's visit is {{ date_of_visit }}.\n\n{{ patient_summary }}\n\nWrite careful notes about your visit with {{ first_name }},\nas Dr. {{ doctor_sampler.first_name }} {{ doctor_sampler.last_name }}.\n\nFormat the notes as a busy doctor might.\n\"\"\",\n    model_alias=MODEL_ALIAS,\n    system_prompt=SYSTEM_PROMPT,\n)\n\nconfig_builder.validate()\n</pre> config_builder.add_column(     name=\"patient_sampler\",     column_type=\"sampler\",     sampler_type=\"person_from_faker\", )  config_builder.add_column(     name=\"doctor_sampler\",     column_type=\"sampler\",     sampler_type=\"person_from_faker\", )  config_builder.add_column(     name=\"patient_id\",     column_type=\"sampler\",     sampler_type=\"uuid\",     params={         \"prefix\": \"PT-\",         \"short_form\": True,         \"uppercase\": True,     }, )  config_builder.add_column(     name=\"first_name\",     column_type=\"expression\",     expr=\"{{ patient_sampler.first_name}}\", )  config_builder.add_column(     name=\"last_name\",     column_type=\"expression\",     expr=\"{{ patient_sampler.last_name }}\", )   config_builder.add_column(     name=\"dob\",     column_type=\"expression\",     expr=\"{{ patient_sampler.birth_date }}\", )  config_builder.add_column(     name=\"symptom_onset_date\",     column_type=\"sampler\",     sampler_type=\"datetime\",     params={\"start\": \"2024-01-01\", \"end\": \"2024-12-31\"}, )  config_builder.add_column(     name=\"date_of_visit\",     column_type=\"sampler\",     sampler_type=\"timedelta\",     params={\"dt_min\": 1, \"dt_max\": 30, \"reference_column_name\": \"symptom_onset_date\"}, )  config_builder.add_column(     name=\"physician\",     column_type=\"expression\",     expr=\"Dr. {{ doctor_sampler.last_name }}\", )  config_builder.add_column(     name=\"physician_notes\",     column_type=\"llm-text\",     prompt=\"\"\"\\ You are a primary-care physician who just had an appointment with {{ first_name }} {{ last_name }}, who has been struggling with symptoms from {{ diagnosis }} since {{ symptom_onset_date }}. The date of today's visit is {{ date_of_visit }}.  {{ patient_summary }}  Write careful notes about your visit with {{ first_name }}, as Dr. {{ doctor_sampler.first_name }} {{ doctor_sampler.last_name }}.  Format the notes as a busy doctor might. \"\"\",     model_alias=MODEL_ALIAS,     system_prompt=SYSTEM_PROMPT, )  config_builder.validate() <pre>[16:19:09] [INFO] \u2705 Validation passed\n</pre> Out[6]: <pre>DataDesignerConfigBuilder(\n    seed_dataset: 'gretelai_symptom_to_diagnosis.csv'\n    seed_dataset_columns: ['diagnosis', 'patient_summary']\n    sampler_columns: [\n        \"patient_sampler\",\n        \"doctor_sampler\",\n        \"patient_id\",\n        \"symptom_onset_date\",\n        \"date_of_visit\"\n    ]\n    llm_text_columns: ['physician_notes']\n    expression_columns: [\n        \"first_name\",\n        \"last_name\",\n        \"dob\",\n        \"physician\"\n    ]\n)\n</pre> In\u00a0[7]: Copied! <pre>preview = data_designer_client.preview(config_builder, num_records=2)\n</pre> preview = data_designer_client.preview(config_builder, num_records=2) <pre>[16:19:09] [INFO] \ud83d\udcf8 Preview generation in progress\n</pre> <pre>[16:19:09] [INFO] \u2705 Validation passed\n</pre> <pre>[16:19:09] [INFO] \u26d3\ufe0f Sorting column configs into a Directed Acyclic Graph\n</pre> <pre>[16:19:09] [INFO] \ud83e\ude7a Running health checks for models...\n</pre> <pre>[16:19:09] [INFO]   |-- \ud83d\udc40 Checking 'nvidia/nvidia-nemotron-nano-9b-v2' in provider named 'nvidia' for model alias 'nemotron-nano-v2'...\n</pre> <pre>[16:19:10] [INFO]   |-- \u2705 Passed!\n</pre> <pre>[16:19:10] [INFO] \ud83c\udf31 Sampling 2 records from seed dataset\n</pre> <pre>[16:19:10] [INFO]   |-- seed dataset size: 820 records\n</pre> <pre>[16:19:10] [INFO]   |-- sampling strategy: ordered\n</pre> <pre>[16:19:10] [INFO] \ud83c\udfb2 Preparing samplers to generate 2 records across 5 columns\n</pre> <pre>[16:19:10] [INFO] (\ud83d\udcbe + \ud83d\udcbe) Concatenating 2 datasets\n</pre> <pre>[16:19:10] [INFO] \ud83e\udde9 Generating column `first_name` from expression\n</pre> <pre>[16:19:10] [INFO] \ud83e\udde9 Generating column `last_name` from expression\n</pre> <pre>[16:19:10] [INFO] \ud83e\udde9 Generating column `dob` from expression\n</pre> <pre>[16:19:10] [INFO] \ud83e\udde9 Generating column `physician` from expression\n</pre> <pre>[16:19:10] [INFO] \ud83d\udcdd Preparing llm-text column generation\n</pre> <pre>[16:19:10] [INFO]   |-- column name: 'physician_notes'\n</pre> <pre>[16:19:10] [INFO]   |-- model config:\n{\n    \"alias\": \"nemotron-nano-v2\",\n    \"model\": \"nvidia/nvidia-nemotron-nano-9b-v2\",\n    \"inference_parameters\": {\n        \"temperature\": 0.5,\n        \"top_p\": 1.0,\n        \"max_tokens\": 1024,\n        \"max_parallel_requests\": 4,\n        \"timeout\": null,\n        \"extra_body\": null\n    },\n    \"provider\": \"nvidia\"\n}\n</pre> <pre>[16:19:10] [INFO] \ud83d\udc19 Processing llm-text column 'physician_notes' with 4 concurrent workers\n</pre> <pre>[16:19:19] [INFO] \ud83d\udcca Model usage summary:\n{\n    \"nvidia/nvidia-nemotron-nano-9b-v2\": {\n        \"token_usage\": {\n            \"prompt_tokens\": 268,\n            \"completion_tokens\": 1608,\n            \"total_tokens\": 1876\n        },\n        \"request_usage\": {\n            \"successful_requests\": 2,\n            \"failed_requests\": 0,\n            \"total_requests\": 2\n        },\n        \"tokens_per_second\": 215,\n        \"requests_per_minute\": 13\n    }\n}\n</pre> <pre>[16:19:19] [INFO] \ud83d\udcd0 Measuring dataset column statistics:\n</pre> <pre>[16:19:19] [INFO]   |-- \ud83c\udf31 column: 'diagnosis'\n</pre> <pre>[16:19:19] [INFO]   |-- \ud83c\udf31 column: 'patient_summary'\n</pre> <pre>[16:19:19] [INFO]   |-- \ud83c\udfb2 column: 'patient_sampler'\n</pre> <pre>[16:19:19] [INFO]   |-- \ud83c\udfb2 column: 'doctor_sampler'\n</pre> <pre>[16:19:19] [INFO]   |-- \ud83c\udfb2 column: 'patient_id'\n</pre> <pre>[16:19:19] [INFO]   |-- \ud83e\udde9 column: 'first_name'\n</pre> <pre>[16:19:19] [INFO]   |-- \ud83e\udde9 column: 'last_name'\n</pre> <pre>[16:19:19] [INFO]   |-- \ud83e\udde9 column: 'dob'\n</pre> <pre>[16:19:19] [INFO]   |-- \ud83c\udfb2 column: 'symptom_onset_date'\n</pre> <pre>[16:19:19] [INFO]   |-- \ud83c\udfb2 column: 'date_of_visit'\n</pre> <pre>[16:19:19] [INFO]   |-- \ud83e\udde9 column: 'physician'\n</pre> <pre>[16:19:19] [INFO]   |-- \ud83d\udcdd column: 'physician_notes'\n</pre> <pre>[16:19:19] [INFO] \u2600\ufe0f Preview complete!\n</pre> In\u00a0[8]: Copied! <pre># Run this cell multiple times to cycle through the 2 preview records.\npreview.display_sample_record()\n</pre> # Run this cell multiple times to cycle through the 2 preview records. preview.display_sample_record() <pre>                                                                                                                   \n                                                   Seed Columns                                                    \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Name            \u2503 Value                                                                                         \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 diagnosis       \u2502 cervical spondylosis                                                                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 patient_summary \u2502 I've been having a lot of pain in my neck and back. I've also been having trouble with my     \u2502\n\u2502                 \u2502 balance and coordination. I've been coughing a lot and my limbs feel weak.                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                                 Generated Columns                                                 \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Name               \u2503 Value                                                                                      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 patient_sampler    \u2502 {                                                                                          \u2502\n\u2502                    \u2502     'uuid': '9eec05f5-4029-4feb-82d8-192842ee8f6f',                                        \u2502\n\u2502                    \u2502     'locale': 'en_US',                                                                     \u2502\n\u2502                    \u2502     'first_name': 'Jeffrey',                                                               \u2502\n\u2502                    \u2502     'last_name': 'Garza',                                                                  \u2502\n\u2502                    \u2502     'middle_name': None,                                                                   \u2502\n\u2502                    \u2502     'sex': 'Male',                                                                         \u2502\n\u2502                    \u2502     'street_number': '27643',                                                              \u2502\n\u2502                    \u2502     'street_name': 'Jordan Turnpike',                                                      \u2502\n\u2502                    \u2502     'city': 'East Willie',                                                                 \u2502\n\u2502                    \u2502     'state': 'Texas',                                                                      \u2502\n\u2502                    \u2502     'postcode': '91318',                                                                   \u2502\n\u2502                    \u2502     'age': 98,                                                                             \u2502\n\u2502                    \u2502     'birth_date': '1927-06-07',                                                            \u2502\n\u2502                    \u2502     'country': 'Greece',                                                                   \u2502\n\u2502                    \u2502     'marital_status': 'separated',                                                         \u2502\n\u2502                    \u2502     'education_level': 'secondary_education',                                              \u2502\n\u2502                    \u2502     'unit': '',                                                                            \u2502\n\u2502                    \u2502     'occupation': 'Interior and spatial designer',                                         \u2502\n\u2502                    \u2502     'phone_number': '2078159446',                                                          \u2502\n\u2502                    \u2502     'bachelors_field': 'no_degree'                                                         \u2502\n\u2502                    \u2502 }                                                                                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 doctor_sampler     \u2502 {                                                                                          \u2502\n\u2502                    \u2502     'uuid': '3ce248b0-7b3f-479f-be2a-d43b0cb683c6',                                        \u2502\n\u2502                    \u2502     'locale': 'en_US',                                                                     \u2502\n\u2502                    \u2502     'first_name': 'Jason',                                                                 \u2502\n\u2502                    \u2502     'last_name': 'Mccann',                                                                 \u2502\n\u2502                    \u2502     'middle_name': None,                                                                   \u2502\n\u2502                    \u2502     'sex': 'Male',                                                                         \u2502\n\u2502                    \u2502     'street_number': '175',                                                                \u2502\n\u2502                    \u2502     'street_name': 'Ann Pines',                                                            \u2502\n\u2502                    \u2502     'city': 'Lake Mary',                                                                   \u2502\n\u2502                    \u2502     'state': 'New Mexico',                                                                 \u2502\n\u2502                    \u2502     'postcode': '80050',                                                                   \u2502\n\u2502                    \u2502     'age': 55,                                                                             \u2502\n\u2502                    \u2502     'birth_date': '1970-06-20',                                                            \u2502\n\u2502                    \u2502     'country': 'Hong Kong',                                                                \u2502\n\u2502                    \u2502     'marital_status': 'separated',                                                         \u2502\n\u2502                    \u2502     'education_level': 'graduate',                                                         \u2502\n\u2502                    \u2502     'unit': '',                                                                            \u2502\n\u2502                    \u2502     'occupation': 'Location manager',                                                      \u2502\n\u2502                    \u2502     'phone_number': '518.470.7318',                                                        \u2502\n\u2502                    \u2502     'bachelors_field': 'business'                                                          \u2502\n\u2502                    \u2502 }                                                                                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 patient_id         \u2502 PT-36A639FD                                                                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 symptom_onset_date \u2502 2024-12-06                                                                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 date_of_visit      \u2502 2024-12-29                                                                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 first_name         \u2502 Jeffrey                                                                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 last_name          \u2502 Garza                                                                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dob                \u2502 1927-06-07                                                                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 physician          \u2502 Dr. Mccann                                                                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 physician_notes    \u2502 **Dr. Jason McCann, Primary Care Physician**                                               \u2502\n\u2502                    \u2502 **Patient: Jeffrey Garza**                                                                 \u2502\n\u2502                    \u2502 **Date of Visit: 2024-12-29**                                                              \u2502\n\u2502                    \u2502 **Chief Complaint:** Chronic neck/back pain, balance/coordination issues, persistent       \u2502\n\u2502                    \u2502 cough, and limb weakness since 2024-12-06.                                                 \u2502\n\u2502                    \u2502                                                                                            \u2502\n\u2502                    \u2502 **History of Present Illness (HPI):**                                                      \u2502\n\u2502                    \u2502 Jeffrey reports ongoing cervical spondylosis symptoms since December 6, 2024. He describes \u2502\n\u2502                    \u2502 progressively worsening neck and back pain, localized to the cervical and lumbar regions,  \u2502\n\u2502                    \u2502 exacerbated by movement or prolonged sitting. He denies trauma but notes worsening pain    \u2502\n\u2502                    \u2502 over time.                                                                                 \u2502\n\u2502                    \u2502                                                                                            \u2502\n\u2502                    \u2502 He also reports new-onset or exacerbated balance and coordination difficulties,            \u2502\n\u2502                    \u2502 particularly when walking or turning. This has led to occasional falls at home.            \u2502\n\u2502                    \u2502                                                                                            \u2502\n\u2502                    \u2502 Jeffrey endorses a persistent, non-productive cough, occurring multiple times daily, which \u2502\n\u2502                    \u2502 he describes as \u201cdry\u201d and worse in the morning. He denies fever, chest pain, or shortness  \u2502\n\u2502                    \u2502 of breath.                                                                                 \u2502\n\u2502                    \u2502                                                                                            \u2502\n\u2502                    \u2502 He reports bilateral limb weakness, most noticeable in his arms and legs, affecting his    \u2502\n\u2502                    \u2502 ability to grip objects and walk steadily. The weakness is not positional but constant.    \u2502\n\u2502                    \u2502                                                                                            \u2502\n\u2502                    \u2502 **Past Medical History (PMHx):**                                                           \u2502\n\u2502                    \u2502 - No significant prior medical history noted.                                              \u2502\n\u2502                    \u2502 - No history of neurological disorders, autoimmune diseases, or cancer.                    \u2502\n\u2502                    \u2502 - No prior surgeries or hospitalizations.                                                  \u2502\n\u2502                    \u2502                                                                                            \u2502\n\u2502                    \u2502 **Medications:**                                                                           \u2502\n\u2502                    \u2502 - Currently taking over-the-counter ibuprofen 400 mg PRN for pain.                         \u2502\n\u2502                    \u2502 - No prescribed medications.                                                               \u2502\n\u2502                    \u2502                                                                                            \u2502\n\u2502                    \u2502 **Allergies:**                                                                             \u2502\n\u2502                    \u2502 - No known drug or environmental allergies.                                                \u2502\n\u2502                    \u2502                                                                                            \u2502\n\u2502                    \u2502 **Social History:**                                                                        \u2502\n\u2502                    \u2502 - Jeffrey is employed as a warehouse worker, which involves repetitive lifting and         \u2502\n\u2502                    \u2502 standing. He denies smoking or alcohol use.                                                \u2502\n\u2502                    \u2502 - Reports stress related to work and symptoms.                                             \u2502\n\u2502                    \u2502                                                                                            \u2502\n\u2502                    \u2502 **Family History (FHx):**                                                                  \u2502\n\u2502                    \u2502 - No known family history of neurological disease, spinal disorders, or autoimmune         \u2502\n\u2502                    \u2502 conditions.                                                                                \u2502\n\u2502                    \u2502                                                                                            \u2502\n\u2502                    \u2502 **Review of Systems (ROS):**                                                               \u2502\n\u2502                    \u2502 - **Constitutional:** No fever, chills, or weight loss.                                    \u2502\n\u2502                    \u2502 - **Musculoskeletal:** Neck/back pain, bilateral limb weakness.                            \u2502\n\u2502                    \u2502 - **Neurological:** Balance/coordination deficits, sensory changes? (denies                \u2502\n\u2502                    \u2502 numbness/tingling).                                                                        \u2502\n\u2502                    \u2502 - **Respiratory:** Persistent cough, no dyspnea or hemoptysis.                             \u2502\n\u2502                    \u2502 - **Other systems:** Negative for GI, cardiovascular, or genitourinary symptoms.           \u2502\n\u2502                    \u2502                                                                                            \u2502\n\u2502                    \u2502 **Physical Examination:**                                                                  \u2502\n\u2502                    \u2502 - **Vital Signs:** Temp 98.6\u00b0F, HR 78, BP 128/80, RR 16, SpO2 98% on room air.             \u2502\n\u2502                    \u2502 - **Neck exam:** Full range of motion without tenderness. Mild crepitus noted with         \u2502\n\u2502                    \u2502 cervical flexion/extension. No focal neurological deficits on passive testing.             \u2502\n\u2502                    \u2502 - **Spine:** Lumbar spine tenderness with palpation. No radicular pain or motor deficits   \u2502\n\u2502                    \u2502 noted.                                                                                     \u2502\n\u2502                    \u2502 - **Neurological:** cerebellar ataxia noted on tandem gait. Proximal and distal muscle     \u2502\n\u2502                    \u2502 strength 4/5 in upper and lower extremities. No reflex abnormalities.                      \u2502\n\u2502                    \u2502 - **Respiratory:** Clear breath sounds bilaterally. No wheezing or crackles.               \u2502\n\u2502                    \u2502                                                                                            \u2502\n\u2502                    \u2502 **Assessment:**                                                                            \u2502\n\u2502                    \u2502 1. **Cervical spondylosis with mechanical neck/back pain** \u2013 likely contributing to        \u2502\n\u2502                    \u2502 functional limitations.                                                                    \u2502\n\u2502                    \u2502 2. **Cervical radiculopathy or myelopathy** \u2013 possible given balance/coordination issues   \u2502\n\u2502                    \u2502 and limb weakness (requires further neuroimaging).                                         \u2502\n\u2502                    \u2502 3. **Persistent cough** \u2013 etiology unclear; could be related to post-viral irritation,     \u2502\n\u2502                    \u2502 GERD, or early respiratory pathology.                                                      \u2502\n\u2502                    \u2502 4. **Bilateral limb weakness** \u2013 concerning for central or peripheral neuropathy; needs    \u2502\n\u2502                    \u2502 further evaluation.                                                                        \u2502\n\u2502                    \u2502                                                                                            \u2502\n\u2502                    \u2502 **Plan:**                                                                                  \u2502\n\u2502                    \u2502 1. **Order imaging:** MRI of cervical and lumbar spine to evaluate for disc herniation,    \u2502\n\u2502                    \u2502 stenosis, or cord compression.                                                             \u2502\n\u2502                    \u2502 2. **Neurology referral:** For further assessment of weakness, coordination deficits, and  \u2502\n\u2502                    \u2502 possible EMG/NCS.                                                                          \u2502\n\u2502                    \u2502 3. **Pulmonary workup:** Chest X-ray and possibly sputum culture to investigate cough.     \u2502\n\u2502                    \u2502 4. **Physical therapy:** To address pain, improve mobility, and strengthen core/neck       \u2502\n\u2502                    \u2502 stabilizers.                                                                               \u2502\n\u2502                    \u2502 5. **NSAID continuation:** Ibuprofen PRN for pain management.                              \u2502\n\u2502                    \u2502 6. **Patient education:** Advise on activity modification, ergonomics, and avoiding heavy  \u2502\n\u2502                    \u2502 lifting.                                                                                   \u2502\n\u2502                    \u2502 7. **Follow-up:** Scheduled in 2 weeks or sooner if symptoms worsen.                       \u2502\n\u2502                    \u2502                                                                                            \u2502\n\u2502                    \u2502 **Note to Self:**                                                                          \u2502\n\u2502                    \u2502 Jeffrey\u2019s symptoms are progressive and multifaceted. The combination of neurological       \u2502\n\u2502                    \u2502 deficits with respiratory symptoms warrants a multidisciplinary approach. Ensure timely    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                    [index: 0]                                                     \n</pre> In\u00a0[9]: Copied! <pre># The preview dataset is available as a pandas DataFrame.\npreview.dataset\n</pre> # The preview dataset is available as a pandas DataFrame. preview.dataset Out[9]: diagnosis patient_summary patient_sampler doctor_sampler patient_id symptom_onset_date date_of_visit first_name last_name dob physician physician_notes 0 cervical spondylosis I've been having a lot of pain in my neck and ... {'uuid': '9eec05f5-4029-4feb-82d8-192842ee8f6f... {'uuid': '3ce248b0-7b3f-479f-be2a-d43b0cb683c6... PT-36A639FD 2024-12-06 2024-12-29 Jeffrey Garza 1927-06-07 Dr. Mccann **Dr. Jason McCann, Primary Care Physician**  ... 1 impetigo I have a rash on my face that is getting worse... {'uuid': '3dadc66a-921a-449e-a106-39bdf10e20cf... {'uuid': '7086576a-02b5-4325-8adf-6dc52873e55f... PT-12782A9D 2024-03-21 2024-04-08 Christopher Porter 1932-11-30 Dr. Navarro **Dr. Bradley Navarro**  \\n**Primary Care Phys... In\u00a0[10]: Copied! <pre># Print the analysis as a table.\npreview.analysis.to_report()\n</pre> # Print the analysis as a table. preview.analysis.to_report() <pre>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83c\udfa8 Data Designer Dataset Profile \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n                                                                                                                   \n                                                 Dataset Overview                                                  \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 number of records               \u2503 number of columns               \u2503 percent complete records                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 2                               \u2502 12                              \u2502 100.0%                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                              \ud83c\udf31 Seed-Dataset Columns                                              \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 column name                          \u2503               data type \u2503                           number unique values \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 diagnosis                            \u2502                  string \u2502                                     2 (100.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 patient_summary                      \u2502                  string \u2502                                     2 (100.0%) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                                \ud83c\udfb2 Sampler Columns                                                 \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 column name                   \u2503       data type \u2503             number unique values \u2503               sampler type \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 patient_sampler               \u2502            dict \u2502                       2 (100.0%) \u2502          person_from_faker \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 doctor_sampler                \u2502            dict \u2502                       2 (100.0%) \u2502          person_from_faker \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 patient_id                    \u2502          string \u2502                       2 (100.0%) \u2502                       uuid \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 symptom_onset_date            \u2502          string \u2502                       2 (100.0%) \u2502                   datetime \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 date_of_visit                 \u2502          string \u2502                       2 (100.0%) \u2502                  timedelta \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                                \ud83d\udcdd LLM-Text Columns                                                \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503                       \u2503               \u2503                            \u2503     prompt tokens \u2503      completion tokens \u2503\n\u2503 column name           \u2503     data type \u2503       number unique values \u2503        per record \u2503             per record \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 physician_notes       \u2502        string \u2502                 2 (100.0%) \u2502     117.0 +/- 5.0 \u2502        754.0 +/- 309.7 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                               \ud83e\udde9 Expression Columns                                               \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 column name                    \u2503                 data type \u2503                               number unique values \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 first_name                     \u2502                    string \u2502                                         2 (100.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 last_name                      \u2502                    string \u2502                                         2 (100.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dob                            \u2502                    string \u2502                                         2 (100.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 physician                      \u2502                    string \u2502                                         2 (100.0%) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Table Notes \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                                 \u2502\n\u2502  1. All token statistics are based on a sample of max(1000, len(dataset)) records.                              \u2502\n\u2502  2. Tokens are calculated using tiktoken's cl100k_base tokenizer.                                               \u2502\n\u2502                                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n                                                                                                                   \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</pre> In\u00a0[11]: Copied! <pre>job_results = data_designer_client.create(config_builder, num_records=10)\n</pre> job_results = data_designer_client.create(config_builder, num_records=10) <pre>[16:19:19] [INFO] \ud83c\udfa8 Creating Data Designer dataset\n</pre> <pre>[16:19:19] [INFO] \u2705 Validation passed\n</pre> <pre>[16:19:19] [INFO] \u26d3\ufe0f Sorting column configs into a Directed Acyclic Graph\n</pre> <pre>[16:19:19] [INFO] \ud83d\udcc2 Dataset path '/home/runner/work/DataDesigner/DataDesigner/docs/notebook_source/artifacts/dataset' already exists. Dataset from this session\n\t\t     will be saved to '/home/runner/work/DataDesigner/DataDesigner/docs/notebook_source/artifacts/dataset_12-08-2025_161919' instead.\n</pre> <pre>[16:19:19] [INFO] \ud83e\ude7a Running health checks for models...\n</pre> <pre>[16:19:19] [INFO]   |-- \ud83d\udc40 Checking 'nvidia/nvidia-nemotron-nano-9b-v2' in provider named 'nvidia' for model alias 'nemotron-nano-v2'...\n</pre> <pre>[16:19:20] [INFO]   |-- \u2705 Passed!\n</pre> <pre>[16:19:20] [INFO] \u23f3 Processing batch 1 of 1\n</pre> <pre>[16:19:20] [INFO] \ud83c\udf31 Sampling 10 records from seed dataset\n</pre> <pre>[16:19:20] [INFO]   |-- seed dataset size: 820 records\n</pre> <pre>[16:19:20] [INFO]   |-- sampling strategy: ordered\n</pre> <pre>[16:19:20] [INFO] \ud83c\udfb2 Preparing samplers to generate 10 records across 5 columns\n</pre> <pre>[16:19:20] [INFO] (\ud83d\udcbe + \ud83d\udcbe) Concatenating 2 datasets\n</pre> <pre>[16:19:20] [INFO] \ud83e\udde9 Generating column `first_name` from expression\n</pre> <pre>[16:19:20] [INFO] \ud83e\udde9 Generating column `last_name` from expression\n</pre> <pre>[16:19:20] [INFO] \ud83e\udde9 Generating column `dob` from expression\n</pre> <pre>[16:19:20] [INFO] \ud83e\udde9 Generating column `physician` from expression\n</pre> <pre>[16:19:20] [INFO] \ud83d\udcdd Preparing llm-text column generation\n</pre> <pre>[16:19:20] [INFO]   |-- column name: 'physician_notes'\n</pre> <pre>[16:19:20] [INFO]   |-- model config:\n{\n    \"alias\": \"nemotron-nano-v2\",\n    \"model\": \"nvidia/nvidia-nemotron-nano-9b-v2\",\n    \"inference_parameters\": {\n        \"temperature\": 0.5,\n        \"top_p\": 1.0,\n        \"max_tokens\": 1024,\n        \"max_parallel_requests\": 4,\n        \"timeout\": null,\n        \"extra_body\": null\n    },\n    \"provider\": \"nvidia\"\n}\n</pre> <pre>[16:19:20] [INFO] \ud83d\udc19 Processing llm-text column 'physician_notes' with 4 concurrent workers\n</pre> <pre>[16:19:39] [INFO] \ud83d\udcca Model usage summary:\n{\n    \"nvidia/nvidia-nemotron-nano-9b-v2\": {\n        \"token_usage\": {\n            \"prompt_tokens\": 1304,\n            \"completion_tokens\": 7177,\n            \"total_tokens\": 8481\n        },\n        \"request_usage\": {\n            \"successful_requests\": 10,\n            \"failed_requests\": 0,\n            \"total_requests\": 10\n        },\n        \"tokens_per_second\": 451,\n        \"requests_per_minute\": 31\n    }\n}\n</pre> <pre>[16:19:39] [INFO] \ud83d\udcd0 Measuring dataset column statistics:\n</pre> <pre>[16:19:39] [INFO]   |-- \ud83c\udf31 column: 'diagnosis'\n</pre> <pre>[16:19:39] [INFO]   |-- \ud83c\udf31 column: 'patient_summary'\n</pre> <pre>[16:19:39] [INFO]   |-- \ud83c\udfb2 column: 'patient_sampler'\n</pre> <pre>[16:19:39] [INFO]   |-- \ud83c\udfb2 column: 'doctor_sampler'\n</pre> <pre>[16:19:39] [INFO]   |-- \ud83c\udfb2 column: 'patient_id'\n</pre> <pre>[16:19:39] [INFO]   |-- \ud83e\udde9 column: 'first_name'\n</pre> <pre>[16:19:39] [INFO]   |-- \ud83e\udde9 column: 'last_name'\n</pre> <pre>[16:19:39] [INFO]   |-- \ud83e\udde9 column: 'dob'\n</pre> <pre>[16:19:39] [INFO]   |-- \ud83c\udfb2 column: 'symptom_onset_date'\n</pre> <pre>[16:19:39] [INFO]   |-- \ud83c\udfb2 column: 'date_of_visit'\n</pre> <pre>[16:19:39] [INFO]   |-- \ud83e\udde9 column: 'physician'\n</pre> <pre>[16:19:39] [INFO]   |-- \ud83d\udcdd column: 'physician_notes'\n</pre> In\u00a0[12]: Copied! <pre># Load the generated dataset as a pandas DataFrame.\ndataset = job_results.load_dataset()\n\ndataset.head()\n</pre> # Load the generated dataset as a pandas DataFrame. dataset = job_results.load_dataset()  dataset.head() Out[12]: diagnosis patient_summary patient_sampler doctor_sampler patient_id symptom_onset_date date_of_visit first_name last_name dob physician physician_notes 0 cervical spondylosis I've been having a lot of pain in my neck and ... {'age': 102, 'bachelors_field': 'education', '... {'age': 64, 'bachelors_field': 'no_degree', 'b... PT-EA6F5264 2024-04-26 2024-05-03 William Gomez 1923-03-17 Dr. Powell **Dr. Cheryl Powell, MD**   **Primary Care Phy... 1 impetigo I have a rash on my face that is getting worse... {'age': 24, 'bachelors_field': 'no_degree', 'b... {'age': 36, 'bachelors_field': 'stem_related',... PT-F37B302C 2024-08-27 2024-09-05 Kathy Williams 2001-04-07 Dr. Robbins **Dr. Pamela Robbins, Primary Care Physician**... 2 urinary tract infection I have been urinating blood. I sometimes feel ... {'age': 113, 'bachelors_field': 'no_degree', '... {'age': 62, 'bachelors_field': 'arts_humanitie... PT-4940F10B 2024-02-07 2024-02-24 Nancy Cowan 1912-11-02 Dr. Brown **Dr. Jacqueline Brown**   **Primary Care Phys... 3 arthritis I have been having trouble with my muscles and... {'age': 60, 'bachelors_field': 'no_degree', 'b... {'age': 105, 'bachelors_field': 'arts_humaniti... PT-0FE12584 2024-10-11 2024-11-01 William Bass 1965-09-19 Dr. Hensley **Dr. Robert Hensley**   **Primary Care Physic... 4 dengue I have been feeling really sick. My body hurts... {'age': 101, 'bachelors_field': 'education', '... {'age': 72, 'bachelors_field': 'no_degree', 'b... PT-AE5CCB2F 2024-12-22 2025-01-14 Brandi Anderson 1924-09-21 Dr. Brown **Dr. Melissa Brown**   *Primary Care Physicia... In\u00a0[13]: Copied! <pre># Load the analysis results into memory.\nanalysis = job_results.load_analysis()\n\nanalysis.to_report()\n</pre> # Load the analysis results into memory. analysis = job_results.load_analysis()  analysis.to_report() <pre>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83c\udfa8 Data Designer Dataset Profile \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n                                                                                                                   \n                                                 Dataset Overview                                                  \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 number of records               \u2503 number of columns               \u2503 percent complete records                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 10                              \u2502 12                              \u2502 100.0%                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                              \ud83c\udf31 Seed-Dataset Columns                                              \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 column name                          \u2503               data type \u2503                           number unique values \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 diagnosis                            \u2502                  string \u2502                                      7 (70.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 patient_summary                      \u2502                  string \u2502                                    10 (100.0%) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                                \ud83c\udfb2 Sampler Columns                                                 \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 column name                   \u2503       data type \u2503             number unique values \u2503               sampler type \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 patient_sampler               \u2502            dict \u2502                      10 (100.0%) \u2502          person_from_faker \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 doctor_sampler                \u2502            dict \u2502                      10 (100.0%) \u2502          person_from_faker \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 patient_id                    \u2502          string \u2502                      10 (100.0%) \u2502                       uuid \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 symptom_onset_date            \u2502          string \u2502                      10 (100.0%) \u2502                   datetime \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 date_of_visit                 \u2502          string \u2502                      10 (100.0%) \u2502                  timedelta \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                                \ud83d\udcdd LLM-Text Columns                                                \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503                       \u2503               \u2503                            \u2503     prompt tokens \u2503      completion tokens \u2503\n\u2503 column name           \u2503     data type \u2503       number unique values \u2503        per record \u2503             per record \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 physician_notes       \u2502        string \u2502                10 (100.0%) \u2502     112.0 +/- 5.3 \u2502         633.0 +/- 93.4 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                               \ud83e\udde9 Expression Columns                                               \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 column name                    \u2503                 data type \u2503                               number unique values \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 first_name                     \u2502                    string \u2502                                          8 (80.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 last_name                      \u2502                    string \u2502                                        10 (100.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dob                            \u2502                    string \u2502                                        10 (100.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 physician                      \u2502                    string \u2502                                          9 (90.0%) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Table Notes \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                                 \u2502\n\u2502  1. All token statistics are based on a sample of max(1000, len(dataset)) records.                              \u2502\n\u2502  2. Tokens are calculated using tiktoken's cl100k_base tokenizer.                                               \u2502\n\u2502                                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n                                                                                                                   \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</pre>"},{"location":"notebooks/3-seeding-with-a-dataset/#data-designer-tutorial-seeding-synthetic-data-generation-with-an-external-dataset","title":"\ud83c\udfa8 Data Designer Tutorial: Seeding Synthetic Data Generation with an External Dataset\u00b6","text":""},{"location":"notebooks/3-seeding-with-a-dataset/#what-youll-learn","title":"\ud83d\udcda What you'll learn\u00b6","text":"<p>In this notebook, we will demonstrate how to seed synthetic data generation in Data Designer with an external dataset.</p> <p>If this is your first time using Data Designer, we recommend starting with the first notebook in this tutorial series.</p>"},{"location":"notebooks/3-seeding-with-a-dataset/#import-the-essentials","title":"\ud83d\udce6 Import the essentials\u00b6","text":"<ul> <li>The <code>essentials</code> module provides quick access to the most commonly used objects.</li> </ul>"},{"location":"notebooks/3-seeding-with-a-dataset/#initialize-the-data-designer-interface","title":"\u2699\ufe0f Initialize the Data Designer interface\u00b6","text":"<ul> <li><p><code>DataDesigner</code> is the main object is responsible for managing the data generation process.</p> </li> <li><p>When initialized without arguments, the default model providers are used.</p> </li> </ul>"},{"location":"notebooks/3-seeding-with-a-dataset/#define-model-configurations","title":"\ud83c\udf9b\ufe0f Define model configurations\u00b6","text":"<ul> <li><p>Each <code>ModelConfig</code> defines a model that can be used during the generation process.</p> </li> <li><p>The \"model alias\" is used to reference the model in the Data Designer config (as we will see below).</p> </li> <li><p>The \"model provider\" is the external service that hosts the model (see the model config docs for more details).</p> </li> <li><p>By default, we use build.nvidia.com as the model provider.</p> </li> </ul>"},{"location":"notebooks/3-seeding-with-a-dataset/#initialize-the-data-designer-config-builder","title":"\ud83c\udfd7\ufe0f Initialize the Data Designer Config Builder\u00b6","text":"<ul> <li><p>The Data Designer config defines the dataset schema and generation process.</p> </li> <li><p>The config builder provides an intuitive interface for building this configuration.</p> </li> <li><p>The list of model configs is provided to the builder at initialization.</p> </li> </ul>"},{"location":"notebooks/3-seeding-with-a-dataset/#prepare-a-seed-dataset","title":"\ud83c\udfe5 Prepare a seed dataset\u00b6","text":"<ul> <li><p>For this notebook, we'll create a synthetic dataset of patient notes.</p> </li> <li><p>We will seed the generation process with a symptom-to-diagnosis dataset.</p> </li> <li><p>We already have the dataset downloaded in the data directory of this repository.</p> </li> </ul> <p>\ud83c\udf31 Why use a seed dataset?</p> <ul> <li><p>Seed datasets let you steer the generation process by providing context that is specific to your use case.</p> </li> <li><p>Seed datasets are also an excellent way to inject real-world diversity into your synthetic data.</p> </li> <li><p>During generation, prompt templates can reference any of the seed dataset fields.</p> </li> </ul>"},{"location":"notebooks/3-seeding-with-a-dataset/#designing-our-synthetic-patient-notes-dataset","title":"\ud83c\udfa8 Designing our synthetic patient notes dataset\u00b6","text":"<ul> <li><p>Here we use <code>add_column</code> with keyword arguments (rather than imported config objects).</p> </li> <li><p>Generally, we recommend using concrete objects, but this is a convenient shorthand.</p> </li> <li><p>Note: The prompt template can reference fields from our seed dataset:</p> <ul> <li><code>{{ diagnosis }}</code> - the medical diagnosis from the seed data</li> <li><code>{{ patient_summary }}</code> - the symptom description from the seed data</li> </ul> </li> </ul>"},{"location":"notebooks/3-seeding-with-a-dataset/#iteration-is-key-preview-the-dataset","title":"\ud83d\udd01 Iteration is key \u2013\u00a0preview the dataset!\u00b6","text":"<ol> <li><p>Use the <code>preview</code> method to generate a sample of records quickly.</p> </li> <li><p>Inspect the results for quality and format issues.</p> </li> <li><p>Adjust column configurations, prompts, or parameters as needed.</p> </li> <li><p>Re-run the preview until satisfied.</p> </li> </ol>"},{"location":"notebooks/3-seeding-with-a-dataset/#analyze-the-generated-data","title":"\ud83d\udcca Analyze the generated data\u00b6","text":"<ul> <li><p>Data Designer automatically generates a basic statistical analysis of the generated data.</p> </li> <li><p>This analysis is available via the <code>analysis</code> property of generation result objects.</p> </li> </ul>"},{"location":"notebooks/3-seeding-with-a-dataset/#scale-up","title":"\ud83c\udd99 Scale up!\u00b6","text":"<ul> <li><p>Happy with your preview data?</p> </li> <li><p>Use the <code>create</code> method to submit larger Data Designer generation jobs.</p> </li> </ul>"},{"location":"notebooks/3-seeding-with-a-dataset/#next-steps","title":"\u23ed\ufe0f Next Steps\u00b6","text":"<p>Use Data Designer to generate synthetic data for your specific use case!</p>"},{"location":"notebooks/4-providing-images-as-context/","title":"Providing Images as Context","text":"In\u00a0[1]: Copied! <pre>!uv pip install pillow\n</pre> !uv pip install pillow <pre>Using Python 3.11.14 environment at: /home/runner/work/DataDesigner/DataDesigner/.venv\r\n\u280b Resolving dependencies...                                                     \r\u280b Resolving dependencies...                                                     \r\u2819 Resolving dependencies...                                                     </pre> <pre>\r\u2819 pillow==12.0.0                                                                </pre> <pre>\r\u2819                                                                               \rResolved 1 package in 74ms\r\n\u280b Preparing packages... (0/0)                                                   \r\u280b Preparing packages... (0/1)                                                   \r\u2819 Preparing packages... (0/1)                                                   \r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------     0 B/6.71 MiB            \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 16.00 KiB/6.71 MiB          </pre> <pre>\r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 32.00 KiB/6.71 MiB          \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 48.00 KiB/6.71 MiB          \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 64.00 KiB/6.71 MiB          \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 80.00 KiB/6.71 MiB          \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 96.00 KiB/6.71 MiB          \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 112.00 KiB/6.71 MiB         \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 128.00 KiB/6.71 MiB         \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 144.00 KiB/6.71 MiB         \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 160.00 KiB/6.71 MiB         \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 176.00 KiB/6.71 MiB         \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 192.00 KiB/6.71 MiB         \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 208.00 KiB/6.71 MiB         \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 224.00 KiB/6.71 MiB         \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 240.00 KiB/6.71 MiB         \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 256.00 KiB/6.71 MiB         \r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 272.00 KiB/6.71 MiB         </pre> <pre>\r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 1.09 MiB/6.71 MiB           </pre> <pre>\r\r\u2819 Preparing packages... (0/1)\r\npillow               ------------------------------ 4.93 MiB/6.71 MiB           \r\r\u2819 Preparing packages... (0/1)                                                   \rPrepared 1 package in 178ms\r\n\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/0] Installing wheels...                                 \r\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/1] Installing wheels...                                 </pre> <pre>\r\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/1] pillow==12.0.0                                       \r\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 [1/1] pillow==12.0.0                                       \rInstalled 1 package in 4ms\r\n + pillow==12.0.0\r\n</pre> In\u00a0[2]: Copied! <pre># Standard library imports\nimport base64\nimport io\nimport uuid\n\n# Third-party imports\nimport pandas as pd\nimport rich\nfrom datasets import load_dataset\nfrom IPython.display import display\nfrom rich.panel import Panel\n\n# Data Designer imports\nfrom data_designer.essentials import (\n    DataDesigner,\n    DataDesignerConfigBuilder,\n    ImageContext,\n    ImageFormat,\n    InferenceParameters,\n    LLMTextColumnConfig,\n    ModalityDataType,\n    ModelConfig,\n)\n</pre> # Standard library imports import base64 import io import uuid  # Third-party imports import pandas as pd import rich from datasets import load_dataset from IPython.display import display from rich.panel import Panel  # Data Designer imports from data_designer.essentials import (     DataDesigner,     DataDesignerConfigBuilder,     ImageContext,     ImageFormat,     InferenceParameters,     LLMTextColumnConfig,     ModalityDataType,     ModelConfig, ) In\u00a0[3]: Copied! <pre>data_designer = DataDesigner()\n</pre> data_designer = DataDesigner() In\u00a0[4]: Copied! <pre># This name is set in the model provider configuration.\nMODEL_PROVIDER = \"nvidia\"\n\nmodel_configs = [\n    ModelConfig(\n        alias=\"vision\",\n        model=\"meta/llama-4-scout-17b-16e-instruct\",\n        provider=MODEL_PROVIDER,\n        inference_parameters=InferenceParameters(\n            temperature=0.60,\n            top_p=0.95,\n            max_tokens=2048,\n        ),\n    ),\n]\n</pre> # This name is set in the model provider configuration. MODEL_PROVIDER = \"nvidia\"  model_configs = [     ModelConfig(         alias=\"vision\",         model=\"meta/llama-4-scout-17b-16e-instruct\",         provider=MODEL_PROVIDER,         inference_parameters=InferenceParameters(             temperature=0.60,             top_p=0.95,             max_tokens=2048,         ),     ), ] In\u00a0[5]: Copied! <pre>config_builder = DataDesignerConfigBuilder(model_configs=model_configs)\n</pre> config_builder = DataDesignerConfigBuilder(model_configs=model_configs) In\u00a0[6]: Copied! <pre># Dataset processing configuration\nIMG_COUNT = 512  # Number of images to process\nBASE64_IMAGE_HEIGHT = 512  # Standardized height for model input\n\n# Load ColPali dataset for visual documents\nimg_dataset_cfg = {\"path\": \"vidore/colpali_train_set\", \"split\": \"train\", \"streaming\": True}\n</pre> # Dataset processing configuration IMG_COUNT = 512  # Number of images to process BASE64_IMAGE_HEIGHT = 512  # Standardized height for model input  # Load ColPali dataset for visual documents img_dataset_cfg = {\"path\": \"vidore/colpali_train_set\", \"split\": \"train\", \"streaming\": True} In\u00a0[7]: Copied! <pre>def resize_image(image, height: int):\n    \"\"\"\n    Resize image while maintaining aspect ratio.\n\n    Args:\n        image: PIL Image object\n        height: Target height in pixels\n\n    Returns:\n        Resized PIL Image object\n    \"\"\"\n    original_width, original_height = image.size\n    width = int(original_width * (height / original_height))\n    return image.resize((width, height))\n\n\ndef convert_image_to_chat_format(record, height: int) -&gt; dict:\n    \"\"\"\n    Convert PIL image to base64 format for chat template usage.\n\n    Args:\n        record: Dataset record containing image and metadata\n        height: Target height for image resizing\n\n    Returns:\n        Updated record with base64_image and uuid fields\n    \"\"\"\n    # Resize image for consistent processing\n    image = resize_image(record[\"image\"], height)\n\n    # Convert to base64 string\n    img_buffer = io.BytesIO()\n    image.save(img_buffer, format=\"PNG\")\n    byte_data = img_buffer.getvalue()\n    base64_encoded_data = base64.b64encode(byte_data)\n    base64_string = base64_encoded_data.decode(\"utf-8\")\n\n    # Return updated record\n    return record | {\"base64_image\": base64_string, \"uuid\": str(uuid.uuid4())}\n</pre> def resize_image(image, height: int):     \"\"\"     Resize image while maintaining aspect ratio.      Args:         image: PIL Image object         height: Target height in pixels      Returns:         Resized PIL Image object     \"\"\"     original_width, original_height = image.size     width = int(original_width * (height / original_height))     return image.resize((width, height))   def convert_image_to_chat_format(record, height: int) -&gt; dict:     \"\"\"     Convert PIL image to base64 format for chat template usage.      Args:         record: Dataset record containing image and metadata         height: Target height for image resizing      Returns:         Updated record with base64_image and uuid fields     \"\"\"     # Resize image for consistent processing     image = resize_image(record[\"image\"], height)      # Convert to base64 string     img_buffer = io.BytesIO()     image.save(img_buffer, format=\"PNG\")     byte_data = img_buffer.getvalue()     base64_encoded_data = base64.b64encode(byte_data)     base64_string = base64_encoded_data.decode(\"utf-8\")      # Return updated record     return record | {\"base64_image\": base64_string, \"uuid\": str(uuid.uuid4())} In\u00a0[8]: Copied! <pre># Load and process the visual document dataset\nprint(\"\ud83d\udce5 Loading and processing document images...\")\n\nimg_dataset_iter = iter(\n    load_dataset(**img_dataset_cfg).map(convert_image_to_chat_format, fn_kwargs={\"height\": BASE64_IMAGE_HEIGHT})\n)\nimg_dataset = pd.DataFrame([next(img_dataset_iter) for _ in range(IMG_COUNT)])\n\nprint(f\"\u2705 Loaded {len(img_dataset)} images with columns: {list(img_dataset.columns)}\")\n</pre> # Load and process the visual document dataset print(\"\ud83d\udce5 Loading and processing document images...\")  img_dataset_iter = iter(     load_dataset(**img_dataset_cfg).map(convert_image_to_chat_format, fn_kwargs={\"height\": BASE64_IMAGE_HEIGHT}) ) img_dataset = pd.DataFrame([next(img_dataset_iter) for _ in range(IMG_COUNT)])  print(f\"\u2705 Loaded {len(img_dataset)} images with columns: {list(img_dataset.columns)}\") <pre>\ud83d\udce5 Loading and processing document images...\n</pre> <pre>\u2705 Loaded 512 images with columns: ['image', 'image_filename', 'query', 'answer', 'source', 'options', 'page', 'model', 'prompt', 'answer_type', 'base64_image', 'uuid']\n</pre> In\u00a0[9]: Copied! <pre>img_dataset.head()\n</pre> img_dataset.head() Out[9]: image image_filename query answer source options page model prompt answer_type base64_image uuid 0 &lt;PIL.JpegImagePlugin.JpegImageFile image mode=... images/1810.07757_2.jpg Comparing panels a, b, c, and d, which stateme... D arxiv_qa ['A. The variance of the data decreases from p... gpt4V None iVBORw0KGgoAAAANSUhEUgAAAUAAAAIACAIAAAB8QiIMAA... d50a8fed-5737-4da0-85ba-bae7b33fc8f0 1 &lt;PIL.JpegImagePlugin.JpegImageFile image mode=... data/scrapped_pdfs_split/pages_extracted/energ... What is the duration of the course mentioned i... ['five to ten hours, not including field trips'] pdf None 9 sonnet \\n        You are an assistant specialized in ... None iVBORw0KGgoAAAANSUhEUgAAAYsAAAIACAIAAAD8HddaAA... 688fccf8-0099-4aac-8a75-4ac54c311efe 2 &lt;PIL.JpegImagePlugin.JpegImageFile image mode=... data/scrapped_pdfs_split/pages_extracted/energ... What is the primary purpose of the PTC in lith... ['protect against external short circuits'] pdf None 414 sonnet \\n        You are an assistant specialized in ... None iVBORw0KGgoAAAANSUhEUgAAAZgAAAIACAIAAAAwhO2xAA... bf2b8ed1-25a7-4d79-98f1-ca76fc4d9e5b 3 &lt;PIL.PngImagePlugin.PngImageFile image mode=L ... 0fd47b51ae9248ef36669b8619b1223f268edae3e7a44a... What is the date?\\nYour answer should be very ... OCTOBER 17, 1995. docvqa None None None None None iVBORw0KGgoAAAANSUhEUgAAAX0AAAIACAAAAABLRuMPAA... 4a84c710-33ec-46fa-85ea-9ef75381ec6e 4 &lt;PIL.PngImagePlugin.PngImageFile image mode=L ... b335cfb9d442f8925ea41a064cb445a5395577f2345d52... What is Bert Shulimson's title?\\nYour response... EXECUTIVE SECRETARY. docvqa None None None None None iVBORw0KGgoAAAANSUhEUgAAAY8AAAIACAAAAABf/7+rAA... 09131c68-14e8-4b43-bd43-52158330a1d8 In\u00a0[10]: Copied! <pre># Add the seed dataset containing our processed images\ndf_seed = pd.DataFrame(img_dataset)[[\"uuid\", \"image_filename\", \"base64_image\", \"page\", \"options\", \"source\"]]\nconfig_builder.with_seed_dataset(\n    DataDesigner.make_seed_reference_from_dataframe(df_seed, file_path=\"colpali_train_set.csv\")\n)\n</pre> # Add the seed dataset containing our processed images df_seed = pd.DataFrame(img_dataset)[[\"uuid\", \"image_filename\", \"base64_image\", \"page\", \"options\", \"source\"]] config_builder.with_seed_dataset(     DataDesigner.make_seed_reference_from_dataframe(df_seed, file_path=\"colpali_train_set.csv\") ) <pre>[16:20:18] [INFO] \ud83d\udcbe Saving seed dataset to colpali_train_set.csv\n</pre> Out[10]: <pre>DataDesignerConfigBuilder(\n    seed_dataset: 'colpali_train_set.csv'\n    seed_dataset_columns: [\n        \"uuid\",\n        \"image_filename\",\n        \"base64_image\",\n        \"page\",\n        \"options\",\n        \"source\"\n    ]\n)\n</pre> In\u00a0[11]: Copied! <pre># Add a column to generate detailed document summaries\nconfig_builder.add_column(\n    LLMTextColumnConfig(\n        name=\"summary\",\n        model_alias=\"vision\",\n        prompt=(\n            \"Provide a detailed summary of the content in this image in Markdown format. \"\n            \"Start from the top of the image and then describe it from top to bottom. \"\n            \"Place a summary at the bottom.\"\n        ),\n        multi_modal_context=[\n            ImageContext(\n                column_name=\"base64_image\",\n                data_type=ModalityDataType.BASE64,\n                image_format=ImageFormat.PNG,\n            )\n        ],\n    )\n)\n</pre> # Add a column to generate detailed document summaries config_builder.add_column(     LLMTextColumnConfig(         name=\"summary\",         model_alias=\"vision\",         prompt=(             \"Provide a detailed summary of the content in this image in Markdown format. \"             \"Start from the top of the image and then describe it from top to bottom. \"             \"Place a summary at the bottom.\"         ),         multi_modal_context=[             ImageContext(                 column_name=\"base64_image\",                 data_type=ModalityDataType.BASE64,                 image_format=ImageFormat.PNG,             )         ],     ) ) Out[11]: <pre>DataDesignerConfigBuilder(\n    seed_dataset: 'colpali_train_set.csv'\n    seed_dataset_columns: [\n        \"uuid\",\n        \"image_filename\",\n        \"base64_image\",\n        \"page\",\n        \"options\",\n        \"source\"\n    ]\n    llm_text_columns: ['summary']\n)\n</pre> In\u00a0[12]: Copied! <pre>preview = data_designer.preview(config_builder, num_records=2)\n</pre> preview = data_designer.preview(config_builder, num_records=2) <pre>[16:20:19] [INFO] \ud83d\udd75\ufe0f Preview generation in progress\n</pre> <pre>[16:20:19] [INFO] \u2705 Validation passed\n</pre> <pre>[16:20:19] [INFO] \u26d3\ufe0f Sorting column configs into a Directed Acyclic Graph\n</pre> <pre>[16:20:19] [INFO] \ud83e\ude7a Running health checks for models...\n</pre> <pre>[16:20:19] [INFO]   |-- \ud83d\udc40 Checking 'meta/llama-4-scout-17b-16e-instruct' in provider named 'nvidia' for model alias 'vision'...\n</pre> <pre>[16:20:20] [INFO]   |-- \u2705 Passed!\n</pre> <pre>[16:20:24] [INFO] \ud83c\udf31 Sampling 2 records from seed dataset\n</pre> <pre>[16:20:24] [INFO]   |-- seed dataset size: 512 records\n</pre> <pre>[16:20:24] [INFO]   |-- sampling strategy: ordered\n</pre> <pre>[16:20:24] [INFO] \ud83d\udcdd Preparing llm-text column generation\n</pre> <pre>[16:20:24] [INFO]   |-- column name: 'summary'\n</pre> <pre>[16:20:24] [INFO]   |-- model config:\n{\n    \"alias\": \"vision\",\n    \"model\": \"meta/llama-4-scout-17b-16e-instruct\",\n    \"inference_parameters\": {\n        \"temperature\": 0.6,\n        \"top_p\": 0.95,\n        \"max_tokens\": 2048,\n        \"max_parallel_requests\": 4,\n        \"timeout\": null,\n        \"extra_body\": null\n    },\n    \"provider\": \"nvidia\"\n}\n</pre> <pre>[16:20:24] [INFO] \ud83d\udc19 Processing llm-text column 'summary' with 4 concurrent workers\n</pre> <pre>[16:20:29] [INFO] \ud83d\udcca Model usage summary:\n{\n    \"meta/llama-4-scout-17b-16e-instruct\": {\n        \"token_usage\": {\n            \"prompt_tokens\": 1396,\n            \"completion_tokens\": 743,\n            \"total_tokens\": 2139\n        },\n        \"request_usage\": {\n            \"successful_requests\": 2,\n            \"failed_requests\": 0,\n            \"total_requests\": 2\n        },\n        \"tokens_per_second\": 278,\n        \"requests_per_minute\": 15\n    }\n}\n</pre> <pre>[16:20:29] [INFO] \ud83d\udcd0 Measuring dataset column statistics:\n</pre> <pre>[16:20:29] [INFO]   |-- \ud83c\udf31 column: 'uuid'\n</pre> <pre>[16:20:29] [INFO]   |-- \ud83c\udf31 column: 'image_filename'\n</pre> <pre>[16:20:29] [INFO]   |-- \ud83c\udf31 column: 'base64_image'\n</pre> <pre>[16:20:29] [INFO]   |-- \ud83c\udf31 column: 'page'\n</pre> <pre>[16:20:29] [INFO]   |-- \ud83c\udf31 column: 'options'\n</pre> <pre>[16:20:29] [INFO]   |-- \ud83c\udf31 column: 'source'\n</pre> <pre>[16:20:29] [INFO]   |-- \ud83d\udcdd column: 'summary'\n</pre> <pre>[16:20:29] [INFO] \ud83c\udfc6 Preview complete!\n</pre> In\u00a0[13]: Copied! <pre># Run this cell multiple times to cycle through the 2 preview records.\npreview.display_sample_record()\n</pre> # Run this cell multiple times to cycle through the 2 preview records. preview.display_sample_record() <pre>                                                                                                                   \n                                                   Seed Columns                                                    \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Name           \u2503 Value                                                                                          \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 uuid           \u2502 d50a8fed-5737-4da0-85ba-bae7b33fc8f0                                                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 image_filename \u2502 images/1810.07757_2.jpg                                                                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 base64_image   \u2502 iVBORw0KGgoAAAANSUhEUgAAAUAAAAIACAIAAAB8QiIMAAEAAElEQVR4nOy9edRt2VUX+vvNufY+53zNbauvVJdKSEUQQ\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 page           \u2502 nan                                                                                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 options        \u2502 ['A. The variance of the data decreases from panel a to panel d.', 'B. The variance of the     \u2502\n\u2502                \u2502 data increases from panel a to panel d.', 'C. The data presents no variance in any of the      \u2502\n\u2502                \u2502 panels.', 'D. The variance of the data is inconsistent across the panels.', '-']               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 source         \u2502 arxiv_qa                                                                                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                                 Generated Columns                                                 \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Name    \u2503 Value                                                                                                 \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 summary \u2502 ## Image Summary                                                                                      \u2502\n\u2502         \u2502                                                                                                       \u2502\n\u2502         \u2502 The image presents a collection of 8 heatmap graphs, arranged in two columns of four rows each. The   \u2502\n\u2502         \u2502 graphs are labeled from \"a)\" to \"h)\".                                                                 \u2502\n\u2502         \u2502                                                                                                       \u2502\n\u2502         \u2502 ### Top Section: Color Bar                                                                            \u2502\n\u2502         \u2502                                                                                                       \u2502\n\u2502         \u2502 * A color bar is provided at the top, representing a correlation coefficient (\u03c4) ranging from 0.2 to  \u2502\n\u2502         \u2502 1.                                                                                                    \u2502\n\u2502         \u2502 * The color bar transitions from dark blue (0.2) to yellow (1).                                       \u2502\n\u2502         \u2502                                                                                                       \u2502\n\u2502         \u2502 ### Graphs                                                                                            \u2502\n\u2502         \u2502                                                                                                       \u2502\n\u2502         \u2502 The graphs display the relationship between two variables:                                            \u2502\n\u2502         \u2502                                                                                                       \u2502\n\u2502         \u2502 * **x-axis:** t (\u03bcs) ranging from 0 to 0.8                                                            \u2502\n\u2502         \u2502 * **y-axis:** \u0394\u03bd (MHz) with varying ranges across graphs                                              \u2502\n\u2502         \u2502                                                                                                       \u2502\n\u2502         \u2502 Here's a brief description of each graph:                                                             \u2502\n\u2502         \u2502                                                                                                       \u2502\n\u2502         \u2502 * **a)**: A relatively stable, horizontal band with a dark blue region (high correlation) around \u0394\u03bd = \u2502\n\u2502         \u2502 0 MHz.                                                                                                \u2502\n\u2502         \u2502 * **b)**: A scattered, random pattern with no clear trend.                                            \u2502\n\u2502         \u2502 * **c)**: Similar to graph \"b)\", with a scattered pattern and no clear trend.                         \u2502\n\u2502         \u2502 * **d)**: Another scattered pattern with a slightly more defined structure.                           \u2502\n\u2502         \u2502 * **e)**: A diagonal, dark blue region (high correlation) with a positive slope.                      \u2502\n\u2502         \u2502 * **f)**: A diagonal, yellow-to-blue transition with a positive slope.                                \u2502\n\u2502         \u2502 * **g)**: A curved, yellow-to-blue transition with a positive slope.                                  \u2502\n\u2502         \u2502 * **h)**: A curved, yellow-to-blue transition with a positive slope.                                  \u2502\n\u2502         \u2502                                                                                                       \u2502\n\u2502         \u2502 ### Summary                                                                                           \u2502\n\u2502         \u2502                                                                                                       \u2502\n\u2502         \u2502 The image presents a set of heatmap graphs illustrating the relationship between two variables, t     \u2502\n\u2502         \u2502 (\u03bcs) and \u0394\u03bd (MHz), with varying patterns and correlation coefficients. The graphs can be broadly      \u2502\n\u2502         \u2502 categorized into two groups: those with relatively stable or scattered patterns (a-d) and those with  \u2502\n\u2502         \u2502 diagonal or curved transitions (e-h). The color bar at the top provides a reference for interpreting  \u2502\n\u2502         \u2502 the correlation coefficients.                                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                    [index: 0]                                                     \n</pre> In\u00a0[14]: Copied! <pre># The preview dataset is available as a pandas DataFrame.\npreview.dataset\n</pre> # The preview dataset is available as a pandas DataFrame. preview.dataset Out[14]: uuid image_filename base64_image page options source summary 0 d50a8fed-5737-4da0-85ba-bae7b33fc8f0 images/1810.07757_2.jpg iVBORw0KGgoAAAANSUhEUgAAAUAAAAIACAIAAAB8QiIMAA... NaN ['A. The variance of the data decreases from p... arxiv_qa ## Image Summary\\n\\nThe image presents a colle... 1 688fccf8-0099-4aac-8a75-4ac54c311efe data/scrapped_pdfs_split/pages_extracted/energ... iVBORw0KGgoAAAANSUhEUgAAAYsAAAIACAIAAAD8HddaAA... 9.0 None pdf ## **How to Use These Materials**\\n\\nThe enclo... In\u00a0[15]: Copied! <pre># Print the analysis as a table.\npreview.analysis.to_report()\n</pre> # Print the analysis as a table. preview.analysis.to_report() <pre>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83c\udfa8 Data Designer Dataset Profile \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n                                                                                                                   \n                                                 Dataset Overview                                                  \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 number of records               \u2503 number of columns               \u2503 percent complete records                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 2                               \u2502 7                               \u2502 100.0%                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                              \ud83c\udf31 Seed-Dataset Columns                                              \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 column name                         \u2503               data type \u2503                            number unique values \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 uuid                                \u2502                  string \u2502                                      2 (100.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 image_filename                      \u2502                  string \u2502                                      2 (100.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 base64_image                        \u2502                  string \u2502                                      2 (100.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 page                                \u2502                   float \u2502                                       1 (50.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 options                             \u2502                  string \u2502                                      2 (100.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 source                              \u2502                  string \u2502                                      2 (100.0%) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                                \ud83d\udcdd LLM-Text Columns                                                \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503                  \u2503               \u2503                              \u2503       prompt tokens \u2503       completion tokens \u2503\n\u2503 column name      \u2503     data type \u2503         number unique values \u2503          per record \u2503              per record \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 summary          \u2502        string \u2502                   2 (100.0%) \u2502        38.0 +/- 0.0 \u2502          370.5 +/- 12.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Table Notes \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                                 \u2502\n\u2502  1. All token statistics are based on a sample of max(1000, len(dataset)) records.                              \u2502\n\u2502  2. Tokens are calculated using tiktoken's cl100k_base tokenizer.                                               \u2502\n\u2502                                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n                                                                                                                   \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</pre> In\u00a0[16]: Copied! <pre># Compare original document with generated summary\nindex = 0  # Change this to view different examples\n\n# Merge preview data with original images for comparison\ncomparison_dataset = preview.dataset.merge(pd.DataFrame(img_dataset)[[\"uuid\", \"image\"]], how=\"left\", on=\"uuid\")\n\n# Extract the record for display\nrecord = comparison_dataset.iloc[index]\n\nprint(\"\ud83d\udcc4 Original Document Image:\")\ndisplay(resize_image(record.image, BASE64_IMAGE_HEIGHT))\n\nprint(\"\\n\ud83d\udcdd Generated Summary:\")\nrich.print(Panel(record.summary, title=\"Document Summary\", title_align=\"left\"))\n</pre> # Compare original document with generated summary index = 0  # Change this to view different examples  # Merge preview data with original images for comparison comparison_dataset = preview.dataset.merge(pd.DataFrame(img_dataset)[[\"uuid\", \"image\"]], how=\"left\", on=\"uuid\")  # Extract the record for display record = comparison_dataset.iloc[index]  print(\"\ud83d\udcc4 Original Document Image:\") display(resize_image(record.image, BASE64_IMAGE_HEIGHT))  print(\"\\n\ud83d\udcdd Generated Summary:\") rich.print(Panel(record.summary, title=\"Document Summary\", title_align=\"left\")) <pre>\ud83d\udcc4 Original Document Image:\n</pre> <pre>\n\ud83d\udcdd Generated Summary:\n</pre> <pre>\u256d\u2500 Document Summary \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 ## Image Summary                                                                                                \u2502\n\u2502                                                                                                                 \u2502\n\u2502 The image presents a collection of 8 heatmap graphs, arranged in two columns of four rows each. The graphs are  \u2502\n\u2502 labeled from \"a)\" to \"h)\".                                                                                      \u2502\n\u2502                                                                                                                 \u2502\n\u2502 ### Top Section: Color Bar                                                                                      \u2502\n\u2502                                                                                                                 \u2502\n\u2502 * A color bar is provided at the top, representing a correlation coefficient (\u03c4) ranging from 0.2 to 1.         \u2502\n\u2502 * The color bar transitions from dark blue (0.2) to yellow (1).                                                 \u2502\n\u2502                                                                                                                 \u2502\n\u2502 ### Graphs                                                                                                      \u2502\n\u2502                                                                                                                 \u2502\n\u2502 The graphs display the relationship between two variables:                                                      \u2502\n\u2502                                                                                                                 \u2502\n\u2502 * **x-axis:** t (\u03bcs) ranging from 0 to 0.8                                                                      \u2502\n\u2502 * **y-axis:** \u0394\u03bd (MHz) with varying ranges across graphs                                                        \u2502\n\u2502                                                                                                                 \u2502\n\u2502 Here's a brief description of each graph:                                                                       \u2502\n\u2502                                                                                                                 \u2502\n\u2502 * **a)**: A relatively stable, horizontal band with a dark blue region (high correlation) around \u0394\u03bd = 0 MHz.    \u2502\n\u2502 * **b)**: A scattered, random pattern with no clear trend.                                                      \u2502\n\u2502 * **c)**: Similar to graph \"b)\", with a scattered pattern and no clear trend.                                   \u2502\n\u2502 * **d)**: Another scattered pattern with a slightly more defined structure.                                     \u2502\n\u2502 * **e)**: A diagonal, dark blue region (high correlation) with a positive slope.                                \u2502\n\u2502 * **f)**: A diagonal, yellow-to-blue transition with a positive slope.                                          \u2502\n\u2502 * **g)**: A curved, yellow-to-blue transition with a positive slope.                                            \u2502\n\u2502 * **h)**: A curved, yellow-to-blue transition with a positive slope.                                            \u2502\n\u2502                                                                                                                 \u2502\n\u2502 ### Summary                                                                                                     \u2502\n\u2502                                                                                                                 \u2502\n\u2502 The image presents a set of heatmap graphs illustrating the relationship between two variables, t (\u03bcs) and \u0394\u03bd   \u2502\n\u2502 (MHz), with varying patterns and correlation coefficients. The graphs can be broadly categorized into two       \u2502\n\u2502 groups: those with relatively stable or scattered patterns (a-d) and those with diagonal or curved transitions  \u2502\n\u2502 (e-h). The color bar at the top provides a reference for interpreting the correlation coefficients.             \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre> In\u00a0[17]: Copied! <pre>results = data_designer.create(config_builder, num_records=10)\n</pre> results = data_designer.create(config_builder, num_records=10) <pre>[16:20:29] [INFO] \ud83c\udfa8 Creating Data Designer dataset\n</pre> <pre>[16:20:29] [INFO] \u2705 Validation passed\n</pre> <pre>[16:20:29] [INFO] \u26d3\ufe0f Sorting column configs into a Directed Acyclic Graph\n</pre> <pre>[16:20:29] [INFO] \ud83d\udcc2 Dataset path '/home/runner/work/DataDesigner/DataDesigner/docs/notebook_source/artifacts/dataset' already exists. Dataset from this session\n\t\t     will be saved to '/home/runner/work/DataDesigner/DataDesigner/docs/notebook_source/artifacts/dataset_12-08-2025_162029' instead.\n</pre> <pre>[16:20:29] [INFO] \ud83e\ude7a Running health checks for models...\n</pre> <pre>[16:20:29] [INFO]   |-- \ud83d\udc40 Checking 'meta/llama-4-scout-17b-16e-instruct' in provider named 'nvidia' for model alias 'vision'...\n</pre> <pre>[16:20:30] [INFO]   |-- \u2705 Passed!\n</pre> <pre>[16:20:31] [INFO] \u23f3 Processing batch 1 of 1\n</pre> <pre>[16:20:33] [INFO] \ud83c\udf31 Sampling 10 records from seed dataset\n</pre> <pre>[16:20:33] [INFO]   |-- seed dataset size: 512 records\n</pre> <pre>[16:20:33] [INFO]   |-- sampling strategy: ordered\n</pre> <pre>[16:20:33] [INFO] \ud83d\udcdd Preparing llm-text column generation\n</pre> <pre>[16:20:33] [INFO]   |-- column name: 'summary'\n</pre> <pre>[16:20:33] [INFO]   |-- model config:\n{\n    \"alias\": \"vision\",\n    \"model\": \"meta/llama-4-scout-17b-16e-instruct\",\n    \"inference_parameters\": {\n        \"temperature\": 0.6,\n        \"top_p\": 0.95,\n        \"max_tokens\": 2048,\n        \"max_parallel_requests\": 4,\n        \"timeout\": null,\n        \"extra_body\": null\n    },\n    \"provider\": \"nvidia\"\n}\n</pre> <pre>[16:20:33] [INFO] \ud83d\udc19 Processing llm-text column 'summary' with 4 concurrent workers\n</pre> <pre>[16:20:54] [INFO] \ud83d\udcca Model usage summary:\n{\n    \"meta/llama-4-scout-17b-16e-instruct\": {\n        \"token_usage\": {\n            \"prompt_tokens\": 8140,\n            \"completion_tokens\": 4952,\n            \"total_tokens\": 13092\n        },\n        \"request_usage\": {\n            \"successful_requests\": 10,\n            \"failed_requests\": 0,\n            \"total_requests\": 10\n        },\n        \"tokens_per_second\": 559,\n        \"requests_per_minute\": 25\n    }\n}\n</pre> <pre>[16:20:54] [INFO] \ud83d\udcd0 Measuring dataset column statistics:\n</pre> <pre>[16:20:54] [INFO]   |-- \ud83c\udf31 column: 'uuid'\n</pre> <pre>[16:20:54] [INFO]   |-- \ud83c\udf31 column: 'image_filename'\n</pre> <pre>[16:20:54] [INFO]   |-- \ud83c\udf31 column: 'base64_image'\n</pre> <pre>[16:20:54] [INFO]   |-- \ud83c\udf31 column: 'page'\n</pre> <pre>[16:20:54] [INFO]   |-- \ud83c\udf31 column: 'options'\n</pre> <pre>[16:20:54] [INFO]   |-- \ud83c\udf31 column: 'source'\n</pre> <pre>[16:20:54] [INFO]   |-- \ud83d\udcdd column: 'summary'\n</pre> In\u00a0[18]: Copied! <pre># Load the generated dataset as a pandas DataFrame.\ndataset = results.load_dataset()\n\ndataset.head()\n</pre> # Load the generated dataset as a pandas DataFrame. dataset = results.load_dataset()  dataset.head() Out[18]: uuid image_filename base64_image page options source summary 0 d50a8fed-5737-4da0-85ba-bae7b33fc8f0 images/1810.07757_2.jpg iVBORw0KGgoAAAANSUhEUgAAAUAAAAIACAIAAAB8QiIMAA... &lt;NA&gt; ['A. The variance of the data decreases from p... arxiv_qa ## Image Summary The image presents a collecti... 1 688fccf8-0099-4aac-8a75-4ac54c311efe data/scrapped_pdfs_split/pages_extracted/energ... iVBORw0KGgoAAAANSUhEUgAAAYsAAAIACAIAAAD8HddaAA... 9.0 &lt;NA&gt; pdf ## Document Summary The document appears to be... 2 bf2b8ed1-25a7-4d79-98f1-ca76fc4d9e5b data/scrapped_pdfs_split/pages_extracted/energ... iVBORw0KGgoAAAANSUhEUgAAAZgAAAIACAIAAAAwhO2xAA... 414.0 &lt;NA&gt; pdf ## **14.10.3 Performance** ### **Voltage** The... 3 4a84c710-33ec-46fa-85ea-9ef75381ec6e 0fd47b51ae9248ef36669b8619b1223f268edae3e7a44a... iVBORw0KGgoAAAANSUhEUgAAAX0AAAIACAAAAABLRuMPAA... &lt;NA&gt; &lt;NA&gt; docvqa ## Document Summary The document appears to be... 4 09131c68-14e8-4b43-bd43-52158330a1d8 b335cfb9d442f8925ea41a064cb445a5395577f2345d52... iVBORw0KGgoAAAANSUhEUgAAAY8AAAIACAAAAABf/7+rAA... &lt;NA&gt; &lt;NA&gt; docvqa **Letterhead and Date** The letter is dated **... In\u00a0[19]: Copied! <pre># Load the analysis results into memory.\nanalysis = results.load_analysis()\n\nanalysis.to_report()\n</pre> # Load the analysis results into memory. analysis = results.load_analysis()  analysis.to_report() <pre>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83c\udfa8 Data Designer Dataset Profile \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n                                                                                                                   \n                                                 Dataset Overview                                                  \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 number of records               \u2503 number of columns               \u2503 percent complete records                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 10                              \u2502 7                               \u2502 100.0%                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                              \ud83c\udf31 Seed-Dataset Columns                                              \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 column name                         \u2503               data type \u2503                            number unique values \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 uuid                                \u2502                  string \u2502                                     10 (100.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 image_filename                      \u2502                  string \u2502                                     10 (100.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 base64_image                        \u2502                  string \u2502                                     10 (100.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 page                                \u2502                   float \u2502                                       6 (60.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 options                             \u2502                  string \u2502                                       3 (30.0%) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 source                              \u2502                  string \u2502                                       3 (30.0%) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n                                                \ud83d\udcdd LLM-Text Columns                                                \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503                  \u2503               \u2503                              \u2503       prompt tokens \u2503       completion tokens \u2503\n\u2503 column name      \u2503     data type \u2503         number unique values \u2503          per record \u2503              per record \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 summary          \u2502        string \u2502                  10 (100.0%) \u2502        38.0 +/- 0.0 \u2502          505.0 +/- 92.4 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                                                                   \n                                                                                                                   \n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Table Notes \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                                 \u2502\n\u2502  1. All token statistics are based on a sample of max(1000, len(dataset)) records.                              \u2502\n\u2502  2. Tokens are calculated using tiktoken's cl100k_base tokenizer.                                               \u2502\n\u2502                                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n                                                                                                                   \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</pre>"},{"location":"notebooks/4-providing-images-as-context/#data-designer-tutorial-providing-images-as-context-for-vision-based-data-generation","title":"\ud83c\udfa8 Data Designer Tutorial: Providing Images as Context for Vision-Based Data Generation\u00b6","text":""},{"location":"notebooks/4-providing-images-as-context/#what-youll-learn","title":"\ud83d\udcda What you'll learn\u00b6","text":"<p>This notebook demonstrates how to provide images as context to generate text descriptions using vision-language models.</p> <ul> <li>\u2728 Visual Document Processing: Converting images to chat-ready format for model consumption</li> <li>\ud83d\udd0d Vision-Language Generation: Using vision models to generate detailed summaries from images</li> </ul> <p>If this is your first time using Data Designer, we recommend starting with the first notebook in this tutorial series.</p>"},{"location":"notebooks/4-providing-images-as-context/#install-dependencies-if-required","title":"\u2b07\ufe0f Install dependencies (if required)\u00b6","text":""},{"location":"notebooks/4-providing-images-as-context/#import-the-essentials","title":"\ud83d\udce6 Import the essentials\u00b6","text":"<ul> <li>The <code>essentials</code> module provides quick access to the most commonly used objects.</li> </ul>"},{"location":"notebooks/4-providing-images-as-context/#initialize-the-data-designer-interface","title":"\u2699\ufe0f Initialize the Data Designer interface\u00b6","text":"<ul> <li><p><code>DataDesigner</code> is the main object is responsible for managing the data generation process.</p> </li> <li><p>When initialized without arguments, the default model providers are used.</p> </li> </ul>"},{"location":"notebooks/4-providing-images-as-context/#define-model-configurations","title":"\ud83c\udf9b\ufe0f Define model configurations\u00b6","text":"<ul> <li><p>Each <code>ModelConfig</code> defines a model that can be used during the generation process.</p> </li> <li><p>The \"model alias\" is used to reference the model in the Data Designer config (as we will see below).</p> </li> <li><p>The \"model provider\" is the external service that hosts the model (see the model config docs for more details).</p> </li> <li><p>By default, we use build.nvidia.com as the model provider.</p> </li> </ul>"},{"location":"notebooks/4-providing-images-as-context/#initialize-the-data-designer-config-builder","title":"\ud83c\udfd7\ufe0f Initialize the Data Designer Config Builder\u00b6","text":"<ul> <li><p>The Data Designer config defines the dataset schema and generation process.</p> </li> <li><p>The config builder provides an intuitive interface for building this configuration.</p> </li> <li><p>The list of model configs is provided to the builder at initialization.</p> </li> </ul>"},{"location":"notebooks/4-providing-images-as-context/#seed-dataset-creation","title":"\ud83c\udf31 Seed Dataset Creation\u00b6","text":"<p>In this section, we'll prepare our visual documents as a seed dataset for summarization:</p> <ul> <li>Loading Visual Documents: We use the ColPali dataset containing document images</li> <li>Image Processing: Convert images to base64 format for vision model consumption</li> <li>Metadata Extraction: Preserve relevant document information (filename, page number, source, etc.)</li> </ul> <p>The seed dataset will be used to generate detailed text summaries of each document image.</p>"},{"location":"notebooks/4-providing-images-as-context/#iteration-is-key-preview-the-dataset","title":"\ud83d\udd01 Iteration is key \u2013 preview the dataset!\u00b6","text":"<ol> <li><p>Use the <code>preview</code> method to generate a sample of records quickly.</p> </li> <li><p>Inspect the results for quality and format issues.</p> </li> <li><p>Adjust column configurations, prompts, or parameters as needed.</p> </li> <li><p>Re-run the preview until satisfied.</p> </li> </ol>"},{"location":"notebooks/4-providing-images-as-context/#analyze-the-generated-data","title":"\ud83d\udcca Analyze the generated data\u00b6","text":"<ul> <li><p>Data Designer automatically generates a basic statistical analysis of the generated data.</p> </li> <li><p>This analysis is available via the <code>analysis</code> property of generation result objects.</p> </li> </ul>"},{"location":"notebooks/4-providing-images-as-context/#visual-inspection","title":"\ud83d\udd0e Visual Inspection\u00b6","text":"<p>Let's compare the original document image with the generated summary to validate quality:</p>"},{"location":"notebooks/4-providing-images-as-context/#scale-up","title":"\ud83c\udd99 Scale up!\u00b6","text":"<ul> <li><p>Happy with your preview data?</p> </li> <li><p>Use the <code>create</code> method to submit larger Data Designer generation jobs.</p> </li> </ul>"},{"location":"notebooks/4-providing-images-as-context/#next-steps","title":"\u23ed\ufe0f Next Steps\u00b6","text":"<p>Now that you've learned how to use visual context for image summarization in Data Designer, explore more:</p> <ul> <li>Experiment with different vision models for specific document types</li> <li>Try different prompt variations to generate specialized descriptions (e.g., technical details, key findings)</li> <li>Combine vision-based summaries with other column types for multi-modal workflows</li> <li>Apply this pattern to other vision tasks like image captioning, OCR validation, or visual question answering</li> </ul>"}]}